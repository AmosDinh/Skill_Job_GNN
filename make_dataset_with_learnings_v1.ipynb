{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is the base where we dont use any edgeweights at all.\n",
        "Vanilla dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install pyg-lib -f https://data.pyg.org/whl/torch-2.1.0+cu121.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# import os\n",
        "# !pip install torch==2.1.0 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "# import torch\n",
        "# os.environ['TORCH'] = torch.__version__\n",
        "# print(torch.__version__)\n",
        "# #torch_version = '2.0.0+cu118'\n",
        "# #!pip install torch-scatter -f https://data.pyg.org/whl/torch-${torch.__version__}.html\n",
        "# #!pip install torch-cluster -f https://data.pyg.org/whl/torch-${torch.__version__}.html\n",
        "# #!pip install torch-sparse -f https://data.pyg.org/whl/torch-${torch.__version__}.html\n",
        "# !pip install torch-sparse -f https://data.pyg.org/whl/torch-2.0.0+cu121.html\n",
        "# !pip install torch-scatter -f https://data.pyg.org/whl/torch-2.0.0+cu121.html\n",
        "# !pip install git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "# !pip install sentence-transformers\n",
        "# !pip install torcheval\n",
        "# !pip install matplotlib\n",
        "# !pip install pandas\n",
        "# !pip install tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "p1oM_TnG9udQ",
        "outputId": "094d85e4-269c-4906-ee4b-396d85fec6d1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from torch_geometric.data import HeteroData\n",
        "import torch_geometric.transforms as T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_13991/3933947480.py:25: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv('final_dataset_courseprograms_joined/'+name+'.csv', lineterminator='\\n')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "final_courses_and_programs 65455\n",
            "final_qualifications 1475\n",
            "final_skills 872043\n",
            "final_qualification_skill_edges 1598\n",
            "final_course_and_program_skill_edges 260381\n",
            "final_course_qualification_edges 2099\n",
            "final_course_and_programs_student_edges 553629\n",
            "final_people 293444\n",
            "final_jobs 55653\n",
            "final_organizations 13613\n",
            "final_job_student_edges 293444\n",
            "final_supervisor_supervisee_edges 217922\n",
            "final_organization_student_edges 292060\n",
            "fixed_job_job_edges 18384\n",
            "fixed_job_skill_edges 16589018\n",
            "fixed_broader_job_job_edges 54586\n",
            "job_skill_edges 16289586\n"
          ]
        }
      ],
      "source": [
        "\n",
        "dataset_files = [\n",
        "    'final_courses_and_programs',\n",
        "    'final_qualifications',\n",
        "    'final_skills',\n",
        "\n",
        "    'final_qualification_skill_edges',\n",
        "    'final_course_and_program_skill_edges',\n",
        "    'final_course_qualification_edges',\n",
        "\n",
        "    'final_course_and_programs_student_edges',\n",
        "\n",
        "    'final_people',\n",
        "    'final_jobs',\n",
        "    'final_organizations',\n",
        "    'final_job_student_edges',\n",
        "    'final_supervisor_supervisee_edges',\n",
        "    'final_organization_student_edges',\n",
        "    'fixed_job_job_edges',\n",
        "    'fixed_job_skill_edges',\n",
        "    'fixed_broader_job_job_edges'\n",
        "    #'job_skill_edges_tfidf_100mio_50kid_800kskill'\n",
        "]\n",
        "df_names= []\n",
        "for name in dataset_files:\n",
        "    df = pd.read_csv('final_dataset_courseprograms_joined/'+name+'.csv', lineterminator='\\n')\n",
        "    print(name, df.shape[0])\n",
        "    globals()[name.replace('final_','').replace('fixed_','')] = df\n",
        "    df_names.append(name.replace('final_','').replace('fixed_',''))\n",
        "    \n",
        "import string\n",
        "word_list = [\n",
        "    \"or\", \"up\", \"it\", \"us\", \"race\", \"location\", \"systems\", \"tools\",\n",
        "    \"so\", \"addition\", \"id\", \"am\", \"edge\"\n",
        "] + list(set(list(string.ascii_lowercase))-set(['r']))\n",
        "job_skill_edges = job_skill_edges.loc[~job_skill_edges['skill'].isna()]\n",
        "job_skill_edges = job_skill_edges.loc[~job_skill_edges['skill'].isin(word_list)]\n",
        "\n",
        "\n",
        "# filter out all skills if the whole skill is a number only\n",
        "job_skill_edges = job_skill_edges.loc[~ job_skill_edges['skill'].str.isnumeric()]\n",
        "print('job_skill_edges', job_skill_edges.shape[0])\n",
        "\n",
        "\n",
        "\n",
        "course_and_program_skill_edges = course_and_program_skill_edges.loc[~course_and_program_skill_edges['Skill'].isna()]\n",
        "skills = skills.loc[~skills['SKILL'].isna()]\n",
        "\n",
        "# convert create_dte to timestamp if it is not already\n",
        "x  = pd.to_datetime(courses_and_programs['CREATE_DTE'], unit='s', errors='coerce')\n",
        "courses_and_programs.loc[~x.isna(), 'CREATE_DTE'] = x\n",
        "\n",
        "\n",
        "\n",
        "courses_and_programs.loc[courses_and_programs['TITLE'].isna(), 'TITLE'] = ''\n",
        "courses_and_programs.loc[courses_and_programs['DESCRIPTION'].isna(), 'DESCRIPTION'] = ''\n",
        "qualifications.loc[qualifications['TITLE'].isna(), 'TITLE'] = ''\n",
        "qualifications.loc[qualifications['DESCRIPTION'].isna(), 'DESCRIPTION'] = ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# add some skills which are only in the job_skill_edges but not in the skills csv\n",
        "a = set(job_skill_edges['skill'].unique())\n",
        "b = set(skills['SKILL'].unique())\n",
        "\n",
        "skills_to_add = list(a-b)\n",
        "skills_to_add = pd.DataFrame({'SKILL':skills_to_add})\n",
        "skills = pd.concat([skills, skills_to_add], axis=0)\n",
        "skills = skills.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_13991/2933620897.py:2: FutureWarning: The default value of numeric_only in DataFrameGroupBy.median is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
            "  job_skill_edges_grouped = job_skill_edges.groupby('JOB_ID').median()\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# group by JOB_ID\n",
        "job_skill_edges_grouped = job_skill_edges.groupby('JOB_ID').median()\n",
        "job_skill_edges_grouped\n",
        "\n",
        "# plot hist for n_jobdesc_used\n",
        "job_skill_edges_grouped['n_jobdesc_used'].hist(bins=50, range=(0,1000))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# filter out jobs with less than 10 job descriptions\n",
        "#job_skill_edges = job_skill_edges.loc[job_skill_edges['n_jobdesc_used']>=6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# import seaborn as sns\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# # Assuming 'job_skill_edges' is your DataFrame with the column 'scaled_tfidf'\n",
        "\n",
        "# # Calculate the threshold value (95th percentile)\n",
        "# threshold = np.percentile(job_skill_edges['scaled_tfidf'], 5)\n",
        "\n",
        "# # Replace values above the threshold with the threshold value\n",
        "# #job_skill_edges.loc[job_skill_edges['scaled_tfidf'] > threshold, 'scaled_tfidf'] = threshold\n",
        "\n",
        "# # Plot the KDE and threshold\n",
        "# sns.kdeplot(data=job_skill_edges['scaled_tfidf'])\n",
        "# plt.axvline(threshold, color='r', linestyle='--', label='Threshold')\n",
        "# plt.legend()\n",
        "# plt.xlabel('scaled_tfidf')\n",
        "# plt.ylabel('Density')\n",
        "# plt.title('Kernel Density Estimation')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "courses_and_programs\n",
            "[]\n",
            "qualifications\n",
            "[]\n",
            "skills\n",
            "[]\n",
            "qualification_skill_edges\n",
            "[]\n",
            "course_and_program_skill_edges\n",
            "[]\n",
            "course_qualification_edges\n",
            "[]\n",
            "course_and_programs_student_edges\n",
            "[]\n",
            "people\n",
            "[]\n",
            "jobs\n",
            "[]\n",
            "organizations\n",
            "[]\n",
            "job_student_edges\n",
            "[]\n",
            "supervisor_supervisee_edges\n",
            "[]\n",
            "organization_student_edges\n",
            "[]\n",
            "job_job_edges\n",
            "[]\n",
            "job_skill_edges\n",
            "[]\n",
            "broader_job_job_edges\n",
            "['Short Title']\n"
          ]
        }
      ],
      "source": [
        "# for each df in df_names print the name and print the columns containing nans\n",
        "for name in df_names:\n",
        "    print(name)\n",
        "    print(globals()[name].columns[globals()[name].isna().any()].tolist())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_13991/4011874702.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  broader_job_job_edges['SRC_ID'] = broader_job_job_edges['index_fixed']\n",
            "/tmp/ipykernel_13991/4011874702.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  broader_job_job_edges['DST_ID'] = broader_job_job_edges['onet_index_fixed']\n"
          ]
        }
      ],
      "source": [
        "del broader_job_job_edges['Short Title']\n",
        "broader_job_job_edges = broader_job_job_edges[['index_fixed','onet_index_fixed']]\n",
        "broader_job_job_edges['SRC_ID'] = broader_job_job_edges['index_fixed']\n",
        "broader_job_job_edges['DST_ID'] = broader_job_job_edges['onet_index_fixed']\n",
        "del broader_job_job_edges['index_fixed']\n",
        "del broader_job_job_edges['onet_index_fixed']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "courses_and_programs\n",
            ">>> converted REV_DTE\n",
            ">>> converted CREATE_DTE\n",
            "qualifications\n",
            ">>> converted CREATE_DTE\n",
            "skills\n",
            "qualification_skill_edges\n",
            "course_and_program_skill_edges\n",
            "course_qualification_edges\n",
            "course_and_programs_student_edges\n",
            ">>> converted COMPL_DTE\n",
            ">>> converted ASSGN_DTE\n",
            "people\n",
            ">>> converted HIRE_DTE\n",
            "jobs\n",
            "organizations\n",
            "job_student_edges\n",
            "supervisor_supervisee_edges\n",
            "organization_student_edges\n",
            "job_job_edges\n",
            "job_skill_edges\n",
            "broader_job_job_edges\n",
            "courses_and_programs\n",
            "qualifications\n",
            "skills\n",
            "qualification_skill_edges\n",
            "course_and_program_skill_edges\n",
            "course_qualification_edges\n",
            "course_and_programs_student_edges\n",
            "people\n",
            "jobs\n",
            "organizations\n",
            "job_student_edges\n",
            "supervisor_supervisee_edges\n",
            "organization_student_edges\n",
            "job_job_edges\n",
            "job_skill_edges\n",
            "broader_job_job_edges\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# for each column which contains DTE DATE or Date or date, convert the column to timestamp, for all dfs in df_names, save the highest timestamp overall to timestamp_max\n",
        "cols_dte = []\n",
        "timestamp_max = 0\n",
        "for name in df_names:\n",
        "    print(name)\n",
        "    for col in globals()[name].columns:\n",
        "        if 'DTE' in col or 'DATE' in col or 'Date' in col or 'date' in col:\n",
        "            try:\n",
        "\n",
        "                globals()[name][col] = (pd.to_datetime(globals()[name][col]) - pd.Timestamp(\"1970-01-01\")) // pd.Timedelta('1s')\n",
        "                timestamp_max = max(timestamp_max, globals()[name][col].max())\n",
        "                cols_dte.append(col)\n",
        "                print('>>> converted',col)\n",
        "            except:\n",
        "                print('could not convert', col)\n",
        "                pass\n",
        "\n",
        "# normalize all timestamps by timestamp max\n",
        "for name in df_names:\n",
        "    print(name)\n",
        "    for col in globals()[name].columns:\n",
        "        if 'DTE' in col or 'DATE' in col or 'Date' in col or 'date' in col:\n",
        "            try:\n",
        "                globals()[name][col] = globals()[name][col] / timestamp_max\n",
        "            except:\n",
        "                print('could not convert', col)\n",
        "                pass\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "courses_and_programs\n",
            "--- did not convert NOTACTIVE\n",
            "TOTAL_RATING\n",
            ">>> converted TOTAL_RATING\n",
            ">>> converted AVG_RATING\n",
            "--- did not convert CPNT_CLASSIFICATION\n",
            ">>> converted CREDIT_HRS\n",
            "--- did not convert THUMBNAIL_URI\n",
            "--- did not convert TITLE\n",
            "--- did not convert TITLE_TRANSLATION_NEEDED\n",
            "--- did not convert DESC_TRANSLATION_NEEDED\n",
            "--- did not convert DESCRIPTION\n",
            "--- did not convert LEARNING_TYPE\n",
            "qualifications\n",
            "--- did not convert NOTACTIVE\n",
            "--- did not convert TITLE\n",
            "--- did not convert TITLE_TRANSLATION_NEEDED\n",
            "--- did not convert DESC_TRANSLATION_NEEDED\n",
            "--- did not convert DESCRIPTION\n",
            "skills\n",
            "--- did not convert SKILL\n",
            "qualification_skill_edges\n",
            "--- did not convert Skill\n",
            "could not convert IS_APPROXIMATE\n",
            "course_and_program_skill_edges\n",
            "--- did not convert Skill\n",
            "could not convert IS_APPROXIMATE\n",
            "course_qualification_edges\n",
            "course_and_programs_student_edges\n",
            ">>> converted TOOK_MINUTES\n",
            "people\n",
            "--- did not convert IS_ACTIVE_INFERRED\n"
          ]
        }
      ],
      "source": [
        "# get all columns not in DTE DATE or Date or date, for all df_names, if the first 20 rows of the column are not numeric, normalize the column by the max of the column\n",
        "cols_numeric = []\n",
        "for name in df_names:\n",
        "    print(name)\n",
        "    for col in globals()[name].columns:\n",
        "        if col not in cols_dte and 'DTE' not in col and 'DATE' not in col and 'Date' not in col and 'date' not in col and 'ID' not in col and 'index' not in col and 'alt_title' not in col:\n",
        "            if 'TOTAL' in col:\n",
        "                print(col)\n",
        "            try:\n",
        "                if not pd.to_numeric(globals()[name][col], errors='coerce').isna().any():\n",
        "                    globals()[name][col] = pd.to_numeric(globals()[name][col]) / pd.to_numeric(globals()[name][col]).max()\n",
        "                    print('>>> converted', col)\n",
        "                    cols_numeric.append(col)\n",
        "                    \n",
        "                else:\n",
        "                    print('--- did not convert', col)\n",
        "            except:\n",
        "                print('could not convert', col)\n",
        "                pass\n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "courses_and_programs\n",
            "NOTACTIVE\n",
            "CPNT_CLASSIFICATION\n",
            ">>> ID col CPNT_TYP_ID\n",
            ">>> ID col DMN_ID\n",
            ">>> ID col CPNT_SRC_ID\n",
            "THUMBNAIL_URI\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TITLE\n",
            "TITLE_TRANSLATION_NEEDED\n",
            "DESC_TRANSLATION_NEEDED\n",
            "DESCRIPTION\n",
            "LEARNING_TYPE\n",
            ">>> ID col REAL_ID\n",
            ">>> ID col LEARNING_ITEM_ID\n",
            "qualifications\n",
            "NOTACTIVE\n",
            ">>> ID col QUAL_TYP_ID\n",
            ">>> ID col DMN_ID\n",
            "TITLE\n",
            "TITLE_TRANSLATION_NEEDED\n",
            "DESC_TRANSLATION_NEEDED\n",
            "DESCRIPTION\n",
            ">>> ID col REAL_ID\n",
            ">>> ID col LEARNING_ITEM_ID\n",
            ">>> ID col QUAL_ID\n",
            "skills\n",
            "SKILL\n",
            "qualification_skill_edges\n",
            "Skill\n",
            "IS_APPROXIMATE\n",
            ">>> ID col LEARNING_ITEM_ID\n",
            "course_and_program_skill_edges\n",
            "Skill\n",
            "IS_APPROXIMATE\n",
            ">>> ID col LEARNING_ITEM_ID\n",
            "course_qualification_edges\n",
            ">>> ID col LEARNING_ITEM_ID\n",
            ">>> ID col QUAL_ID\n",
            "course_and_programs_student_edges\n",
            ">>> ID col LEARNING_ITEM_ID\n",
            ">>> ID col STUD_ID\n",
            "people\n",
            ">>> ID col EMP_TYP_ID\n",
            "IS_ACTIVE_INFERRED\n",
            "FULLTIME\n",
            ">>> ID col DMN_ID\n",
            ">>> ID col STUD_ID\n",
            "jobs\n",
            ">>> ID col TITLE\n",
            "O*NET-SOC Code\n",
            ">>> ID col ID\n",
            "organizations\n",
            ">>> ID col ORG_ID\n",
            "job_student_edges\n",
            ">>> ID col ONET_ID\n",
            ">>> ID col STUD_ID\n",
            "supervisor_supervisee_edges\n",
            ">>> ID col STUD_ID\n",
            ">>> ID col SUPER_ID\n",
            "organization_student_edges\n",
            ">>> ID col STUD_ID\n",
            ">>> ID col ORG_ID\n",
            "job_job_edges\n",
            "O*NET-SOC Code\n",
            "Title\n",
            "Related O*NET-SOC Code\n",
            "Related Title\n",
            "Relatedness Tier\n",
            ">>> ID col SRC_ID\n",
            ">>> ID col DST_ID\n",
            "job_skill_edges\n",
            "skill\n",
            ">>> ID col JOB_ID\n",
            "broader_job_job_edges\n",
            ">>> ID col SRC_ID\n",
            ">>> ID col DST_ID\n"
          ]
        }
      ],
      "source": [
        "# for all columns not in col_dte and cols_numeric, if the column only contains unique values, save it to cols_id\n",
        "cols_id = []\n",
        "for name in df_names:\n",
        "    print(name)\n",
        "    for col in globals()[name].columns:\n",
        "        if col not in cols_dte and col not in cols_numeric:\n",
        "            if len(globals()[name][col].unique()) == globals()[name].shape[0] or '_ID' in col or 'index_x' in col or 'index_y' in col:\n",
        "                cols_id.append(col)\n",
        "                print('>>> ID col', col)\n",
        "            else:\n",
        "                print(col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "courses_and_programs\n",
            ">>> binary col NOTACTIVE\n",
            "CPNT_CLASSIFICATION\n",
            "THUMBNAIL_URI\n",
            ">>> binary col TITLE_TRANSLATION_NEEDED\n",
            ">>> binary col DESC_TRANSLATION_NEEDED\n",
            "DESCRIPTION\n",
            "LEARNING_TYPE\n",
            "qualifications\n",
            ">>> binary col NOTACTIVE\n",
            ">>> binary col TITLE_TRANSLATION_NEEDED\n",
            ">>> binary col DESC_TRANSLATION_NEEDED\n",
            "DESCRIPTION\n",
            "skills\n",
            "SKILL\n",
            "qualification_skill_edges\n",
            "Skill\n",
            ">>> binary col IS_APPROXIMATE\n",
            "course_and_program_skill_edges\n",
            "Skill\n",
            ">>> binary col IS_APPROXIMATE\n",
            "course_qualification_edges\n",
            "course_and_programs_student_edges\n",
            "people\n",
            "IS_ACTIVE_INFERRED\n",
            ">>> binary col FULLTIME\n",
            "jobs\n",
            "O*NET-SOC Code\n",
            "organizations\n",
            "job_student_edges\n",
            "supervisor_supervisee_edges\n",
            "organization_student_edges\n",
            "job_job_edges\n",
            "O*NET-SOC Code\n",
            "Title\n",
            "Related O*NET-SOC Code\n",
            "Related Title\n",
            "Relatedness Tier\n",
            "job_skill_edges\n",
            "skill\n",
            "broader_job_job_edges\n"
          ]
        }
      ],
      "source": [
        "# for all columns not in col_dte and cols_numeric and cols_id, if the column only contains 2 different values, save it to cols_binary and encode the column to 0 and 1\n",
        "cols_binary = []\n",
        "for name in df_names:\n",
        "    print(name)\n",
        "    for col in globals()[name].columns:\n",
        "        if col not in cols_dte and col not in cols_numeric and col not in cols_id:\n",
        "            if len(globals()[name][col].unique()) == 2:\n",
        "                cols_binary.append(col)\n",
        "                print('>>> binary col', col)\n",
        "                globals()[name][col] = globals()[name][col].astype('category').cat.codes\n",
        "            else:\n",
        "                print(col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "courses_and_programs\n",
            "   NOTACTIVE\n",
            "   REV_DTE\n",
            "   CREATE_DTE\n",
            "   TOTAL_RATING\n",
            "   AVG_RATING\n",
            "   CPNT_CLASSIFICATION\n",
            "   CPNT_TYP_ID\n",
            "   DMN_ID\n",
            "   CPNT_SRC_ID\n",
            "   CREDIT_HRS\n",
            "   THUMBNAIL_URI\n",
            "   TITLE\n",
            "   TITLE_TRANSLATION_NEEDED\n",
            "   DESC_TRANSLATION_NEEDED\n",
            "   DESCRIPTION\n",
            "   LEARNING_TYPE\n",
            "   REAL_ID\n",
            "   LEARNING_ITEM_ID\n",
            "qualifications\n",
            "   NOTACTIVE\n",
            "   CREATE_DTE\n",
            "   QUAL_TYP_ID\n",
            "   DMN_ID\n",
            "   TITLE\n",
            "   TITLE_TRANSLATION_NEEDED\n",
            "   DESC_TRANSLATION_NEEDED\n",
            "   DESCRIPTION\n",
            "   REAL_ID\n",
            "   LEARNING_ITEM_ID\n",
            "   QUAL_ID\n",
            "skills\n",
            "   SKILL\n",
            "qualification_skill_edges\n",
            "   Skill\n",
            "   IS_APPROXIMATE\n",
            "   LEARNING_ITEM_ID\n",
            "course_and_program_skill_edges\n",
            "   Skill\n",
            "   IS_APPROXIMATE\n",
            "   LEARNING_ITEM_ID\n",
            "course_qualification_edges\n",
            "   LEARNING_ITEM_ID\n",
            "   QUAL_ID\n",
            "course_and_programs_student_edges\n",
            "   COMPL_DTE\n",
            "   ASSGN_DTE\n",
            "   TOOK_MINUTES\n",
            "   LEARNING_ITEM_ID\n",
            "   STUD_ID\n",
            "people\n",
            "   EMP_TYP_ID\n",
            "   IS_ACTIVE_INFERRED\n",
            "   FULLTIME\n",
            "   DMN_ID\n",
            "   HIRE_DTE\n",
            "   STUD_ID\n",
            "jobs\n",
            "   TITLE\n",
            "   O*NET-SOC Code\n",
            "   ID\n",
            "organizations\n",
            "   ORG_ID\n",
            "job_student_edges\n",
            "   ONET_ID\n",
            "   STUD_ID\n",
            "supervisor_supervisee_edges\n",
            "   STUD_ID\n",
            "   SUPER_ID\n",
            "organization_student_edges\n",
            "   STUD_ID\n",
            "   ORG_ID\n",
            "job_job_edges\n",
            "   O*NET-SOC Code\n",
            "   Title\n",
            "   Related O*NET-SOC Code\n",
            "   Related Title\n",
            "   Relatedness Tier\n",
            "   SRC_ID\n",
            "   DST_ID\n",
            "job_skill_edges\n",
            "   skill\n",
            "   scaled_tfidf\n",
            "   n_jobdesc_used\n",
            "   JOB_ID\n",
            "broader_job_job_edges\n",
            "   SRC_ID\n",
            "   DST_ID\n"
          ]
        }
      ],
      "source": [
        "for name in df_names:\n",
        "    print(name)\n",
        "    for col in globals()[name].columns:\n",
        "        print('  ', col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "courses_and_programs\n",
            "DMN_ID\n",
            "courses_and_programs ['OCN' 'SCOTIABANK' 'PUBLIC' 'IB' 'SKILLSOFT' 'INACTIVE' '5065']\n",
            "qualifications\n",
            "DMN_ID\n",
            "qualifications ['SCOTIABANK' 'PUBLIC' 'IB']\n",
            "skills\n",
            "qualification_skill_edges\n",
            "course_and_program_skill_edges\n",
            "course_qualification_edges\n",
            "course_and_programs_student_edges\n",
            "people\n",
            "DMN_ID\n",
            "people ['SCOTIABANK' 'HIDDEN' 'MALAYSIA' 'PUBLIC']\n",
            "jobs\n",
            "organizations\n",
            "job_student_edges\n",
            "supervisor_supervisee_edges\n",
            "organization_student_edges\n",
            "job_job_edges\n",
            "job_skill_edges\n",
            "broader_job_job_edges\n",
            "unique domain ids {'SKILLSOFT', '5065', 'OCN', 'INACTIVE', 'IB', 'HIDDEN', 'PUBLIC', 'SCOTIABANK', 'MALAYSIA'}\n",
            "courses_and_programs\n",
            "DMN_ID\n",
            "qualifications\n",
            "DMN_ID\n",
            "skills\n",
            "qualification_skill_edges\n",
            "course_and_program_skill_edges\n",
            "course_qualification_edges\n",
            "course_and_programs_student_edges\n",
            "people\n",
            "DMN_ID\n",
            "jobs\n",
            "organizations\n",
            "job_student_edges\n",
            "supervisor_supervisee_edges\n",
            "organization_student_edges\n",
            "job_job_edges\n",
            "job_skill_edges\n",
            "broader_job_job_edges\n"
          ]
        }
      ],
      "source": [
        "unique_domains = set()\n",
        "for name in df_names:\n",
        "    print(name)\n",
        "    for col in globals()[name].columns:\n",
        "        if 'DMN_ID' in col:\n",
        "            print(col)\n",
        "            unique_domains.update(globals()[name][col].unique())\n",
        "            print(name, globals()[name][col].unique())\n",
        "            \n",
        "print('unique domain ids' , unique_domains)\n",
        "\n",
        "# create onehot mapping for all domain ids\n",
        "domain_id_to_onehot = {}\n",
        "for i, domain_id in enumerate(unique_domains):\n",
        "    onehot = [0] * len(unique_domains)\n",
        "    onehot[i] = 1\n",
        "    domain_id_to_onehot[domain_id] = onehot\n",
        "\n",
        "# for all columns, if they are DMN_ID columns, replace the column with the onehot mapping\n",
        "for name in df_names:\n",
        "    print(name)\n",
        "    for col in globals()[name].columns:\n",
        "        if 'DMN_ID' in col:\n",
        "            print(col)\n",
        "            globals()[name][col] = globals()[name][col].apply(lambda x: domain_id_to_onehot[x])\n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# in the qualification program edges, remap the qual_id to the learning item id of the qualification\n",
        "# so that we dont have to remap the skill qualification edges, which use the learning item id of the qualification\n",
        "\n",
        "qual_to_learning_id = {row.QUAL_ID:row.LEARNING_ITEM_ID for i, row in qualifications.iterrows()}\n",
        "\n",
        "\n",
        "course_qualification_edges['QUAL_LEARNING_ID'] = course_qualification_edges['QUAL_ID'].apply(lambda x: qual_to_learning_id[x])\n",
        "del course_qualification_edges['QUAL_ID'] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "courses_and_programs\n",
            ">>> remove NOTACTIVE\n",
            ">>> remove THUMBNAIL_URI\n",
            ">>> remove TITLE_TRANSLATION_NEEDED\n",
            ">>> remove"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " DESC_TRANSLATION_NEEDED\n",
            ">>> remove REAL_ID\n",
            "qualifications\n",
            ">>> remove NOTACTIVE\n",
            ">>> remove TITLE_TRANSLATION_NEEDED\n",
            ">>> remove DESC_TRANSLATION_NEEDED\n",
            ">>> remove REAL_ID\n",
            ">>> remove QUAL_ID\n",
            "skills\n",
            "qualification_skill_edges\n",
            ">>> remove IS_APPROXIMATE\n",
            "course_and_program_skill_edges\n",
            ">>> remove IS_APPROXIMATE\n",
            "course_qualification_edges\n",
            "course_and_programs_student_edges\n",
            "people\n",
            ">>> remove IS_ACTIVE_INFERRED\n",
            "jobs\n",
            ">>> remove O*NET-SOC Code\n",
            "organizations\n",
            "job_student_edges\n",
            "supervisor_supervisee_edges\n",
            "organization_student_edges\n",
            "job_job_edges\n",
            ">>> remove O*NET-SOC Code\n",
            ">>> remove Title\n",
            ">>> remove Related O*NET-SOC Code\n",
            ">>> remove Related Title\n",
            "job_skill_edges\n",
            ">>> remove n_jobdesc_used\n",
            "broader_job_job_edges\n"
          ]
        }
      ],
      "source": [
        "\n",
        "cols = {\n",
        "    'courses_and_programs': {\n",
        "        'categorical': [\n",
        "            'CPNT_TYP_ID', 'CPNT_SRC_ID', 'LEARNING_TYPE', 'CPNT_CLASSIFICATION' #, 'DMN_ID' handle dmn id separately\n",
        "        ],\n",
        "        'remove':[\n",
        "            'REAL_ID', \n",
        "            'THUMBNAIL_URI',\n",
        "            'TITLE_TRANSLATION_NEEDED',\n",
        "            'DESCRIPTION_TRANSLATION_NEEDED',\n",
        "            'DESC_TRANSLATION_NEEDED',\n",
        "            'NOTACTIVE'\n",
        "        ],\n",
        "        'text': [\n",
        "            'TITLE', 'DESCRIPTION'\n",
        "        ]\n",
        "    },\n",
        "    'qualifications': {\n",
        "        'categorical': [\n",
        "            'QUAL_TYP_ID', # 'DMN_ID' handle dmn id separately\n",
        "        ],\n",
        "        'remove':[\n",
        "            'REAL_ID', \n",
        "            'TITLE_TRANSLATION_NEEDED',\n",
        "            'DESCRIPTION_TRANSLATION_NEEDED',\n",
        "            'DESC_TRANSLATION_NEEDED',\n",
        "            'NOTACTIVE',\n",
        "            #\"LEARNING_ITEM_ID\"\n",
        "            'QUAL_ID'\n",
        "        ],\n",
        "        'text': [\n",
        "            'TITLE', 'DESCRIPTION'\n",
        "        ]\n",
        "    },\n",
        "    'skills':{\n",
        "        'text':['SKILL']\n",
        "    },\n",
        "    'jobs':{\n",
        "        'remove':[\n",
        "            'O*NET-SOC Code', \n",
        "        ],\n",
        "        'text':['TITLE']\n",
        "    },\n",
        "     'job_job_edges':{\n",
        "        'remove':[\n",
        "            'O*NET-SOC Code', \n",
        "            'Related O*NET-SOC Code',\n",
        "            'Title',\n",
        "            'Related Title'\n",
        "            \n",
        "        ],\n",
        "    },\n",
        "     'job_skill_edges':{\n",
        "        'remove':[\n",
        "            'n_jobdesc_used'\n",
        "            \n",
        "        ],\n",
        "    },\n",
        "     'qualification_skill_edges':{\n",
        "        'remove':[\n",
        "            'IS_APPROXIMATE'\n",
        "            \n",
        "        ]\n",
        "        \n",
        "    },\n",
        "      'course_and_program_skill_edges':{\n",
        "        'remove':[\n",
        "            'IS_APPROXIMATE'\n",
        "            \n",
        "        ]\n",
        "        \n",
        "    },\n",
        "      'people':{\n",
        "          'remove':['IS_ACTIVE_INFERRED'],\n",
        "          'categorical':['EMP_TYP_ID']\n",
        "      }\n",
        "    \n",
        "}\n",
        "# for all columns in cols, if the column is in the df, remove the column from the df\n",
        "for name in df_names:\n",
        "    print(name)\n",
        "    for col in globals()[name].columns:\n",
        "        if name in cols.keys() and 'remove' in cols[name].keys() and col in cols[name]['remove']:\n",
        "            print('>>> remove', col)\n",
        "            \n",
        "            globals()[name] = globals()[name].drop(col, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "courses_and_programs\n",
            ">>> categorical CPNT_CLASSIFICATION\n",
            "courses_and_programs CPNT_CLASSIFICATION categories: {'CONTINUOUS ONLINE ACCESS': [1, 0, 0, 0, 0, 0], 'TIME-BASED': [0, 1, 0, 0, 0, 0], 'EXTERNAL-COURSE': [0, 0, 1, 0, 0, 0], 'PHYSICAL GOOD': [0, 0, 0, 1, 0, 0], 'BLENDED': [0, 0, 0, 0, 1, 0], 'PROGRAM': [0, 0, 0, 0, 0, 1]}\n",
            ">>> categorical CPNT_TYP_ID\n",
            "courses_and_programs CPNT_TYP_ID categories: {'WBT': [1, 0, 0, 0, 0, 0, 0], 'ILT': [0, 1, 0, 0, 0, 0, 0], 'SKILLASSESSMENT': [0, 0, 1, 0, 0, 0, 0], 'OJT': [0, 0, 0, 1, 0, 0, 0], 'CRSE': [0, 0, 0, 0, 1, 0, 0], 'VC': [0, 0, 0, 0, 0, 1, 0], 'SYSTEM_PROGRAM_ENTITY': [0, 0, 0, 0, 0, 0, 1]}\n",
            ">>> categorical CPNT_SRC_ID\n",
            "courses_and_programs CPNT_SRC_ID categories: {'PLURALSIGHT': [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'CSI': [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'Scotiabank': [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], 'LINKEDINLEARNING': [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], 'UNKNOWN': [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], 'VIDYARD': [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], 'SkillSoft': [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], 'LINKEDINLEARNING_VIDEO': [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0], 'Berlitz': [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], 'CIFP': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], 'IFSE': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]}\n",
            ">>> categorical LEARNING_TYPE\n",
            "courses_and_programs LEARNING_TYPE categories: {'COURSE': [1, 0, 0, 0], 'OPEN_ENDED': [0, 1, 0, 0], 'DURATION_BASED': [0, 0, 1, 0], 'SCHEDULE_BASED': [0, 0, 0, 1]}\n",
            "qualifications\n",
            ">>> categorical QUAL_TYP_ID\n",
            "qualifications QUAL_TYP_ID categories: {'CERT': [1, 0, 0, 0], 'UNKNOWN': [0, 1, 0, 0], 'PROF': [0, 0, 1, 0], 'LEAD': [0, 0, 0, 1]}\n",
            "skills\n",
            "qualification_skill_edges\n",
            "course_and_program_skill_edges\n",
            "course_qualification_edges\n",
            "course_and_programs_student_edges\n",
            "people\n",
            ">>> categorical EMP_TYP_ID\n",
            "people EMP_TYP_ID categories: {'REGULAR': [1, 0, 0, 0, 0, 0, 0, 0], 'CONTRACT': [0, 1, 0, 0, 0, 0, 0, 0], 'CONTINGENT_WORKER': [0, 0, 1, 0, 0, 0, 0, 0], 'STUDENT': [0, 0, 0, 1, 0, 0, 0, 0], 'PENSION': [0, 0, 0, 0, 1, 0, 0, 0], 'CASUAL': [0, 0, 0, 0, 0, 1, 0, 0], 'UNKNOWN': [0, 0, 0, 0, 0, 0, 1, 0], 'PRENSION': [0, 0, 0, 0, 0, 0, 0, 1]}\n",
            "jobs\n",
            "organizations\n",
            "job_student_edges\n",
            "supervisor_supervisee_edges\n",
            "organization_student_edges\n",
            "job_job_edges\n",
            "job_skill_edges\n",
            "broader_job_job_edges\n"
          ]
        }
      ],
      "source": [
        "# for all dfs for all columns, if col in cols and categorical in cols[name] and col in df, convert the column to onehot categories\n",
        "onehot_and_numeric_mappings = {}\n",
        "for name in df_names:\n",
        "    print(name)\n",
        "    onehot_and_numeric_mappings[name] = {}\n",
        "    for col in globals()[name].columns:\n",
        "        if name in cols.keys() and 'categorical' in cols[name].keys() and col in cols[name]['categorical']:\n",
        "            print('>>> categorical', col)\n",
        "            unique_categories = globals()[name][col].unique()\n",
        "            to_onehot = {}\n",
        "            for i, category in enumerate(unique_categories):\n",
        "                onehot = [0] * len(unique_categories)\n",
        "                onehot[i] = 1\n",
        "                to_onehot[category] = onehot\n",
        "                \n",
        "            globals()[name][col] = globals()[name][col].apply(lambda x: to_onehot[x])\n",
        "            print(name, col, 'categories:',str(to_onehot))\n",
        "            onehot_and_numeric_mappings[name][col] = to_onehot\n",
        "            \n",
        "            \n",
        "job_job_edges['Relatedness Tier'] = job_job_edges['Relatedness Tier'].apply(lambda x: {'Primary-Short':1,'Primary-Long':0.75, 'Supplemental':0.5}[x])\n",
        "onehot_and_numeric_mappings['job_job_edges'] = {'Relatedness Tier':{'Primary-Short':1,'Primary-Long':0.75, 'Supplemental':0.5}}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for all text columns apply all-mpnet-base-v2 sentence embeddings\n",
        "# from sentence_transformers import SentenceTransformer\n",
        "# model = SentenceTransformer('all-mpnet-base-v2', device='cuda')\n",
        "# for name in df_names:\n",
        "#     print(name)\n",
        "#     for col in globals()[name].columns:\n",
        "#         if name in cols.keys() and 'text' in cols[name].keys() and col in cols[name]['text']:\n",
        "#             if col =='DESCRIPTION':\n",
        "#                 # skip \n",
        "#                 continue \n",
        "            \n",
        "#             print('>>> text col, apply mpnet', col)\n",
        "            \n",
        "#             # save to pickle and if it already exists, load from pickle \n",
        "#             pickle_path = 'final_dataset_courseprograms_joined/'+name+'_'+col+'_mpnet.pkl'\n",
        "#             if os.path.exists(pickle_path):\n",
        "#                 if col == 'TITLE':\n",
        "#                     globals()[name]['TEXT_EMBEDDING'] = pd.read_pickle(pickle_path)\n",
        "#                 else:\n",
        "#                     globals()[name][col] = pd.read_pickle(pickle_path)\n",
        "#             else:\n",
        "#                 if col == 'TITLE': # combine Title and Description\n",
        "#                     globals()[name]['TEXT_EMBEDDING'] = globals()[name]['TITLE'] + '\\n' + globals()[name]['DESCRIPTION']\n",
        "#                     globals()[name]['TEXT_EMBEDDING'] = globals()[name]['TEXT_EMBEDDING'].apply(lambda x: model.encode(x))\n",
        "#                 else:\n",
        "#                     globals()[name][col] = globals()[name][col].apply(lambda x: model.encode(x))\n",
        "                    \n",
        "#                 globals()[name][col].to_pickle(pickle_path)\n",
        "       \n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "courses_and_programs\n",
            ">>> text col, apply mpnet TITLE\n",
            "qualifications\n",
            ">>> text col, apply mpnet TITLE\n",
            "skills\n",
            ">>> text col, apply mpnet SKILL\n",
            "qualification_skill_edges\n",
            "course_and_program_skill_edges\n",
            "course_qualification_edges\n",
            "course_and_programs_student_edges\n",
            "people\n",
            "jobs\n",
            ">>> text col, apply mpnet TITLE\n",
            "organizations\n",
            "job_student_edges\n",
            "supervisor_supervisee_edges\n",
            "organization_student_edges\n",
            "job_job_edges\n",
            "job_skill_edges\n",
            "broader_job_job_edges\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from tqdm.auto import tqdm\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "model = SentenceTransformer('all-mpnet-base-v2', device='cuda')\n",
        "\n",
        "batch_size = 1000  # Specify your batch size\n",
        "\n",
        "for name in df_names:\n",
        "    print(name)\n",
        "    for col in globals()[name].columns:\n",
        "        if name in cols.keys() and 'text' in cols[name].keys() and col in cols[name]['text']:\n",
        "            if col =='DESCRIPTION':\n",
        "                # skip \n",
        "                continue \n",
        "            \n",
        "            print('>>> text col, apply mpnet', col)\n",
        "            \n",
        "            # save to pickle and if it already exists, load from pickle \n",
        "            pickle_path = 'final_dataset_courseprograms_joined/'+name+'_'+col+'_mpnet.pkl'\n",
        "            if os.path.exists(pickle_path):\n",
        "                # if col == 'TITLE':\n",
        "                #     globals()[name]['TEXT_EMBEDDING'] = pd.read_pickle(pickle_path)\n",
        "                # else:\n",
        "                globals()[name]['TEXT_EMBEDDING'] = pd.read_pickle(pickle_path)\n",
        "            else:\n",
        "                num_batches = int(np.ceil(len(globals()[name][col]) / batch_size))\n",
        "                embeddings = []\n",
        "                \n",
        "                if col == 'TITLE' and name !='jobs':\n",
        "                    texts = globals()[name]['TITLE'] + '\\n' + globals()[name]['DESCRIPTION']\n",
        "                else:\n",
        "                    texts = globals()[name][col]\n",
        "                \n",
        "                for i in tqdm(range(num_batches)):\n",
        "                    batch_texts = texts[i * batch_size: (i + 1) * batch_size]\n",
        "                    batch_embeddings = model.encode(batch_texts.tolist())\n",
        "                    embeddings.extend(batch_embeddings)\n",
        "                    \n",
        "                # if col == 'TITLE' and name !='jobs':\n",
        "                #     globals()[name]['TEXT_EMBEDDING'] = embeddings\n",
        "                # else:\n",
        "                globals()[name]['TEXT_EMBEDDING'] = embeddings\n",
        "\n",
        "                pd.to_pickle(embeddings, pickle_path)\n",
        "                \n",
        "                \n",
        "skills = skills.drop_duplicates(subset=['SKILL']) # don't want to recompute with the dropped list, so we drop afterwards"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# job job remapping\n",
        "# job skill remapping\n",
        "# job broader job remapping\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([5573066., 1804891., 1075701.,  748492.,  564394.,  447021.,\n",
              "         367442.,  309200.,  264869.,  229667.,  203534.,  181147.,\n",
              "         162844.,  148135.,  134272.,  122995.,  114135.,  105177.,\n",
              "          98376.,   90941.,   84685.,   79518.,   75446.,   70618.,\n",
              "          66815.,   63374.,   60872.,   57226.,   54737.,   52048.,\n",
              "          49551.,   47361.,   45569.,   43633.,   41795.,   40060.,\n",
              "          38525.,   37513.,   36293.,   34477.,   33413.,   32570.,\n",
              "          31486.,   30369.,   29521.,   28765.,   27656.,   27195.,\n",
              "          26320.,   25380.,   24565.,   24102.,   23328.,   23155.,\n",
              "          22205.,   21621.,   21221.,   20842.,   20127.,   19485.,\n",
              "          19331.,   18897.,   18556.,   17963.,   17568.,   17153.,\n",
              "          16632.,   16519.,   16127.,   15871.,   15590.,   15329.,\n",
              "          14853.,   14630.,   13981.,   14010.,   13784.,   13436.,\n",
              "          13464.,   13005.,   12821.,   12662.,   12371.,   12262.,\n",
              "          11688.,   11790.,   11389.,   11422.,   11226.,   10849.,\n",
              "          10939.,   10734.,   10374.,   10308.,   10201.,    9905.,\n",
              "           9804.,    9706.,    9635.,    9393.]),\n",
              " array([0.0e+00, 1.0e-06, 2.0e-06, 3.0e-06, 4.0e-06, 5.0e-06, 6.0e-06,\n",
              "        7.0e-06, 8.0e-06, 9.0e-06, 1.0e-05, 1.1e-05, 1.2e-05, 1.3e-05,\n",
              "        1.4e-05, 1.5e-05, 1.6e-05, 1.7e-05, 1.8e-05, 1.9e-05, 2.0e-05,\n",
              "        2.1e-05, 2.2e-05, 2.3e-05, 2.4e-05, 2.5e-05, 2.6e-05, 2.7e-05,\n",
              "        2.8e-05, 2.9e-05, 3.0e-05, 3.1e-05, 3.2e-05, 3.3e-05, 3.4e-05,\n",
              "        3.5e-05, 3.6e-05, 3.7e-05, 3.8e-05, 3.9e-05, 4.0e-05, 4.1e-05,\n",
              "        4.2e-05, 4.3e-05, 4.4e-05, 4.5e-05, 4.6e-05, 4.7e-05, 4.8e-05,\n",
              "        4.9e-05, 5.0e-05, 5.1e-05, 5.2e-05, 5.3e-05, 5.4e-05, 5.5e-05,\n",
              "        5.6e-05, 5.7e-05, 5.8e-05, 5.9e-05, 6.0e-05, 6.1e-05, 6.2e-05,\n",
              "        6.3e-05, 6.4e-05, 6.5e-05, 6.6e-05, 6.7e-05, 6.8e-05, 6.9e-05,\n",
              "        7.0e-05, 7.1e-05, 7.2e-05, 7.3e-05, 7.4e-05, 7.5e-05, 7.6e-05,\n",
              "        7.7e-05, 7.8e-05, 7.9e-05, 8.0e-05, 8.1e-05, 8.2e-05, 8.3e-05,\n",
              "        8.4e-05, 8.5e-05, 8.6e-05, 8.7e-05, 8.8e-05, 8.9e-05, 9.0e-05,\n",
              "        9.1e-05, 9.2e-05, 9.3e-05, 9.4e-05, 9.5e-05, 9.6e-05, 9.7e-05,\n",
              "        9.8e-05, 9.9e-05, 1.0e-04]),\n",
              " <BarContainer object of 100 artists>)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt \n",
        "# plot job_skill_edges scaled_tfidf, histogram, from 0 to 1, 100 bins\n",
        "plt.hist(job_skill_edges['scaled_tfidf'], bins=100, range=(0,0.0001))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "qualification_skill_edges\n",
            "course_and_program_skill_edges\n",
            "course_qualification_edges\n",
            "course_and_programs_student_edges\n",
            "job_student_edges\n",
            "supervisor_supervisee_edges\n",
            "organization_student_edges\n",
            "job_job_edges\n",
            "job_skill_edges\n",
            "broader_job_job_edges\n"
          ]
        }
      ],
      "source": [
        "# print all dfs in df_name if they have a name with edge in it\n",
        "for name in df_names:\n",
        "    if 'edge' in name:\n",
        "        print(name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# rename edges so we can do automatic mapping\n",
        "# for all of the below:\n",
        "# qualification_skill_edges\n",
        "# course_and_program_skill_edges\n",
        "# course_qualification_edges\n",
        "# course_and_programs_student_edges\n",
        "# job_student_edges\n",
        "# supervisor_supervisee_edges\n",
        "# organization_student_edges\n",
        "# job_job_edges\n",
        "# job_skill_edges\n",
        "# broader_job_job_edges\n",
        "# create a dictionary which has the column renamed for each df\n",
        "rename_dict = {}\n",
        "rename_dict['qualification_skill_edges'] = {'LEARNING_ITEM_ID':'qualifications_id', 'Skill':'skills_id'}\n",
        "rename_dict['course_and_program_skill_edges'] = {'Skill':'skills_id','LEARNING_ITEM_ID':'courses_and_programs_id'}\n",
        "rename_dict['course_qualification_edges'] = {'LEARNING_ITEM_ID':'courses_and_programs_id', 'QUAL_LEARNING_ID':'qualifications_id'}\n",
        "rename_dict['course_and_programs_student_edges'] = {'LEARNING_ITEM_ID':'courses_and_programs_id', 'STUD_ID':'people_id'}\n",
        "rename_dict['job_student_edges'] = {'ONET_ID':'jobs_id','STUD_ID':'people_id'}\n",
        "rename_dict['supervisor_supervisee_edges'] = {'STUD_ID':'people_id1', 'SUPER_ID':'people_id2'}\n",
        "rename_dict['organization_student_edges'] = {'ORG_ID':'organizations_id', 'STUD_ID':'people_id'}\n",
        "rename_dict['job_job_edges'] = {'SRC_ID':'jobs_id1','DST_ID':'jobs_id2'}\n",
        "rename_dict['job_skill_edges'] = {'skill':'skills_id','JOB_ID':'jobs_id'}\n",
        "rename_dict['broader_job_job_edges'] = {'SRC_ID':'jobs_id1','DST_ID':'jobs_id2'}\n",
        "\n",
        "# same for the node dfs\n",
        "rename_dict['courses_and_programs'] = {'LEARNING_ITEM_ID':'courses_and_programs_id'}\n",
        "rename_dict['qualifications'] = {'LEARNING_ITEM_ID':'qualifications_id'}\n",
        "#rename_dict['skills'] = {'SKILL':'skills_id'}\n",
        "rename_dict['jobs'] = {'ID':'jobs_id'}\n",
        "rename_dict['people'] = {'STUD_ID':'people_id'}\n",
        "rename_dict['organizations'] = {'ORG_ID':'organizations_id'}\n",
        "\n",
        "\n",
        "# rename all the columns correspondingly\n",
        "for name in df_names:\n",
        "    if name in rename_dict.keys():\n",
        "        globals()[name] = globals()[name].rename(columns=rename_dict[name])\n",
        "        \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "qualification_skill_edges\n",
            "Index(['skills_id', 'qualifications_id'], dtype='object')\n",
            "course_and_program_skill_edges\n",
            "Index(['skills_id', 'courses_and_programs_id'], dtype='object')\n",
            "course_qualification_edges\n",
            "Index(['courses_and_programs_id', 'qualifications_id'], dtype='object')\n",
            "course_and_programs_student_edges\n",
            "Index(['COMPL_DTE', 'ASSGN_DTE', 'TOOK_MINUTES', 'courses_and_programs_id',\n",
            "       'people_id'],\n",
            "      dtype='object')\n",
            "job_student_edges\n",
            "Index(['jobs_id', 'people_id'], dtype='object')\n",
            "supervisor_supervisee_edges\n",
            "Index(['people_id1', 'people_id2'], dtype='object')\n",
            "organization_student_edges\n",
            "Index(['people_id', 'organizations_id'], dtype='object')\n",
            "job_job_edges\n",
            "Index(['Relatedness Tier', 'jobs_id1', 'jobs_id2'], dtype='object')\n",
            "job_skill_edges\n",
            "Index(['skills_id', 'scaled_tfidf', 'jobs_id'], dtype='object')\n",
            "broader_job_job_edges\n",
            "Index(['jobs_id1', 'jobs_id2'], dtype='object')\n"
          ]
        }
      ],
      "source": [
        "# print out columns for all edge types:\n",
        "for name in df_names:\n",
        "    if 'edge' in name:\n",
        "        print(name)\n",
        "        print(globals()[name].columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "qualification_skill_edges\n",
            "course_and_program_skill_edges\n",
            "job_skill_edges\n"
          ]
        }
      ],
      "source": [
        "# in the skills df, rename the SKILL column to skill_id and create a mapping which maps the skill to the skill_id\n",
        "# add the mapping to the onehot_and_numeric_mappings\n",
        "# change the values in the skill_id column to the skill_id mapping\n",
        "# add the original skill name as TITLE\n",
        "if 'skills' in onehot_and_numeric_mappings.keys() and 'skills_id' not in onehot_and_numeric_mappings['skills'].keys() or 'skills' not in onehot_and_numeric_mappings.keys():\n",
        "    skills = skills.rename(columns={'SKILL':'skills_id'})\n",
        "    skills['TITLE'] = skills['skills_id']\n",
        "    skill_to_skill_id = {}\n",
        "    for i, skill in enumerate(skills['skills_id'].unique()):\n",
        "        skill_to_skill_id[skill] = i+1\n",
        "    skills['skills_id'] = skills['skills_id'].apply(lambda x: skill_to_skill_id[x])\n",
        "    onehot_and_numeric_mappings['skills'] = {'skills_id':skill_to_skill_id}\n",
        "\n",
        "# for all edge dfs in df_names, if the df has a column called skill_id, change the values in the skill_id column to the skill_id mapping\n",
        "for name in df_names:\n",
        "    if 'edge' in name:\n",
        "        if 'skills_id' in globals()[name].columns:\n",
        "            print(name)\n",
        "            globals()[name]['skills_id'] = globals()[name]['skills_id'].apply(lambda x: skill_to_skill_id[x])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "courses_and_programs\n",
            "qualifications\n",
            "skills\n",
            "qualification_skill_edges\n",
            "qualification_skill_edges\n",
            "course_and_program_skill_edges\n",
            "course_and_program_skill_edges\n",
            "course_qualification_edges\n",
            "course_qualification_edges\n",
            "course_and_programs_student_edges\n",
            "course_and_programs_student_edges\n",
            "people\n",
            "jobs\n",
            "organizations\n",
            "job_student_edges\n",
            "job_student_edges\n",
            "supervisor_supervisee_edges\n",
            "supervisor_supervisee_edges\n",
            "organization_student_edges\n",
            "organization_student_edges\n",
            "job_job_edges\n",
            "job_job_edges\n",
            "job_skill_edges\n",
            "job_skill_edges\n",
            "broader_job_job_edges\n",
            "broader_job_job_edges\n"
          ]
        }
      ],
      "source": [
        "# substract 1 from each id column\n",
        "# for all df_names, if the df has a column called id, substract 1 from the column\n",
        "if 'runonce1' not in globals().keys():\n",
        "    runonce1 = True\n",
        "    for name in df_names:\n",
        "        #if 'edge' in name:\n",
        "        if 'skills_id' in globals()[name].columns:\n",
        "            print(name)\n",
        "            globals()[name]['skills_id'] = globals()[name]['skills_id'] - 1\n",
        "        if 'qualifications_id' in globals()[name].columns:\n",
        "            print(name)\n",
        "            globals()[name]['qualifications_id'] = globals()[name]['qualifications_id'] - 1\n",
        "#        if name =='qualification_skill_edges':\n",
        "#            globals()[name]['LEARNING_ITEM_ID'] =  globals()[name]['LEARNING_ITEM_ID'] - 1\n",
        "        if 'courses_and_programs_id' in globals()[name].columns:\n",
        "            print(name)\n",
        "            globals()[name]['courses_and_programs_id'] = globals()[name]['courses_and_programs_id'] - 1\n",
        "        if 'jobs_id' in globals()[name].columns:\n",
        "            print(name)\n",
        "            globals()[name]['jobs_id'] = globals()[name]['jobs_id'] - 1\n",
        "        if 'jobs_id1' in globals()[name].columns:\n",
        "            print(name)\n",
        "            globals()[name]['jobs_id1'] = globals()[name]['jobs_id1'] - 1\n",
        "        if 'jobs_id2' in globals()[name].columns:\n",
        "            print(name)\n",
        "            globals()[name]['jobs_id2'] = globals()[name]['jobs_id2'] - 1\n",
        "        if 'people_id' in globals()[name].columns:\n",
        "            print(name)\n",
        "            globals()[name]['people_id'] = globals()[name]['people_id'] - 1\n",
        "        if 'people_id1' in globals()[name].columns:\n",
        "            print(name)\n",
        "            globals()[name]['people_id1'] = globals()[name]['people_id1'] - 1\n",
        "        if 'people_id2' in globals()[name].columns:\n",
        "            print(name)\n",
        "            globals()[name]['people_id2'] = globals()[name]['people_id2'] - 1\n",
        "        if 'organizations_id' in globals()[name].columns:\n",
        "            print(name)\n",
        "            globals()[name]['organizations_id'] = globals()[name]['organizations_id'] - 1\n",
        "\n",
        "    # do the same for people, skills, jobs, organizations, qualifications, courses_and_programs\n",
        "    # up top\n",
        "\n",
        "                \n",
        "    # people['people_id'] = people['people_id'] - 1\n",
        "    # skills['skills_id'] = skills['skills_id'] - 1\n",
        "    # jobs['jobs_id1'] = jobs['jobs_id1'] - 1\n",
        "    # jobs['jobs_id2'] = jobs['jobs_id2'] - 1\n",
        "    # organizations['organizations_id'] = organizations['organizations_id'] - 1\n",
        "    # qualifications['qualifications_id'] = qualifications['qualifications_id'] - 1\n",
        "    # #qualifications['LEARNING_ITEM_ID' ] = qualifications['LEARNING_ITEM_ID'] - 1\n",
        "    # courses_and_programs['courses_and_programs_id'] = courses_and_programs['courses_and_programs_id'] - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "courses_and_programs\n",
            ">>>  REV_DTE number\n",
            "     <class 'numpy.float64'>\n",
            ">>>  CREATE_DTE number\n",
            "     <class 'numpy.float64'>\n",
            ">>>  TOTAL_RATING number\n",
            "     <class 'numpy.float64'>\n",
            ">>>  AVG_RATING number\n",
            "     <class 'numpy.float64'>\n",
            ">>>  CPNT_CLASSIFICATION list\n",
            "     6\n",
            ">>>  CPNT_TYP_ID list\n",
            "     7\n",
            ">>>  DMN_ID list\n",
            "     9\n",
            ">>>  CPNT_SRC_ID list\n",
            "     11\n",
            ">>>  CREDIT_HRS number\n",
            "     <class 'numpy.float64'>\n",
            ">>>  TITLE text\n",
            "     <class 'str'>\n",
            ">>>  DESCRIPTION text\n",
            "     <class 'str'>\n",
            ">>>  LEARNING_TYPE list\n",
            "     4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_7590/1147001284.py:24: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)\n",
            "  temp_obj = torch.tensor(globals()[name][col].to_numpy().tolist())\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>>  TEXT_EMBEDDING list\n",
            "     768\n",
            "=== torch.Size([65455, 810])\n",
            "qualifications\n",
            ">>>  CREATE_DTE number\n",
            "     <class 'numpy.float64'>\n",
            ">>>  QUAL_TYP_ID list\n",
            "     4\n",
            ">>>  DMN_ID list\n",
            "     9\n",
            ">>>  TITLE text\n",
            "     <class 'str'>\n",
            ">>>  DESCRIPTION text\n",
            "     <class 'str'>\n",
            ">>>  TEXT_EMBEDDING list\n",
            "     768\n",
            "=== torch.Size([1475, 782])\n",
            "skills\n",
            ">>>  TEXT_EMBEDDING list\n",
            "     768\n",
            ">>>  TITLE text\n",
            "     <class 'str'>\n",
            "=== torch.Size([860483, 768])\n",
            "people\n",
            ">>>  EMP_TYP_ID list\n",
            "     8\n",
            ">>>  FULLTIME number\n",
            "     <class 'numpy.int8'>\n",
            ">>>  DMN_ID list\n",
            "     9\n",
            ">>>  HIRE_DTE number\n",
            "     <class 'numpy.float64'>\n",
            "=== torch.Size([293444, 19])\n",
            "jobs\n",
            ">>>  TITLE text\n",
            "     <class 'str'>\n",
            ">>>  TEXT_EMBEDDING list\n",
            "     768\n",
            "=== torch.Size([55653, 768])\n",
            "organizations\n",
            "qualification_skill_edges\n",
            "Index(['skills_id', 'qualifications_id'], dtype='object')\n",
            "qualification_skill_edges ('skills', 'qualification_skill', 'qualifications')\n",
            ">>> edge_index ['skills_id', 'qualifications_id']\n",
            ">>> edge_attr []\n",
            "course_and_program_skill_edges\n",
            "Index(['skills_id', 'courses_and_programs_id'], dtype='object')\n",
            "course_and_program_skill_edges ('skills', 'course_and_program_skill', 'courses_and_programs')\n",
            ">>> edge_index ['skills_id', 'courses_and_programs_id']\n",
            ">>> edge_attr []\n",
            "course_qualification_edges\n",
            "Index(['courses_and_programs_id', 'qualifications_id'], dtype='object')\n",
            "course_qualification_edges ('courses_and_programs', 'course_qualification', 'qualifications')\n",
            ">>> edge_index ['courses_and_programs_id', 'qualifications_id']\n",
            ">>> edge_attr []\n",
            "course_and_programs_student_edges\n",
            "Index(['COMPL_DTE', 'ASSGN_DTE', 'TOOK_MINUTES', 'courses_and_programs_id',\n",
            "       'people_id'],\n",
            "      dtype='object')\n",
            "course_and_programs_student_edges ('courses_and_programs', 'course_and_programs_student', 'people')\n",
            ">>> edge_index ['courses_and_programs_id', 'people_id']\n",
            ">>> edge_attr ['COMPL_DTE', 'ASSGN_DTE', 'TOOK_MINUTES']\n",
            "job_student_edges\n",
            "Index(['jobs_id', 'people_id'], dtype='object')\n",
            "job_student_edges ('jobs', 'job_student', 'people')\n",
            ">>> edge_index ['jobs_id', 'people_id']\n",
            ">>> edge_attr []\n",
            "supervisor_supervisee_edges\n",
            "Index(['people_id1', 'people_id2'], dtype='object')\n",
            "supervisor_supervisee_edges ('people', 'supervisor_supervisee', 'people')\n",
            ">>> edge_index ['people_id1', 'people_id2']\n",
            ">>> edge_attr []\n",
            "organization_student_edges\n",
            "Index(['people_id', 'organizations_id'], dtype='object')\n",
            "organization_student_edges ('people', 'organization_student', 'organizations')\n",
            ">>> edge_index ['people_id', 'organizations_id']\n",
            ">>> edge_attr []\n",
            "job_job_edges\n",
            "Index(['Relatedness Tier', 'jobs_id1', 'jobs_id2'], dtype='object')\n",
            "job_job_edges ('jobs', 'job_job', 'jobs')\n",
            ">>> edge_index ['jobs_id1', 'jobs_id2']\n",
            ">>> edge_attr ['Relatedness Tier']\n",
            "job_skill_edges\n",
            "Index(['skills_id', 'scaled_tfidf', 'jobs_id'], dtype='object')\n",
            "job_skill_edges ('skills', 'job_skill', 'jobs')\n",
            ">>> edge_index ['skills_id', 'jobs_id']\n",
            ">>> edge_attr ['scaled_tfidf']\n",
            "broader_job_job_edges\n",
            "Index(['jobs_id1', 'jobs_id2'], dtype='object')\n",
            "broader_job_job_edges ('jobs', 'broader_job_job', 'jobs')\n",
            ">>> edge_index ['jobs_id1', 'jobs_id2']\n",
            ">>> edge_attr []\n"
          ]
        }
      ],
      "source": [
        "from torch_geometric.data import HeteroData\n",
        "import torch\n",
        "data = HeteroData()\n",
        "\n",
        "# for all dfs which have no \"edges\" in the name, add the df to the data object as a node, but ignore all columns containing id or ID\n",
        "for name in df_names:\n",
        "    if 'edge' not in name:\n",
        "        for col in globals()[name].columns:\n",
        "            if col.endswith('_id'):\n",
        "                # sort by the id column\n",
        "                globals()[name] = globals()[name].sort_values(by=[col])\n",
        "        \n",
        "for name in df_names:\n",
        "    if 'edge' not in name:\n",
        "        \n",
        "            \n",
        "            tensor_obj = None\n",
        "            print(name)\n",
        "            \n",
        "            for col in globals()[name].columns:\n",
        "                \n",
        "                if '_id' not in col: # lowercase only!\n",
        "                    if type(globals()[name][col].values[0]) == np.ndarray or type(globals()[name][col].values[0]) == list:\n",
        "                        temp_obj = torch.tensor(globals()[name][col].to_numpy().tolist())\n",
        "                        print('>>> ', col, 'list')\n",
        "                        print('    ', len(globals()[name][col].values[0]))\n",
        "                    elif type(globals()[name][col].values[0]) == str:\n",
        "                        data[name][col] = globals()[name][col].values\n",
        "                        print('>>> ', col, 'text')\n",
        "                        print('    ', type(globals()[name][col].values[0]))\n",
        "                        continue # important\n",
        "                        \n",
        "                    else:\n",
        "                        temp_obj = torch.tensor(globals()[name][col].values).reshape(-1,1)\n",
        "                        print('>>> ', col, 'number')\n",
        "                        print('    ', type(globals()[name][col].values[0]))\n",
        "                        \n",
        "                    if tensor_obj is None:\n",
        "                        tensor_obj = temp_obj\n",
        "                    else:\n",
        "                        tensor_obj = torch.cat((tensor_obj, temp_obj), dim=1)\n",
        "                    \n",
        "            \n",
        "            \n",
        "            if tensor_obj is not None:\n",
        "                print('===', tensor_obj.shape)\n",
        "                data[name].x = tensor_obj\n",
        "            else:\n",
        "                data[name].num_nodes = globals()[name].shape[0]\n",
        "\n",
        "# for all edge dfs, take the two columns with _id in name and add them as edge to the data object\n",
        "for name in df_names:\n",
        "    if 'edge' in name:\n",
        "        print(name)\n",
        "        print(globals()[name].columns)\n",
        "        edge_cols = []\n",
        "        non_id_cols = []\n",
        "        for col in globals()[name].columns:\n",
        "            if '_id' in col:\n",
        "                edge_cols.append(col)\n",
        "            else:\n",
        "                non_id_cols.append(col)\n",
        "                \n",
        "        assert len(edge_cols) == 2, f'{name} needs 2 _id cols'\n",
        "        col_name = edge_cols[0].replace('_id1','').replace('_id2','').replace('_id',''), name.replace('_edges',''), edge_cols[1].replace('_id1','').replace('_id2','').replace('_id','')\n",
        "        print(name, col_name)\n",
        "        data[col_name].edge_index = torch.tensor(globals()[name][edge_cols].to_numpy().T)\n",
        "        if len(non_id_cols):\n",
        "            data[col_name].edge_attr = torch.tensor(globals()[name][non_id_cols].to_numpy())\n",
        "            \n",
        "        print('>>> edge_index', edge_cols)\n",
        "        print('>>> edge_attr', non_id_cols)\n",
        "        \n",
        "        \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "('skills', 'qualification_skill', 'qualifications')\n",
            "\n",
            "('skills', 'course_and_program_skill', 'courses_and_programs')\n",
            "\n",
            "('courses_and_programs', 'course_qualification', 'qualifications')\n",
            "\n",
            "('courses_and_programs', 'course_and_programs_student', 'people')\n",
            "\n",
            "('jobs', 'job_student', 'people')\n",
            "\n",
            "('people', 'supervisor_supervisee', 'people')\n",
            "\n",
            "('people', 'organization_student', 'organizations')\n",
            "\n",
            "('jobs', 'job_job', 'jobs')\n",
            "\n",
            "('skills', 'job_skill', 'jobs')\n",
            "\n",
            "('jobs', 'broader_job_job', 'jobs')\n"
          ]
        }
      ],
      "source": [
        "for typ in data.edge_types:\n",
        "    print()\n",
        "    print(typ)\n",
        "    continue  \n",
        "    for i in range(10000):\n",
        "        \n",
        "        a = data[typ].edge_index[0,i]\n",
        "        b = data[typ].edge_index[1,i]\n",
        "        if 'TITLE' in data[typ[0]].keys():\n",
        "            print(typ[0], data[typ[0]].TITLE[a])\n",
        "        if 'DESCRIPTION' in data[typ[0]].keys():\n",
        "            print(typ[0], data[typ[0]].DESCRIPTION[a])\n",
        "            \n",
        "            \n",
        "        print(typ[2])\n",
        "        if 'TITLE' in data[typ[2]].keys():\n",
        "            print(typ[2], data[typ[2]].TITLE[b])\n",
        "        if 'DESCRIPTION' in data[typ[2]].keys():\n",
        "            print(typ[2], data[typ[2]].DESCRIPTION[b])\n",
        "        \n",
        "        print('---')\n",
        "        \n",
        "        \n",
        "    print('======')\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(False, True)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.has_self_loops(), data.has_isolated_nodes()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch_geometric.transforms as T\n",
        "\n",
        "transform = T.Compose([\n",
        "       T.RemoveIsolatedNodes(),\n",
        "       T.ToUndirected(merge=False), # don't merge reversed edges into the original edge type\n",
        "       T.RemoveDuplicatedEdges(),\n",
        "       \n",
        "])\n",
        "\n",
        "data = transform(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "idx = data[('courses_and_programs', 'course_and_programs_student', 'people')].edge_index\n",
        "unique_rows, counts = np.unique(idx.T, axis=0, return_counts=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "175"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "counts[np.where(counts>1)[0]].sum()  - np.where(counts>1)[0].shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# gc collect\n",
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('skills', 'qualification_skill', 'qualifications')\n",
            "torch.Size([2, 1596])\n",
            "torch.Size([2, 1598])\n",
            "---\n",
            "('skills', 'course_and_program_skill', 'courses_and_programs')\n",
            "torch.Size([2, 258099])\n",
            "torch.Size([2, 260364])\n",
            "---\n",
            "('courses_and_programs', 'course_qualification', 'qualifications')\n",
            "torch.Size([2, 2099])\n",
            "torch.Size([2, 2099])\n",
            "---\n",
            "('courses_and_programs', 'course_and_programs_student', 'people')\n",
            "torch.Size([2, 553454])\n",
            "torch.Size([2, 553629])\n",
            "---\n",
            "('jobs', 'job_student', 'people')\n",
            "torch.Size([2, 293444])\n",
            "torch.Size([2, 293444])\n",
            "---\n",
            "('people', 'supervisor_supervisee', 'people')\n",
            "torch.Size([2, 217922])\n",
            "torch.Size([2, 217922])\n",
            "---\n",
            "('people', 'organization_student', 'organizations')\n",
            "torch.Size([2, 292060])\n",
            "torch.Size([2, 292060])\n",
            "---\n",
            "('jobs', 'job_job', 'jobs')\n",
            "torch.Size([2, 18384])\n",
            "torch.Size([2, 18384])\n",
            "---\n",
            "('skills', 'job_skill', 'jobs')\n",
            "torch.Size([2, 16289586])\n",
            "torch.Size([2, 16289586])\n",
            "---\n",
            "('jobs', 'broader_job_job', 'jobs')\n",
            "torch.Size([2, 54586])\n",
            "torch.Size([2, 54586])\n",
            "---\n",
            "courses_and_programs\n",
            "55796\n",
            "65455\n",
            "---\n",
            "qualifications\n",
            "1242\n",
            "1475\n",
            "---\n",
            "skills\n",
            "138698\n",
            "860483\n",
            "---\n",
            "people\n",
            "293444\n",
            "293444\n",
            "---\n",
            "jobs\n",
            "55638\n",
            "55653\n",
            "---\n",
            "organizations\n",
            "13613\n",
            "13613\n",
            "---\n"
          ]
        }
      ],
      "source": [
        "for edge_type in data.edge_types:\n",
        "    print(edge_type)\n",
        "    print(dataT[edge_type].edge_index.shape)\n",
        "    print(data[edge_type].edge_index.shape)\n",
        "    print('---')\n",
        "\n",
        "for node_type in data.node_types:\n",
        "    print(node_type)\n",
        "    print(dataT[node_type].num_nodes)\n",
        "    print(data[node_type].num_nodes)\n",
        "    print('---')\n",
        "    \n",
        "# ignore the ones where we have duplicate edge, idk why they are there\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# add features:\n",
        "# node degrees\n",
        "from torch_geometric.utils import to_dense_adj, degree\n",
        "degrees = {}\n",
        "for node_type in data.node_types:\n",
        "    degrees[node_type] = {}\n",
        "    \n",
        "for edge_type in data.edge_types:\n",
        "    if edge_type[0] == edge_type[2]:\n",
        "        degrees[edge_type[0]][edge_type] = degree(data[edge_type].edge_index.flatten(), num_nodes=data[edge_type[0]].num_nodes)\n",
        "    else:\n",
        "        degrees[edge_type[0]][edge_type] = degree(data[edge_type].edge_index[0], num_nodes=data[edge_type[0]].num_nodes)\n",
        "        degrees[edge_type[2]][edge_type] = degree(data[edge_type].edge_index[1], num_nodes=data[edge_type[2]].num_nodes)\n",
        "\n",
        "# for each node type, add the degrees of all edge types and append it as 'total_degree' to the degrees dict\n",
        "for node_type in data.node_types:\n",
        "    degrees[node_type]['total_degree'] = torch.zeros(data[node_type].num_nodes)\n",
        "    for edge_type in degrees[node_type]:\n",
        "        if edge_type != 'total_degree':\n",
        "            degrees[node_type]['total_degree'] += degrees[node_type][edge_type] \n",
        "\n",
        "# for each node type print degree statistics for each edge type, and the total degree, max, min, mean, median. Also make a small degree plot\n",
        "for node_type in data.node_types:\n",
        "    print(node_type)\n",
        "    # create empty torch array with length of nodes\n",
        "    node_degrees = None\n",
        "    \n",
        "    for edge_type in degrees[node_type]:\n",
        "        print(edge_type, \n",
        "              'mean',degrees[node_type][edge_type].mean()'\\nstd',degrees[node_type][edge_type].std(), '\\nmedian',degrees[node_type][edge_type].median(),'\\nmax', degrees[node_type][edge_type].max(),'\\nmin', degrees[node_type][edge_type].min())\n",
        "        print('We normalize by max degree')\n",
        "        #smaller figure\n",
        "        plt.figure(figsize=(3,3))\n",
        "        x = degrees[node_type]['total_degree'].numpy()\n",
        "        plt.hist(x, bins=100);\n",
        "        plt.title(str(node_type) +' '+str(edge_type));\n",
        "        plt.xlim(0,x.max())\n",
        "        plt.show();\n",
        "        maximum = degrees[node_type][edge_type].max()\n",
        "        if node_degrees is None:\n",
        "            node_degrees = (degrees[node_type][edge_type]/maximum).unsqueeze(1)\n",
        "        else:\n",
        "            node_degrees = torch.cat((node_degrees, (degrees[node_type][edge_type]/maximum)).unsqueeze(1), dim=1)\n",
        "            \n",
        "        print('node degree shape',node_type, node_degrees.shape)\n",
        "    \n",
        "    data[node_type].x = torch.cat((data[node_type].x, node_degrees), dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch_sparse import SparseTensor\n",
        "from tqdm.auto import tqdm\n",
        "import torch\n",
        "import gc\n",
        "from torch_geometric.utils import is_undirected\n",
        "\n",
        "\n",
        "def triangle_count(adj_matrix:SparseTensor):\n",
        "    # block wise triangle count, to avoid memory issues\n",
        "    diags = []\n",
        "    \n",
        "    row_block_size = 50\n",
        "    rows = adj_matrix.size(0)\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device(\"cuda\")\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "    print('using',device)\n",
        "    with torch.no_grad():\n",
        "        \n",
        "        adj_matrix = adj_matrix.to(device)\n",
        "        for block in tqdm(range(0,rows, row_block_size), desc='blockwise sparse matrix-multiplication'):\n",
        "            torch.cuda.empty_cache()\n",
        "            gc.collect()\n",
        "            start = block\n",
        "            end = min(block+row_block_size, rows)\n",
        "            adj_pow_3_block = adj_matrix[start:end].spspmm(adj_matrix).spspmm(adj_matrix)\n",
        "            diag_block = get_diag(adj_pow_3_block[:,start:]).cpu()\n",
        "            diags.append(diag_block)\n",
        "\n",
        "    \n",
        "    return 1/2 * torch.cat(diags, dim=0)\n",
        "        \n",
        "from torch_geometric.utils import to_undirected\n",
        "from torch_sparse import SparseTensor\n",
        "from torch_sparse.diag import get_diag\n",
        "\n",
        "def undirected_triangle_counts(edge_index, max_num_nodes): \n",
        "    \"\"\"Get triangles **per node**, to get count for whole graph, divide by 3\"\"\"\n",
        "    \n",
        "    if not is_undirected(edge_index):\n",
        "        print('converting edge index to undirected')\n",
        "        edge_index = to_undirected(edge_index)\n",
        "    \n",
        "    adj_matrix = SparseTensor(row=edge_index[0], col=edge_index[1], value=torch.ones(ud[1].shape[0]), sparse_sizes=(max_num_nodes, max_num_nodes))\n",
        "    triangles = triangle_count(adj_matrix) \n",
        "    return triangles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for edge types where both ends are the same node type, add the triangle count for the node\n",
        "\n",
        "for edge_type in edge_types:\n",
        "    if edge_type[0] == edge_type[2]:\n",
        "        print('add triangles to', edge_type[0])\n",
        "        triangles = undirected_triangle_counts(data[edge_type].edge_index, data[edge_type[0]].num_nodes)\n",
        "        print(edge_type[0], 'triangles', '\\nmean' triangles.mean(),'\\nstd', triangles.std(), '\\nmedian',triangles.median(), '\\nmax',triangles.max(), '\\nmin',triangles.min())\n",
        "        data[edge_type[0]].x = torch.cat([data[edge_type[0]].x, triangles.unsqueeze(1)], dim=1)\n",
        "    \n",
        "\n",
        "print('add homogeneous triangles')\n",
        "homogeneous_data = data.to_homogeneous()\n",
        "homogenous_triangles = undirected_triangle_counts(homogeneous_data.edge_index, homogeneous_data.num_nodes)\n",
        "print('homogeneous triangles', '\\nmean' homogenous_triangles.mean(),'\\nstd', homogenous_triangles.std(), '\\nmedian',homogenous_triangles.median(), '\\nmax',homogenous_triangles.max(), '\\nmin',homogenous_triangles.min())\n",
        "\n",
        "for i in range(len(data.node_types)):\n",
        "    mask =  homogeneous_data.node_type == i\n",
        "    data[node_type].x = torch.cat([data[node_type].x, homogenous_triangles[mask].unsqueeze(1)], dim=1)\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch_geometric.data import HeteroData\n",
        "\n",
        "\n",
        "filename = 'HeteroData_Learnings_v1.pt'\n",
        "if os.path.exists('./'+filename):\n",
        "    # data = HeteroData.from_dict(torch.load('./'+filename))\n",
        "    raise Exception('File already exists')\n",
        "else:\n",
        "    torch.save(dataT.to_dict(), './'+filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# END\n",
        "\n",
        "wadawdwa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data['courses_and_programs']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# drop all text columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.HGTConv.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "wdwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch_geometric.data import HeteroData\n",
        "import torch\n",
        "\n",
        "data = HeteroData()\n",
        "data['Skill'].x = torch.tensor(skill_sbert_embeddings)\n",
        "data['Job'].x = torch.tensor(job_sbert_embeddings)\n",
        "\n",
        "data['Job','REQUIRES','Skill'].edge_index = torch.tensor(skill_job_edges[['job_src','skill_dst']].to_numpy().T)\n",
        "data['Skill','IS_SIMILAR_SKILL','Skill'].edge_index = torch.tensor(skill_skill_edges[['skill_src','skill_dst']].to_numpy().T)\n",
        "data['Job','IS_SIMILAR_JOB','Job'].edge_index = torch.tensor(job_job_edges[['job_src','job_dst']].to_numpy().T)\n",
        "\n",
        "\n",
        "data['Job','REQUIRES','Skill'].edge_weight = torch.tensor(skill_job_edges['normalized_tfidf']).to(torch.float)\n",
        "data['Skill','IS_SIMILAR_SKILL','Skill'].edge_weight = torch.tensor(skill_skill_edges['cosine_sim_score'].to_numpy()).to(torch.float)\n",
        "data['Job','IS_SIMILAR_JOB','Job'].edge_weight = torch.tensor(job_job_edges['relatedness_weight'].to_numpy()).to(torch.float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCzFw-fn9udY"
      },
      "outputs": [],
      "source": [
        "# map 3,6,7,3,3,... to 1,2,3,1,1 ...\n",
        "skillmapping ={}\n",
        "for i,skill in enumerate(skill_nodes.skill.unique()):\n",
        "    skillmapping[skill] =i\n",
        "\n",
        "jobmapping ={}\n",
        "jobmapping_index_to_title_alttile = {}\n",
        "for i, index in enumerate(job_nodes['index'].unique()):\n",
        "    jobmapping[index] =i\n",
        "\n",
        "for _, row in job_nodes.iterrows():\n",
        "    if type(row['Title']) == str:\n",
        "        a = row['Title']\n",
        "    else:\n",
        "        a = ''\n",
        "    \n",
        "    jobmapping_index_to_title_alttile[row['index']] = (a+' / '+row['Alternate Title']).strip('/')\n",
        "\n",
        "inverted_skillmapping = {v:k for k,v in skillmapping.items()}\n",
        "inverted_jobmapping = {v:k for k,v in jobmapping.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHirmQzn9udY"
      },
      "outputs": [],
      "source": [
        "skill_job_edges['skill_dst'] = skill_job_edges['skill'].apply(lambda x:skillmapping[x])\n",
        "skill_job_edges['job_src'] = skill_job_edges['alt_title'].apply(lambda x:jobmapping[x])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# normalization and removal of job-skill edges\n",
        "# first group by jobs and limit the skills for each job to 175\n",
        "# then normalize those tfidf edgeweights\n",
        "# then group by skill and limit edges to 125 for skills (ordered by normalized tf-idf)\n",
        "skill_job_edges = skill_job_edges.groupby('job_src').apply(lambda group: group.nlargest(200,'scaled_tfidf')).reset_index(drop=True)\n",
        "summed_tfidf_per_job = skill_job_edges.groupby('job_src').sum()\n",
        "skill_job_edges['sum'] = skill_job_edges['job_src'].apply(lambda x: summed_tfidf_per_job.loc[x]['scaled_tfidf'])\n",
        "skill_job_edges['normalized_tfidf'] =  skill_job_edges['scaled_tfidf']/skill_job_edges['sum']\n",
        "skill_job_edges = skill_job_edges.groupby('skill_dst').apply(lambda group: group.nlargest(200,'normalized_tfidf')).reset_index(drop=True)\n",
        "# we dont do the second round of normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# normalization and removing of skill-skill edges\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "#for each alt title select the first 125 skill_job edges, ordered by tfidf\n",
        "# skill_job_edges = skill_job_edges.groupby('job_src')\n",
        "# skill_job_edges = skill_job_edges.groupby('job_src').apply(lambda group: group.nlargest(125,'scaled_tfidf')).reset_index(drop=True)\n",
        "\n",
        "# for each skill only use the 125 edges with the highest tf-idf score\n",
        "#skill_job_edges = skill_job_edges.groupby('skill').apply(lambda group: group.nlargest(125,'scaled_tfidf')).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "skill_job_edges"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Yfi1fRd9udY"
      },
      "outputs": [],
      "source": [
        "onet_alttitles = pd.read_csv('neo4jgraph/onet_alt_titles_unique.csv')\n",
        "del onet_alttitles['Unnamed: 0']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8FgE8nyo9udY"
      },
      "outputs": [],
      "source": [
        "onet_alttitle_str_mapping = {}\n",
        "for i,row in onet_alttitles.iterrows():\n",
        "    onet_alttitle_str_mapping[row['index']] = row['Alternate Title']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "mappings = {\n",
        "    'onet_alttitle_str_mapping':onet_alttitle_str_mapping,\n",
        "    'skillmapping':skillmapping,\n",
        "    'inverted_skillmapping':inverted_skillmapping,\n",
        "    'jobmapping':jobmapping,\n",
        "    'inverted_jobmapping':inverted_jobmapping,\n",
        "    'jobmapping_index_to_title_alttile':jobmapping_index_to_title_alttile\n",
        "}\n",
        "\n",
        "torch.save(mappings, 'Job_Skill_HeteroData_name_mappings_withdupes_fulldataset_v2.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(jobmapping.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E1_J7gV59udY"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vK1p6Rf-9udZ"
      },
      "outputs": [],
      "source": [
        "skill_sbert_embeddings = embedder.encode(skill_nodes['skill'].tolist(), convert_to_numpy=True, device='cuda')\n",
        "job_sbert_embeddings = embedder.encode(job_nodes['Alternate Title'].tolist(), convert_to_numpy=True, device='cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vD1fRkf9udZ"
      },
      "outputs": [],
      "source": [
        "# add job-job edges, dataset see https://www.onetcenter.org/dictionary/26.3/excel/related_occupations.html\n",
        "job_job_edges = pd.read_csv('neo4jgraph/onet_related_occupations.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMsTH1Sx9udZ"
      },
      "outputs": [],
      "source": [
        "job_job_edges"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1lR651a9uda"
      },
      "outputs": [],
      "source": [
        "job_job_edges['job_src'] = job_job_edges['index_x'].apply(lambda x: jobmapping[x])\n",
        "job_job_edges['job_dst'] = job_job_edges['index_y'].apply(lambda x: jobmapping[x])\n",
        "relatedness_weight = {\n",
        "    'Supplemental':0.5,\n",
        "    'Primary-Long':0.75,\n",
        "    'Primary-Short':1\n",
        "}\n",
        "job_job_edges['relatedness_weight'] = job_job_edges['Relatedness Tier'].apply(lambda x: relatedness_weight[x])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1Wc7CIL9uda"
      },
      "outputs": [],
      "source": [
        "skill_skill_edges = pd.read_csv('neo4jgraph/skill_skill_edges.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8qOHTGfL9uda"
      },
      "outputs": [],
      "source": [
        "#filter out potentially bad skills (which are not in our original skillmapping)\n",
        "skill_skill_edges = skill_skill_edges.loc[(skill_skill_edges.skill.isin(list(skillmapping.keys()))) & (skill_skill_edges.related_skill.isin(list(skillmapping.keys())))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQhTLGTV9uda"
      },
      "outputs": [],
      "source": [
        "skill_skill_edges['skill_src'] = skill_skill_edges['skill'].apply(lambda x: skillmapping[x])\n",
        "skill_skill_edges['skill_dst'] = skill_skill_edges['related_skill'].apply(lambda x: skillmapping[x])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # only take largest 125 \"both directions\" (not ideal)\n",
        "# skill_skill_edges =  skill_skill_edges.groupby('skill_src').apply(lambda group: group.nlargest(125,'cosine_sim_score')).reset_index(drop=True)\n",
        "# skill_skill_edges =  skill_skill_edges.groupby('skill_dst').apply(lambda group: group.nlargest(125,'cosine_sim_score')).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get normalized tfidf boxplot using matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "plt.boxplot(skill_job_edges['normalized_tfidf'])\n",
        "plt.show()\n",
        "\n",
        "# get count of skills outside the boxplot\n",
        "len(skill_job_edges.loc[skill_job_edges['normalized_tfidf']>0.1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.hist(a, bins=100)\n",
        "plt.show()\n",
        "plt.hist(skill_skill_edges['cosine_sim_score'].to_numpy(), bins=100)\n",
        "plt.show()\n",
        "plt.hist(job_job_edges['relatedness_weight'].to_numpy(), bins=100)\n",
        "\n",
        "# change all values over "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# recscale to interval 0.5-1\n",
        "a = skill_job_edges['normalized_tfidf'].copy()\n",
        "a[a>0.08] = 0.08\n",
        "a = (a-a.min())/(a.max()-a.min())\n",
        "# rescale to interval 0.5-1\n",
        "a = (a*0.5)+0.5\n",
        "skill_job_edges['normalized_tfidf'] = a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "La85Q2M59uda"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.data import HeteroData\n",
        "import torch\n",
        "\n",
        "data = HeteroData()\n",
        "data['Skill'].x = torch.tensor(skill_sbert_embeddings)\n",
        "data['Job'].x = torch.tensor(job_sbert_embeddings)\n",
        "\n",
        "data['Job','REQUIRES','Skill'].edge_index = torch.tensor(skill_job_edges[['job_src','skill_dst']].to_numpy().T)\n",
        "data['Skill','IS_SIMILAR_SKILL','Skill'].edge_index = torch.tensor(skill_skill_edges[['skill_src','skill_dst']].to_numpy().T)\n",
        "data['Job','IS_SIMILAR_JOB','Job'].edge_index = torch.tensor(job_job_edges[['job_src','job_dst']].to_numpy().T)\n",
        "\n",
        "\n",
        "data['Job','REQUIRES','Skill'].edge_weight = torch.tensor(skill_job_edges['normalized_tfidf']).to(torch.float)\n",
        "data['Skill','IS_SIMILAR_SKILL','Skill'].edge_weight = torch.tensor(skill_skill_edges['cosine_sim_score'].to_numpy()).to(torch.float)\n",
        "data['Job','IS_SIMILAR_JOB','Job'].edge_weight = torch.tensor(job_job_edges['relatedness_weight'].to_numpy()).to(torch.float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Look at node degree statistics\n",
        "\n",
        "from torch_geometric.utils import to_dense_adj, degree\n",
        "\n",
        "\n",
        "\n",
        "job_n = data['Job'].x.shape[0]\n",
        "skill_n = data['Skill'].x.shape[0]\n",
        "\n",
        "JRS_J = degree(data['Job','REQUIRES','Skill'].edge_index[0], num_nodes=job_n)\n",
        "JRS_S = degree(data['Job','REQUIRES','Skill'].edge_index[1], num_nodes=skill_n)\n",
        "S_SIM_S = degree(data['Skill','IS_SIMILAR_SKILL','Skill'].edge_index.flatten(), num_nodes=skill_n)\n",
        "J_SIM_J = degree(data['Job','IS_SIMILAR_JOB','Job'].edge_index.flatten(), num_nodes=job_n)\n",
        "\n",
        "actual_skill_n = torch.nonzero(JRS_S+S_SIM_S).shape[0] # only skills which have any edge at all\n",
        "actual_job_n = torch.nonzero(JRS_J+J_SIM_J).shape[0] # only job which have any edge at all\n",
        "print(f'Jobs: {job_n}, actual Jobs used (in at least one edge): {actual_job_n}')\n",
        "print(f'Skills: {skill_n}, actual Skills used (in at least one edge): {actual_skill_n}')\n",
        "\n",
        "print('\\nFollowing metrics only include Skills and Jobs with at least one edge:\\n')\n",
        "\n",
        "print(f\"JRS edges: {data['Job','REQUIRES','Skill'].edge_index.shape[1]}\")\n",
        "print(f'Average JRS Job degree: {torch.sum(JRS_J)/actual_job_n}, Skill: {torch.sum(JRS_S)/actual_skill_n}')\n",
        "print(f'Median JRS Job degree: {torch.median(JRS_J[JRS_J!=0])}, Skill: {torch.median(JRS_S[JRS_S!=0])}')\n",
        "print(f'Max JRS Job degree: {torch.max(JRS_J)}, Skill: {torch.max(JRS_S)}\\n')\n",
        "\n",
        "print(f\"S_SIM_S edges: {data['Skill','IS_SIMILAR_SKILL','Skill'].edge_index.shape[1]}\")\n",
        "print(f'Average S_SIM_S degree: {torch.sum(S_SIM_S)/actual_skill_n}')\n",
        "print(f'Median S_SIM_S degree: {torch.median(S_SIM_S[S_SIM_S!=0])}')\n",
        "print(f'Max S_SIM_S degree: {torch.max(S_SIM_S)}')\n",
        "\n",
        "print(f'J_SIM_J edges: {data[\"Job\", \"IS_SIMILAR_JOB\", \"Job\"].edge_index.shape[1]}')\n",
        "print(f'Average J_SIM_J degree: {torch.sum(J_SIM_J)/actual_job_n}')\n",
        "print(f'Median J_SIM_J degree: {torch.median(J_SIM_J[J_SIM_J!=0])}')\n",
        "print(f'Max J_SIM_J degree: {torch.max(J_SIM_J)}\\n')\n",
        "\n",
        "print(f'Average total degree: Job: {(torch.sum(JRS_J)+torch.sum(J_SIM_J))/actual_job_n}')\n",
        "print(f'Average total degree: Skill: {(torch.sum(JRS_S)+torch.sum(S_SIM_S))/actual_skill_n}')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import os \n",
        "\n",
        "os.makedirs(\"plot_images/\", exist_ok=True)\n",
        "\n",
        "# Plot and save the first plot\n",
        "plt.title('J-R-S Job degree-distribution')\n",
        "plt.hist(JRS_J[JRS_J != 0], bins=25)\n",
        "plt.xlabel('Degree')\n",
        "plt.ylabel('Frequency')\n",
        "plt.savefig('plot_images/JRS_J_degree_distribution.svg', format='svg')\n",
        "plt.show()\n",
        "plt.clf()  # Clear the current figure\n",
        "\n",
        "# Plot and save the second plot\n",
        "plt.title('J-R-S Skill degree-distribution')\n",
        "plt.hist(JRS_S[JRS_S != 0], bins=25)\n",
        "plt.xlabel('Degree')\n",
        "plt.ylabel('Frequency')\n",
        "plt.savefig('plot_images/JRS_S_degree_distribution.svg', format='svg')\n",
        "plt.show()\n",
        "plt.clf()  # Clear the current figure\n",
        "\n",
        "# Plot and save the third plot\n",
        "plt.title('S-R-S Skill degree')\n",
        "plt.hist(S_SIM_S[S_SIM_S != 0], bins=25)\n",
        "plt.xlabel('Degree')\n",
        "plt.ylabel('Frequency')\n",
        "plt.savefig('plot_images/S_SIM_S_skill_degree.svg', format='svg')\n",
        "plt.show()\n",
        "plt.clf()  # Clear the current figure\n",
        "\n",
        "# Plot and save the fourth plot\n",
        "plt.title('J-R-J Job degree')\n",
        "plt.hist(J_SIM_J[J_SIM_J != 0], bins=25)\n",
        "plt.xlabel('Degree')\n",
        "plt.ylabel('Frequency')\n",
        "plt.savefig('plot_images/J_SIM_J_job_degree.svg', format='svg')\n",
        "plt.show()\n",
        "plt.clf()  # Clear the current figure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add features:\n",
        "# - node degree\n",
        "# - normalize edge weights by node degree\n",
        "# - (triangle count)\n",
        "\n",
        "\n",
        "# add node degree statistics:\n",
        "\n",
        "job_degrees = torch.cat((JRS_J.reshape(-1,1) / 125, J_SIM_J.reshape(-1,1)/ 125), dim=1) # divide by approx. max degrees\n",
        "skill_degrees = torch.cat((JRS_S.reshape(-1,1) / 125, S_SIM_S.reshape(-1,1)/ 125), dim=1) # divide by approx. max degrees\n",
        "\n",
        "data['Job'].x = torch.cat((data['Job'].x, job_degrees), dim=1)\n",
        "data['Skill'].x = torch.cat((data['Skill'].x, skill_degrees), dim=1)\n",
        "\n",
        "# normalize edge weights by node degree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch_sparse import SparseTensor\n",
        "from tqdm.auto import tqdm\n",
        "import torch\n",
        "import gc\n",
        "# adj_matmul\n",
        "# row1 to rowS * full_matrix\n",
        "# rowS+1 to rowT * full_matrix\n",
        "# ....\n",
        "\n",
        "# def blockwise_sparse_square_mmul(adj_matrix, blocks=None):\n",
        "#     row_blocks = []\n",
        "    \n",
        "#     if blocks is None:\n",
        "#         row_block_size = 10000\n",
        "#         rows = adj_matrix.size(0)\n",
        "#         for block in tqdm(range(0,rows, row_block_size), desc='blockwise sparse matrix-multiplication'):\n",
        "#             start = block\n",
        "#             end = min(block+row_block_size, rows)\n",
        "#             row_blocks.append(adj_matrix[start:end].spspmm(adj_matrix))\n",
        "#     else:\n",
        "#         for block in tqdm(blocks, desc='blockwise sparse matrix-multiplication'):\n",
        "#             row_blocks.append(block.spspmm(adj_matrix))\n",
        "\n",
        "#     return row_blocks\n",
        "\n",
        "\n",
        "# def blockwise_sparse_get_diag(blocks):\n",
        "#     diags = []\n",
        "#     for block in tqdm(blocks, desc='get blockwise sparse matrix diagonal'):\n",
        "#         diags.append(get_diag(block))\n",
        "    \n",
        "#     return torch.cat(diags, dim=0)\n",
        "\n",
        "def triangle_count(adj_matrix:SparseTensor):\n",
        "    # adj_matmul, blockwise, so kernel does not crash\n",
        "    # diag1((row1 to rowS) * full_matrix * full_matrix)\n",
        "    # diag2((rowS+1 to rowR) * full_matrix * full_matrix)\n",
        "    # ....\n",
        "    diags = []\n",
        "    \n",
        "    row_block_size = 400\n",
        "    rows = adj_matrix.size(0)\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device(\"cuda\")\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "    print(device)\n",
        "    with torch.no_grad():\n",
        "        \n",
        "        adj_matrix = adj_matrix.to(device)\n",
        "        for block in tqdm(range(0,rows, row_block_size), desc='blockwise sparse matrix-multiplication'):\n",
        "            torch.cuda.empty_cache()\n",
        "            gc.collect()\n",
        "            start = block\n",
        "            end = min(block+row_block_size, rows)\n",
        "            adj_pow_3_block = adj_matrix[start:end].spspmm(adj_matrix).spspmm(adj_matrix)\n",
        "            diag_block = get_diag(adj_pow_3_block[:,start:].cpu()).cpu()\n",
        "            diags.append(diag_block)\n",
        "            # diag = torch.eye(end)\n",
        "            # indices_i, indices_j = diag.nonzero().unbind(dim=1)\n",
        "            \n",
        "            # A = adj_pow_2_block[indices_i]\n",
        "            # B = adj_matrix[:, indices_j]\n",
        "            # print(A, t(B))\n",
        "            # print(type(B), type(A))\n",
        "            # print(A.size(0), A.size(1), B.size(0), B.size(1))\n",
        "            #C = A * t(B)\n",
        "            #C = reduction(C, dim=1)\n",
        "            \n",
        "           \n",
        "            #print(C)\n",
        "            \n",
        "            \n",
        "            \n",
        "    \n",
        "    return 1/2 * torch.cat(diags, dim=0)\n",
        "        \n",
        "from torch_geometric.utils import to_undirected\n",
        "from torch_sparse import SparseTensor\n",
        "from torch_sparse.diag import get_diag\n",
        "\n",
        "def undirected_triangle_counts(edge_index, max_num_nodes): \n",
        "    \"\"\"Get triangles **per node**, to get count for whole graph, divide by 3\"\"\"\n",
        "    ud = to_undirected(edge_index)\n",
        "    \n",
        "    adj_matrix = SparseTensor(row=ud[0], col=ud[1], value=torch.ones(ud[1].shape[0]), sparse_sizes=(max_num_nodes, max_num_nodes))\n",
        "    #adj_matrix = torch.sparse_coo_tensor(edge_index, torch.ones(edge_index.shape[1]), (max_num_nodes, max_num_nodes))\n",
        "    #adj_matrix = torch.sparse_csr_tensor(ud[0], ud[1], values=torch.ones(ud[1].shape[0]), dtype=torch.float32).to_sparse_coo()\n",
        "    triangles = triangle_count(adj_matrix) \n",
        "    return triangles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from torch_sparse import SparseTensor\n",
        "# adj = torch.tensor(\n",
        "#     [\n",
        "#         [0,1,1,1,1],\n",
        "#         [1,0,1,0,1],\n",
        "#         [1,1,0,1,0],\n",
        "#         [1,0,1,0,1],\n",
        "#         [1,1,0,1,0]\n",
        "#     ]\n",
        "# ).to(torch.float)\n",
        "# X = SparseTensor.from_dense(adj)\n",
        "# triangles = triangle_count(X)\n",
        "# triangles\n",
        "#adj_matrix = SparseTensor(row=ud[0], col=ud[1], value=torch.ones(ud[1].shape[0]), sparse_sizes=(max_num_nodes, max_num_nodes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "homogeneous_data = data.to_homogeneous()\n",
        "homogenous_triangles = undirected_triangle_counts(homogeneous_data.edge_index, homogeneous_data.x.shape[0])\n",
        "# max triangles: 9000\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Job_homogeneous_triangles = homogenous_triangles[homogeneous_data.node_type == 1]\n",
        "Skill_homogeneous_triangles = homogenous_triangles[homogeneous_data.node_type != 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "actual_s_triangles = Skill_homogeneous_triangles[(JRS_S+S_SIM_S)!=0] \n",
        "actual_j_triangles = Job_homogeneous_triangles[(JRS_J+J_SIM_J)!=0] \n",
        "\n",
        "print(f'Median triangles of skill nodes: {actual_s_triangles.median()}, mean: {actual_s_triangles.mean()}, max: {actual_s_triangles.max()}, min: {actual_s_triangles.min()}')\n",
        "print(f'Median triangles of job nodes: {actual_j_triangles.median()}, mean: {actual_j_triangles.mean()}, max: {actual_j_triangles.max()}, min: {actual_s_triangles.min()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.title('Skill triangles')\n",
        "plt.hist(actual_s_triangles.numpy(), bins=40)\n",
        "plt.show()\n",
        "plt.title('Job triangles')\n",
        "plt.hist(actual_j_triangles.numpy(), bins=40)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "J_SIM_J_triangles = undirected_triangle_counts(data['Job','IS_SIMILAR_JOB', 'Job'].edge_index, data['Job'].x.shape[0])\n",
        "S_SIM_S_triangles = undirected_triangle_counts(data['Skill','IS_SIMILAR_SKILL', 'Skill'].edge_index, data['Skill'].x.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "actual_s_triangles = S_SIM_S_triangles[(JRS_S+S_SIM_S)!=0] \n",
        "actual_j_triangles = J_SIM_J_triangles[(JRS_J+J_SIM_J)!=0] \n",
        "\n",
        "print(f'Median triangles of skill nodes for skill-skill edges: {actual_s_triangles.median()}, mean: {actual_s_triangles.mean()}, max: {actual_s_triangles.max()}, min: {actual_s_triangles.min()}')\n",
        "print(f'Median triangles of job nodes for job-job edges: {actual_j_triangles.median()}, mean: {actual_j_triangles.mean()}, max: {actual_j_triangles.max()}, min: {actual_s_triangles.min()}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Skill_homogeneous_triangles.max(), Job_homogeneous_triangles.max(), S_SIM_S_triangles.max(), J_SIM_J_triangles.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data['Skill'].x = torch.cat((data['Skill'].x, Skill_homogeneous_triangles.reshape(-1,1)/65380), dim=1) # normalize by max 9285.0\n",
        "data['Job'].x = torch.cat((data['Job'].x, Job_homogeneous_triangles.reshape(-1,1)/2059), dim=1) # normalize by max 1320\n",
        "\n",
        "data['Skill'].x = torch.cat((data['Skill'].x, S_SIM_S_triangles.reshape(-1,1)/65380), dim=1) # normalize by max 9285.0\n",
        "data['Job'].x = torch.cat((data['Job'].x, J_SIM_J_triangles.reshape(-1,1)/1284), dim=1) # normalize by max 1320"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZAF_riX9uda"
      },
      "outputs": [],
      "source": [
        "data.has_isolated_nodes(), data.has_self_loops()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5MjvjO09uda"
      },
      "outputs": [],
      "source": [
        "#data = data.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMAfCM0u9uda"
      },
      "outputs": [],
      "source": [
        "import torch_geometric.transforms as T\n",
        "\n",
        "transform = T.Compose([\n",
        "       #T.RemoveIsolatedNodes(),\n",
        "       T.RemoveDuplicatedEdges(),\n",
        "       T.ToUndirected(merge=False) # don't merge reversed edges into the original edge type\n",
        "])\n",
        "\n",
        "data = transform(data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# torch.save(data.to_dict(), path)\n",
        "# data = Data.from_dict(torch.load(path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch_geometric.data import HeteroData\n",
        "\n",
        "\n",
        "filename = 'Job_Skill_HeteroData_withdupes_fulldataset_v2.pt'\n",
        "if os.path.exists('./'+filename):\n",
        "    # data = HeteroData.from_dict(torch.load('./'+filename))\n",
        "    raise Exception('File already exists')\n",
        "else:\n",
        "    torch.save(data.to_dict(), './'+filename)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
