{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "90e61775-c59a-4697-866e-c5226f2d040d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e3c4b139-0996-4471-990d-08f1a7bbe79a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "70ff1fe6-6bf8-4150-ac65-9a9f45fe8df1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if \"DATABRICKS_RUNTIME_VERSION\" in os.environ:\n",
    "  #CUDA = 'cu121' \n",
    "  \n",
    "  import os\n",
    "  \n",
    "  !pip install torch==2.1.0  torchvision==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu121\n",
    "  import torch\n",
    "  #os.environ['TORCH'] = torch.__version__\n",
    "  #print(torch.__version__)\n",
    "  #torch_version = '2.0.0+cu118'\n",
    "  \n",
    "  #!pip install pyg_lib torch_scatter torch_sparse torch_cluster -f https://data.pyg.org/whl/torch-2.1.0+${CUDA}.html # torch_spline_conv\n",
    "  !pip install torch_geometric\n",
    "  !pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.1.0+cu121.html\n",
    "  #!pip install torch_sparse -f https://data.pyg.org/whl/torch-2.1.0+${CUDA}.html\n",
    "  #!pip install torch_scatter -f https://data.pyg.org/whl/torch-2.1.0+${CUDA}.html\n",
    "  #!pip install pyg_lib -f https://data.pyg.org/whl/torch-2.1.0+${CUDA}.html\n",
    "  !pip install sentence-transformers\n",
    "  !pip install torcheval\n",
    "  !pip install matplotlib\n",
    "  !pip install pandas\n",
    "  !pip install tensorboard\n",
    "  ROOT_FOLDER = 'dbfs:/FileStore/GraphNeuralNetworks/'\n",
    "else:\n",
    "  ROOT_FOLDER = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "efe06c00-84ff-49e4-89a9-cad18f63b110",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from learnings_sampler_v1 import get_datasets, uniform_hgt_sampler, get_minibatch_count\n",
    "\n",
    "train_data, val_data, test_data = get_datasets(get_edge_attr=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0d1eaa98-6d39-486c-a20c-67b7bec2fdda",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from models.TransE import TransE\n",
    "from models.HGT import HGT\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, gnn : torch.nn.Module, head :  torch.nn.Module, node_types, edge_types, ggn_output_dim):\n",
    "        super().__init__()\n",
    "        # edge_type onehot lookup table with keys\n",
    "        # node_type onehot lookup table with keys\n",
    "        self.node_type_embedding = torch.nn.Embedding(len(node_types), ggn_output_dim) # hidden channels should be the output dim of gnn\n",
    "        \n",
    "        self.edge_types = edge_types\n",
    "        for edge_type in edge_types:\n",
    "            if edge_type[1].startswith('rev_'):\n",
    "                self.edge_types.remove(edge_type)\n",
    "        \n",
    "        # create edge to int mapping\n",
    "        self.edgeindex_lookup = {edge_type:torch.tensor(i)  for i, edge_type in enumerate(edge_types)}\n",
    "            \n",
    "        # hidden channels should be the output dim of gnn\n",
    "        if head=='TransE': \n",
    "            self.head = TransE(len(node_types), len(edge_types) , ggn_output_dim)  # KGE head with loss function\n",
    "            self.head.to('cuda:0')\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        \n",
    "        self.gnn = gnn\n",
    "        \n",
    "    \n",
    "\n",
    "    def forward(self, hetero_data1, target_edge_type, edge_label_index, edge_label, hetero_data2=None):\n",
    "        \n",
    "        if hetero_data2 is not None:\n",
    "            assert target_edge_type[0] != target_edge_type[2], 'when passing two data objects, the edge type has to contain two different node types'\n",
    "            head_embeddings = self.gnn(hetero_data1.x_dict, hetero_data1.edge_index_dict)[target_edge_type[0]][edge_label_index[0,:]]\n",
    "            tail_embeddings = self.gnn(hetero_data2.x_dict, hetero_data2.edge_index_dict)[target_edge_type[2]][edge_label_index[1,:]]\n",
    "        else:\n",
    "            assert target_edge_type[0] == target_edge_type[2], 'when passing one data object, the edge type has to contain the same node types'\n",
    "            embeddings = self.gnn(hetero_data1.x_dict, hetero_data1.edge_index_dict)\n",
    "            head_embeddings = embeddings[target_edge_type[0]][edge_label_index[0,:]]\n",
    "            tail_embeddings = embeddings[target_edge_type[2]][edge_label_index[1,:]]\n",
    "        \n",
    "        edgeindex = self.edgeindex_lookup[target_edge_type]\n",
    "        loss = self.head.loss(head_embeddings, edgeindex.to(next(model.parameters()).device), tail_embeddings, edge_label)\n",
    "        return loss\n",
    "    \n",
    "        \n",
    "metadata = train_data.metadata()\n",
    "# add selfloops\n",
    "for node_type in train_data.node_types:\n",
    "    metadata[1].append((node_type, 'self_loop', node_type))    \n",
    "    \n",
    "out_channels = 64\n",
    "gnn = HGT(hidden_channels=64, out_channels=out_channels, num_heads=2, num_layers=2, node_types=train_data.node_types, data_metadata=metadata)\n",
    "\n",
    "model = Model(gnn, head='TransE', node_types=metadata[0], edge_types=metadata[1], ggn_output_dim=out_channels)\n",
    "model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9e709e2c-bb2f-4c9e-bcd5-2cbf1aa724c1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "176f7b03-b45d-4428-a7b7-9f0af0d4c281",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# get cuda device names\n",
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d435e3f3-b5b8-4ab7-8fdf-3004df6940aa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model.to('cuda:0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "78e86ffc-3ba8-4110-9960-d8e3c59b0dae",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# test training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "437d09e3-f157-4d13-acef-a8eba3cbcd66",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# for each node type get the data type of .x\n",
    "for node_type in train_data.node_types:\n",
    "    print(node_type, train_data[node_type].x.dtype)\n",
    "    # get min and max\n",
    "    print(train_data[node_type].x.min(), train_data[node_type].x.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "86ff7053-ec92-4d2a-8f0a-c5c679189017",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4ebad4a8-bb51-45f9-8f93-8036fd9e89ae",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_relationships = len(train_data.edge_types)\n",
    "one_hop_neighbors = (25 * batch_size)//num_relationships # per relationship type\n",
    "two_hop_neighbors = (25 * 10 * batch_size)//num_relationships # per relationship type\n",
    "num_neighbors = [one_hop_neighbors, two_hop_neighbors]\n",
    "print('num_neighbors', num_neighbors)\n",
    "device = 'cuda:0'\n",
    "sampler = uniform_hgt_sampler(train_data, batch_size, True, 'binary', 1, num_neighbors)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-7) #2e-15\n",
    "model.train()\n",
    "\n",
    "for i,(same_nodetype, target_edge_type, batch) in enumerate(sampler):\n",
    "    optimizer.zero_grad() \n",
    "    # batching is different depending on if node types in edge are same or different\n",
    "    print(target_edge_type)\n",
    "    if same_nodetype:\n",
    "        minibatch, edge_label_index, edge_label, input_edge_ids = batch\n",
    "        loss = model(minibatch.to(device), target_edge_type, edge_label_index.to(device), edge_label.to(device))\n",
    "    else:\n",
    "        minibatchpart1, minibatchpart2, edge_label_index, edge_label, input_edge_id = batch\n",
    "        loss = model(minibatch1.to(device), target_edge_type, edge_label_index.to(device), edge_label.to(device), minibatch2.to(device))\n",
    "        \n",
    "    optimizer.step()\n",
    "    print(loss)\n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a5bb0fb9-0134-4f5e-af53-d2fe28c6cf9b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5b9e3925-10b5-4ab4-a6af-6a013f7301e3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch_geometric.data import HeteroData\n",
    "\n",
    "\n",
    "from typing import Tuple, List\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "from torch_geometric.sampler import NegativeSampling\n",
    "from torch_geometric.data import HeteroData\n",
    "import gc\n",
    "import multiprocessing as mp\n",
    "\n",
    "# watch -n 1 df -h /dev/shm\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "from torcheval.metrics import BinaryAccuracy, BinaryPrecision, BinaryRecall, BinaryF1Score, BinaryAUPRC, BinaryAUROC\n",
    "from tqdm.auto import tqdm\n",
    "import gc\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "class GNNTrainer():\n",
    "    def __init__(self, model, criterion, optimizer, device, log_folder):\n",
    "        #super().__init__(model, criterion, optimizer, device, ) # metrics=['f1','accuracy','precision','recall', 'aucpr']\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.device = device\n",
    "        self.train_batch_size = 0  # for tqdm, for logging\n",
    "        self.train_n_mini_in_batch = 0  # for tqdm\n",
    "        self.val_n_mini_in_batch = 0  # for tqdm\n",
    "        self.log_folder = log_folder\n",
    "    \n",
    "    def free_memory(self):\n",
    "        \"\"\"Clears the GPU cache and triggers garbage collection, to reduce OOMs.\"\"\"\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "    \n",
    "            \n",
    "    \n",
    "        \n",
    "    def write_calc_metrics(self, split_name:str, y_hat, y, y_per_edgetype, y_hat_per_edgetype, epoch:int, is_epoch:bool, minibatch:int=0, loss:int=0, loss_per_edgetype=None, print_=True):\n",
    "        assert epoch>=1, 'Epoch must be >= 1'\n",
    "        assert minibatch >= 1, \"minibatch must be >=1\"\n",
    "        \n",
    "        if split_name=='train':\n",
    "            assert self.train_batch_size != 0\n",
    "            assert self.train_n_mini_in_batch != 0\n",
    "            assert loss != 0, \"loss can't be 0\"\n",
    "            if is_epoch:\n",
    "                loss_per_edge_type = {}\n",
    "                y_per_edgetype = {}\n",
    "                y_hat_per_edgetype = {}\n",
    "            assert loss_per_edgetype is not None\n",
    "            \n",
    "        else:\n",
    "            assert loss_per_edgetype is None\n",
    "            \n",
    "        if is_epoch:\n",
    "            split_name = 'epoch_'+split_name\n",
    "            index = epoch\n",
    "        else:\n",
    "            split_name = 'samples_'+split_name\n",
    "            no_minibatches = (epoch-1)*self.train_n_mini_in_batch + minibatch\n",
    "            approx_no_samples = no_minibatches*self.train_batch_size\n",
    "            index = approx_no_samples\n",
    "        \n",
    "        y_per_edgetype[('','all','')]= y\n",
    "        y_hat_per_edgetype[('','all','')]= y_hat\n",
    "        if 'train' in split_name:\n",
    "            loss_per_edgetype[('','all','')] = loss\n",
    "        \n",
    "        \n",
    "        for edgetype in y_per_edgetype.keys():\n",
    "            y = y_per_edgetype[edgetype].to(torch.int).detach().cpu()\n",
    "            y_hat = y_hat_per_edgetype[edgetype].detach().cpu()\n",
    "            edge_name = '-'.join(list(edgetype)).strip('-')\n",
    "        \n",
    "            \n",
    "            def calculate_f1(y_hat, y, thresholds):\n",
    "                \n",
    "                return np.array([f1_score(y_hat>threshold, y, average='binary') for threshold in thresholds])\n",
    "            \n",
    "            # get best f1 threshold\n",
    "            thresholds = np.arange(0.001, 1, 0.001)\n",
    "            a, b = y_hat.numpy(), y.numpy()\n",
    "            f1s = calculate_f1(a,b , thresholds)\n",
    "            optimal_threshold = thresholds[np.argmax(f1s)]\n",
    "            f1=max(f1s)\n",
    "    \n",
    "            acc, prec, rec = BinaryAccuracy(threshold=optimal_threshold).update(y_hat, y).compute().item(), BinaryPrecision(threshold=optimal_threshold).update(y_hat, y).compute().item(), BinaryRecall(threshold=optimal_threshold).update(y_hat, y).compute().item()\n",
    "            self.writer.add_scalar(f'{split_name}_f1threshold_{edge_name}', optimal_threshold, index)\n",
    "            self.writer.add_scalar(f'{split_name}_accuracy_{edge_name}', acc, index)\n",
    "            self.writer.add_scalar(f'{split_name}_precision_{edge_name}', prec, index)\n",
    "            self.writer.add_scalar(f'{split_name}_recall_{edge_name}', rec, index)\n",
    "            self.writer.add_scalar(f'{split_name}_f1_{edge_name}', f1, index)\n",
    "            \n",
    "        \n",
    "            auprc = BinaryAUPRC().update(y_hat, y).compute().item()\n",
    "            auroc = BinaryAUROC().update(y_hat, y).compute().item()\n",
    "            \n",
    "            self.writer.add_scalar(f'{split_name}_auprc_{edge_name}', auprc, index)\n",
    "            self.writer.add_scalar(f'{split_name}_auroc_{edge_name}', auroc, index)\n",
    "            if 'train' in split_name:\n",
    "                loss = loss_per_edgetype[edgetype]\n",
    "                self.writer.add_scalar(f'{split_name}_loss_{edge_name}', loss, index)\n",
    "            self.writer.flush()\n",
    "            \n",
    "            if print_ and edgetype==('','all',''):\n",
    "                out_of = f'/{self.train_n_mini_in_batch:06d}' if 'train' in split_name else ''\n",
    "                no_samples = f'|samples:{index}' if 'train' in split_name else ''\n",
    "                loss_to_show = f'loss:{loss:.4f},' if 'train' in split_name else ''\n",
    "                print(f'{split_name}|{int(minibatch):04d}{out_of}|{epoch:04d}{no_samples}|{loss_to_show} F1: {f1:.6f}, AUC-PR: {auprc:.6f}, (auroc: {auroc:.6f}, acc: {acc:.6f}, prec: {prec:.6f}, rec: {rec:.6f})')\n",
    "\n",
    "    def create_logfolders(self, run_folder=None):\n",
    "        if run_folder is None:\n",
    "            run_folder = datetime.now().strftime('run_%d%m%Y_%H%M%S')\n",
    "            \n",
    "        self.writer = SummaryWriter(log_dir=Path(self.log_folder)/(run_folder+'_tensorboard'))\n",
    "        self.checkpoint_folder = Path(self.log_folder)/(run_folder+'_checkpoints')\n",
    "        if not os.path.exists(self.checkpoint_folder):\n",
    "            os.makedirs(self.checkpoint_folder)\n",
    "        \n",
    "        if not os.path.exists(Path(self.log_folder)/(run_folder+'_tensorboard')):\n",
    "            os.makedirs(Path(self.log_folder)/(run_folder+'_tensorboard'))\n",
    "            \n",
    "        print(f'run folder is {run_folder}')\n",
    "        \n",
    "    \n",
    "    def train(self, train_iterator, val_iterator, start_epoch, n_epochs, run_folder=None, save_metrics_after_n_batches=100):\n",
    "        self.free_memory()\n",
    "        self.create_logfolders(run_folder)\n",
    "\n",
    "        self.model.train()\n",
    "        \n",
    "        print(f'Number of parameters: {sum(p.numel() for p in model.parameters())}')\n",
    "        print(f'Number of learnable parameters: {sum(p.numel() for p in model.parameters()  if p.requires_grad)}')\n",
    "        \n",
    "        assert start_epoch >= 1, \"Epoch must be >= 1\"\n",
    "        \n",
    "        for epoch in range(start_epoch, start_epoch+n_epochs):\n",
    "            \n",
    "            epoch_loss = 0\n",
    "            for batch_idx, edge_batches in tqdm(enumerate(train_iterator()), total=self.train_n_mini_in_batch, desc='train epoch'):\n",
    "                batch_idx+=1  # start from 1\n",
    "                self.optimizer.zero_grad()  # empty gradients\n",
    "                minibatch_loss = 0\n",
    "                loss_per_edgetype = {}\n",
    "                y_hat, y = [], []\n",
    "                y_hat_per_edgetype, y_per_edgetype = {}, {}\n",
    "                for supervision_edge_type, batch in edge_batches:  # each \"batch\" here is one edge type, since we want to learn for all edge types\n",
    "                    batch = batch.to(self.device)\n",
    "                    hetero_out = model(batch.x_dict, batch.edge_index_dict, batch.edge_weight_dict, batch.num_sampled_edges_dict, batch.num_sampled_nodes_dict)  # get model output\n",
    "\n",
    "                    # evaluate, calculate cosine sim and compute cross-entropy loss\n",
    "                    src_type, dst_type = supervision_edge_type[0], supervision_edge_type[2]\n",
    "                    edge_label = batch[supervision_edge_type].edge_label\n",
    "                    edge_label_index = batch[supervision_edge_type].edge_label_index\n",
    "                    src_node_embeddings = hetero_out[src_type][edge_label_index[0]]\n",
    "                    dst_node_embeddings = hetero_out[dst_type][edge_label_index[1]]\n",
    "                    \n",
    "                    loss, y_pred = self.criterion(src_node_embeddings, dst_node_embeddings, edge_label)\n",
    "                    \n",
    "                    minibatch_loss += loss\n",
    "                    # collect data for metrics\n",
    "                    loss_per_edgetype[supervision_edge_type] = loss.detach().item()\n",
    "                    y_hat_per_edgetype[supervision_edge_type] = y_pred.detach().cpu()\n",
    "                    y_per_edgetype[supervision_edge_type] = edge_label.to(torch.int).detach().cpu()\n",
    "                    y_hat.append(y_hat_per_edgetype[supervision_edge_type])\n",
    "                    y.append(y_per_edgetype[supervision_edge_type])\n",
    "                    \n",
    "                minibatch_loss.backward()\n",
    "                self.optimizer.step()\n",
    "                minibatch_loss = minibatch_loss.detach().item()\n",
    "                epoch_loss += minibatch_loss\n",
    "             \n",
    "                y_hat = torch.cat(y_hat)\n",
    "                y = torch.cat(y)\n",
    "                # create metrics and write to tensorboard writer\n",
    "                if batch_idx%save_metrics_after_n_batches==1:\n",
    "                    self.write_calc_metrics('train', y_hat, y, y_per_edgetype, y_hat_per_edgetype,  epoch=epoch, minibatch=batch_idx, loss=minibatch_loss, loss_per_edgetype=loss_per_edgetype, is_epoch=False, print_=False)\n",
    "                    self.validate(val_iterator, epoch, batch_idx, is_epoch=False)\n",
    "                    self.model.train()  # back to training, just in case\n",
    "           \n",
    "            self.save_checkpoint(epoch, batch_idx)\n",
    "            self.write_calc_metrics('train', y_hat, y, y_per_edgetype={}, y_hat_per_edgetype={}, loss_per_edgetype={}, epoch=epoch, minibatch=batch_idx, loss=epoch_loss, is_epoch=True, print_=True)\n",
    "            self.validate(val_iterator, epoch, batch_idx, is_epoch=True)\n",
    "            self.model.train()  # back to training, just in case\n",
    "            \n",
    "    def validate(self, val_iterator, epoch, batch_idx, is_epoch):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_hat, y = [], []\n",
    "            y_hat_per_edgetype, y_per_edgetype = {}, {}\n",
    "            for edge_batches in val_iterator():\n",
    "                for supervision_edge_type, batch in edge_batches:  # each \"batch\" here is one edge type, since we want to learn for all edge types\n",
    "                    batch = batch.to(self.device)\n",
    "                    hetero_out = model(batch.x_dict, batch.edge_index_dict, batch.edge_weight_dict, batch.num_sampled_edges_dict, batch.num_sampled_nodes_dict)\n",
    "\n",
    "                    # evaluate, calculate cosine sim and compute cross-entropy loss\n",
    "                    src_type, dst_type = supervision_edge_type[0], supervision_edge_type[2]\n",
    "                    edge_label = batch[supervision_edge_type].edge_label\n",
    "                    edge_label_index = batch[supervision_edge_type].edge_label_index\n",
    "                    if src_type not in  hetero_out.keys() or dst_type not in hetero_out.keys():\n",
    "                        print('eval failed on one minibatch part, skipping')\n",
    "                        print('Supervision edge type:',supervision_edge_type)\n",
    "                        print('one type is missing in model output',src_type, dst_type)\n",
    "                        hetero_out = model(batch.x_dict, batch.edge_index_dict, batch.edge_weight_dict, batch.num_sampled_edges_dict, batch.num_sampled_nodes_dict)\n",
    "                        print(batch.x_dict)\n",
    "                        print(hetero_out.keys())\n",
    "                        print(batch)\n",
    "                        continue\n",
    "                        \n",
    "                    src_node_embeddings = hetero_out[src_type][edge_label_index[0]]\n",
    "                    dst_node_embeddings = hetero_out[dst_type][edge_label_index[1]]\n",
    "                    \n",
    "                    #logits = F.cosine_similarity(src_node_embeddings, dst_node_embeddings, dim=-1)\n",
    "                    \n",
    "                    _, y_pred = self.criterion(src_node_embeddings, dst_node_embeddings, edge_label)\n",
    "                    # y_hat.append(y_pred.detach())\n",
    "                    # y.append(edge_label.to(torch.int).detach())\n",
    "\n",
    "                    # collect data for metrics\n",
    "                    if supervision_edge_type not in y_hat_per_edgetype.keys():\n",
    "                        y_hat_per_edgetype[supervision_edge_type] = []\n",
    "                        y_per_edgetype[supervision_edge_type] = []\n",
    "                        \n",
    "                    y_hat_per_edgetype[supervision_edge_type].append(y_pred.detach().cpu())\n",
    "                    y_per_edgetype[supervision_edge_type].append(edge_label.to(torch.int).detach().cpu())\n",
    "                   \n",
    "                    \n",
    "            # save metrics\n",
    "            for key in y_hat_per_edgetype:\n",
    "                y_hat_per_edgetype[key] = torch.cat(y_hat_per_edgetype[key])\n",
    "                y_per_edgetype[key] = torch.cat(y_per_edgetype[key])\n",
    "                y_hat.append(y_hat_per_edgetype[key])\n",
    "                y.append(y_per_edgetype[key])\n",
    "                \n",
    "            y_hat = torch.cat(y_hat)\n",
    "            y = torch.cat(y)\n",
    "            self.write_calc_metrics('val', y_hat, y, y_per_edgetype, y_hat_per_edgetype, epoch=epoch, is_epoch=is_epoch, print_=True, minibatch=batch_idx)\n",
    "    \n",
    "    def save_checkpoint(self, epoch, batch_idx):\n",
    "        print(f'save checkpoint {self.checkpoint_folder}/checkpoint_ep{epoch}_{batch_idx}.pt')\n",
    "        torch.save({\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "           # 'metrics_history': self.story,\n",
    "        }, f'{self.checkpoint_folder}/checkpoint_ep{epoch}.pt')\n",
    "\n",
    "    def load_checkpoint(self, load_path):\n",
    "        checkpoint = torch.load(load_path)\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        \n",
    "        \n",
    "import os\n",
    "import torch\n",
    "\n",
    "\n",
    "# from models.WeightedSkillGAT import weightedSkillGAT_lr_2emin6_16hiddenchannels_8heads_128out_2layers_edgeweights_checkpoints\n",
    "# model = weightedSkillGAT_lr_2emin6_16hiddenchannels_8heads_128out_2layers_edgeweights_checkpoints()\n",
    "from models.WeightedSkillSAGE import weightedSkillSAGE_lr_2emin7_1lin_1lin_256dim_edgeweight_noskillskillpred_checkpoints\n",
    "from models.WeightedSkillSAGE import weightedSkillSAGE_lr_2emin7_0lin_256dim_edgeweight_prelu_batchnorm_checkpoints\n",
    "from models.WeightedSkillSAGE import weightedSkillSAGE_lr_2emin7_0lin_132dim_edgeweight_prelu_batchnorm_checkpoints\n",
    "from models.WeightedSkillSAGE import skillsage_388_prelu_batchnorm_edgeweight\n",
    "# model = weightedSkillSAGE_lr_2emin7_1lin_1lin_256dim_edgeweight_noskillskillpred_checkpoints()\n",
    "# model = weightedSkillSAGE_lr_2emin7_0lin_256dim_edgeweight_prelu_batchnorm_checkpoints()\n",
    "model = skillsage_388_prelu_batchnorm_edgeweight()\n",
    "#os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "# torch._dynamo.config.verbose=True\n",
    "# torch._dynamo.config.suppress_errors = True\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-7) #2e-15\n",
    "def graphSAGE_loss(u, v, y_label):\n",
    "    y_neg = (y_label-1)\n",
    "    y_label = (y_neg + y_label).squeeze()  # has -1 for neg and 1 for pos\n",
    "    # loss= -1* log(sig(u,v_pos)) - Q*E*log(sig(-1*u,v_neg)) where Q is number of neg, E is expected value\n",
    "    logits = torch.sum(torch.mul(u, v), dim=-1)\n",
    "    \n",
    "    mul = torch.sigmoid(torch.mul(logits, y_label))\n",
    "    loss = -1*torch.sum(torch.log(mul)) # sum across all examples\n",
    "    y_hat = torch.sigmoid(logits) # just for metrics in later step\n",
    "    return loss, y_hat.detach()\n",
    "\n",
    "criterion = graphSAGE_loss\n",
    "#criterion = torch.nn.CrossEntropyLoss()\n",
    "trainer = GNNTrainer(model, criterion, optimizer, device , log_folder='runs')\n",
    "#trainer.load_checkpoint('./checkpoints/checkpoint_0_300.pt')\n",
    "\n",
    "\n",
    "# for tqdm\n",
    "trainer.train_batch_size = batch_size\n",
    "trainer.train_n_mini_in_batch = train_batch_len\n",
    "trainer.val_n_mini_in_batch = val_batch_len\n",
    "\n",
    "trainer.train(\n",
    "    train_iterator, \n",
    "    val_iterator, \n",
    "    start_epoch=1, \n",
    "    n_epochs=200, \n",
    "    run_folder=f'skillsage_388_prelu_batchnorm_edgeweight_jsssjj_fulldsv2', # temp\n",
    "    save_metrics_after_n_batches=1000) # graphconv_v0_lr_2emin6_2lin_1lin_256dim\n",
    "#weightedSkillSAGE_lr_2emin7_0lin_256dim_edgeweight_prelu_batchnorm_checkpoints\n",
    "# trainer.validate(val_dataloader)\n",
    "# trainer.plot_losses()\n",
    "# trainer.load_checkpoint('./checkpoints/checkpoint_100.pt')\n",
    "# trainer.validate(val_iterator,1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ed794dff-b1f8-45fa-aba6-9b3a3ebe9b03",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_relationships = len(train_data.edge_types)\n",
    "one_hop_neighbors = (25 * batch_size)//num_relationships # per relationship type\n",
    "two_hop_neighbors = (25 * 10 * batch_size)//num_relationships # per relationship type\n",
    "num_neighbors = [one_hop_neighbors, two_hop_neighbors]\n",
    "print('num_neighbors', num_neighbors)\n",
    "\n",
    "sampler = uniform_hgt_sampler(train_data, batch_size, True, 'binary', 1, num_neighbors)\n",
    "start = datetime.datetime.now()\n",
    "print(start)\n",
    "print()\n",
    "for i,(same_nodetype, target_edge_type, batch) in enumerate(sampler):\n",
    "    \n",
    "    # batching is different depending on if node types in edge are same or different\n",
    "    edge_type = batch[-1]\n",
    "    if same_nodetype:\n",
    "        minibatch, edge_label_index, edge_label, input_edge_ids = batch\n",
    "        print(minibatch)\n",
    "    else:\n",
    "        minibatchpart1, minibatchpart2, edge_label_index, edge_label, input_edge_id = batch\n",
    "        print(minibatchpart1)\n",
    "        \n",
    "    print(i,target_edge_type)\n",
    "    \n",
    "    break\n",
    "    time.sleep(5)\n",
    "    \n",
    "end = datetime.datetime.now()\n",
    "print()\n",
    "print(end-start)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "learnings_training_v1",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "pyg_torch21",
   "language": "python",
   "name": "pyg_torch21"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
