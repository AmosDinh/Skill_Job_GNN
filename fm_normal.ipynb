{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from models.TransE import TransE\n",
    "from models.DistMult import DistMult\n",
    "from models.FactorizationMachineModel import FactorizationMachineModel\n",
    "import torch_geometric\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, fm : torch.nn.Module, head, node_types, edge_types, ggn_output_dim, pnorm=1, num_supervisors=0, num_organizations=0):\n",
    "        super().__init__()\n",
    "        # edge_type onehot lookup table with keys\n",
    "        # node_type onehot lookup table with keys\n",
    "        self.node_type_embedding = torch.nn.Embedding(len(node_types), ggn_output_dim) # hidden channels should be the output dim of gnn\n",
    "        self.num_supervisors = num_supervisors\n",
    "        self.num_organizations = num_organizations\n",
    "        self.edge_types = edge_types\n",
    "        for edge_type in edge_types:\n",
    "            if edge_type[1].startswith('rev_'):\n",
    "                self.edge_types.remove(edge_type)\n",
    "        \n",
    "        # create edge to int mapping\n",
    "        self.edgeindex_lookup = {edge_type:torch.tensor(i)  for i, edge_type in enumerate(edge_types)}\n",
    "            \n",
    "        if head=='TransE': \n",
    "            self.head = TransE(len(node_types), len(edge_types) , ggn_output_dim, p_norm= pnorm)  # KGE head with loss function\n",
    "        elif head=='DistMult':\n",
    "            self.head = DistMult(len(node_types), len(edge_types) , ggn_output_dim, p_norm= pnorm)  # KGE head with loss function\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        \n",
    "        self.fm = fm\n",
    "       \n",
    "     \n",
    "        self.layer1 = torch.nn.Linear(3167,512)\n",
    "        self.layer2 = torch.nn.Linear(512,256)\n",
    "        self.layer3 = torch.nn.Linear(257,256)\n",
    "        self.fc_output = torch.nn.Linear(256, 256)\n",
    "\n",
    "    def forward(self, hetero_data, hetero_data_embeddings, edge_label_index, edge_label):\n",
    "        \n",
    "    \n",
    "        people = hetero_data['people'].x[edge_label_index[0,:],:]\n",
    "        # last two columns in people are the indices of onehot, so change them to full onehot supervisor and organization\n",
    "        #supervisors = torch.nn.functional.one_hot(people[:,-2].to(torch.int64), num_classes=self.num_supervisors).to(torch.float32)\n",
    "        #organizations = torch.nn.functional.one_hot(people[:,-1].to(torch.int64), num_classes=self.num_organizations).to(torch.float32)\n",
    "        #people = torch.cat((people[:,:-2], supervisors, organizations), dim=1)\n",
    "        people_embeddings = hetero_data_embeddings['people'].x[edge_label_index[0,:],:]\n",
    "                        \n",
    "        learnings = hetero_data['courses_and_programs'].x[edge_label_index[1,:],:]\n",
    "        learning_embeddings = hetero_data_embeddings['courses_and_programs'].x[edge_label_index[1,:],:]\n",
    "        \n",
    "        #x1 = torch.cat((people_embeddings, learning_embeddings),dim=1)\n",
    "        #x1 = self.layer1(x1).relu()\n",
    "        #x1 = self.layer2(x1).relu()\n",
    "        x2 = torch.cat((people,learnings),dim=1)\n",
    "        x2 = self.fm(x2)\n",
    "        scores = x2\n",
    "        #x3 = self.layer3(torch.cat((x1,x2.unsqueeze(1)),dim=1)).relu()\n",
    "        #scores = self.fc_output(x3).relu()\n",
    "     \n",
    "        pos_scores = scores[edge_label==1]\n",
    "        neg_scores = scores[edge_label==0]\n",
    "            \n",
    "\n",
    "        return F.margin_ranking_loss(\n",
    "            pos_scores,\n",
    "            neg_scores,\n",
    "            target=torch.ones_like(pos_scores), # 1 for similarity, -1 for dissimilarity\n",
    "            margin=0.2\n",
    "        )\n",
    "        \n",
    "    \n",
    "out_channels = 1\n",
    "hidden_channels = 16\n",
    "num_heads = 0\n",
    "num_layers = 0\n",
    "pnorm = 2\n",
    "head = 'TransE'\n",
    "#gnn = HGT(hidden_channels=out_channels, out_channels=out_channels, num_heads=num_heads, num_layers=num_layers, node_types=train_data.node_types, data_metadata=metadata)\n",
    "filename = 'HeteroData_Learnings_normalized_triangles_withadditionaldata_v1.pt'\n",
    "data_forlookup = HeteroData.from_dict(torch.load(ROOT_FOLDER+filename))\n",
    "num_supervisors = data_forlookup['people'].num_nodes\n",
    "num_organizations = data_forlookup['organizations'].num_nodes\n",
    "metadata = data_forlookup.metadata()\n",
    "# add selfloops\n",
    "for node_type in data_forlookup.node_types:\n",
    "    metadata[1].append((node_type, 'self_loop', node_type))  \n",
    "    \n",
    "    \n",
    "\n",
    "del data_forlookup\n",
    "print(train_data['people'].labelencoding.shape, train_data['courses_and_programs'].labelencoding.shape)  \n",
    "field_dims = torch.cat((train_data['people'].labelencoding,train_data['courses_and_programs'].labelencoding), dim=0)\n",
    "print(field_dims)\n",
    "# convert the field dims to integer\n",
    "field_dims = field_dims.to(torch.int64)\n",
    "fm = FactorizationMachineModel(\n",
    "    field_dims=field_dims,\n",
    "        embed_dim=hidden_channels)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Model(fm, head=head, node_types=metadata[0], edge_types=metadata[1], ggn_output_dim=out_channels, pnorm=pnorm, num_supervisors=num_supervisors, num_organizations=num_organizations)\n",
    "#torch_geometric.compile(model, dynamic=True)\n",
    "model.to(device)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
