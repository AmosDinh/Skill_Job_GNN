{
   "cells": [
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {
            "application/vnd.databricks.v1+cell": {
               "cellMetadata": {
                  "byteLimit": 2048000,
                  "rowLimit": 10000
               },
               "inputWidgets": {},
               "nuid": "fbc6e4a8-59f7-4d4a-bfa6-6824af347441",
               "showTitle": false,
               "title": ""
            }
         },
         "outputs": [],
         "source": [
            "# import pytroch geometric hetero data\n",
            "# from torch_geometric.data import HeteroData\n",
            "# import torch\n",
            "# data = HeteroData.from_dict(torch.load('HeteroData_Learnings_normalized_triangles_withadditionaldata_v1.pt'))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 7,
         "metadata": {},
         "outputs": [],
         "source": [
            "import os\n",
            "\n",
            "if \"DATABRICKS_RUNTIME_VERSION\" in os.environ and not 'installed_libs' in globals():\n",
            "  #CUDA = 'cu121' \n",
            "  installed_libs = True\n",
            "  \n",
            "  \n",
            "  !pip install torch==2.1.0  torchvision==0.16.0 torchtext==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu121\n",
            "  import torch\n",
            "  #os.environ['TORCH'] = torch.__version__\n",
            "  #print(torch.__version__)\n",
            "  #torch_version = '2.0.0+cu118'\n",
            "  \n",
            "  #!pip install pyg_lib torch_scatter torch_sparse torch_cluster -f https://data.pyg.org/whl/torch-2.1.0+${CUDA}.html # torch_spline_conv\n",
            "  !pip install torch_geometric\n",
            "  !pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.1.0+cu121.html\n",
            "  #!pip install torch_sparse -f https://data.pyg.org/whl/torch-2.1.0+${CUDA}.html\n",
            "  #!pip install torch_scatter -f https://data.pyg.org/whl/torch-2.1.0+${CUDA}.html\n",
            "  #!pip install pyg_lib -f https://data.pyg.org/whl/torch-2.1.0+${CUDA}.html\n",
            "  !pip install sentence-transformers\n",
            "  !pip install torcheval\n",
            "  !pip install matplotlib\n",
            "  !pip install pandas\n",
            "  !pip install tensorboard\n",
            "  \n",
            "if \"DATABRICKS_RUNTIME_VERSION\" in os.environ:\n",
            "  ROOT_FOLDER = '/dbfs/FileStore/GraphNeuralNetworks/'\n",
            "else:\n",
            "  ROOT_FOLDER = ''"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 8,
         "metadata": {
            "application/vnd.databricks.v1+cell": {
               "cellMetadata": {
                  "byteLimit": 2048000,
                  "rowLimit": 10000
               },
               "inputWidgets": {},
               "nuid": "a3529f9f-8ec0-4554-ac0f-9562ea79b6e4",
               "showTitle": false,
               "title": ""
            }
         },
         "outputs": [],
         "source": [
            "from learnings_sampler_v1 import get_datasets"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 9,
         "metadata": {
            "application/vnd.databricks.v1+cell": {
               "cellMetadata": {
                  "byteLimit": 2048000,
                  "rowLimit": 10000
               },
               "inputWidgets": {},
               "nuid": "148b0a02-d22f-4202-a5fa-7115c0b66e45",
               "showTitle": false,
               "title": ""
            }
         },
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "size of dataset on disk:  2.279761238 gb\n",
                  "loading saved heterodata object\n",
                  "for skill job edges keep top k edges per job, k is  50\n",
                  "keep tensor(1208056) of total 16289586\n"
               ]
            }
         ],
         "source": [
            "train_data, val_data, test_data = get_datasets(get_edge_attr=False,filename=ROOT_FOLDER+'HeteroData_Learnings_normalized_triangles_withadditionaldata_v1.pt', filter_top_k=True, top_k=50)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {
            "application/vnd.databricks.v1+cell": {
               "cellMetadata": {
                  "byteLimit": 2048000,
                  "rowLimit": 10000
               },
               "inputWidgets": {},
               "nuid": "0a0a3b3c-ed0b-4390-a571-02fc765958b3",
               "showTitle": false,
               "title": ""
            }
         },
         "outputs": [],
         "source": [
            "# people have jobs, if multiple, we average\n",
            "# jobs have skills, if multiple, we average\n",
            "#  \n",
            "\n",
            "# so row is [pid, lid][person learning person_features person_jobs job_skills target_watched]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 5,
         "metadata": {
            "application/vnd.databricks.v1+cell": {
               "cellMetadata": {
                  "byteLimit": 2048000,
                  "rowLimit": 10000
               },
               "inputWidgets": {},
               "nuid": "a52bf379-b6d1-4741-b56f-2e2ba8521dc6",
               "showTitle": false,
               "title": ""
            }
         },
         "outputs": [],
         "source": [
            "import torch\n",
            "from tqdm.auto import tqdm\n",
            "from torch_geometric.data import HeteroData\n",
            "import os \n",
            "\n",
            "def make_ds(data, split_name):\n",
            "    def skills_avg(edge_index_to_skill, entity_id):\n",
            "        # eg job->skill, entity_id = job 254\n",
            "        mask1 = edge_index_to_skill[0,:]==entity_id\n",
            "        mask2 = edge_index_to_skill[1,:][mask1].squeeze()\n",
            "        if torch.sum(mask1)==0:\n",
            "            return torch.zeros(1, data['skills'].x.shape[1])\n",
            "        a = data['skills'].x[mask2]\n",
            "        if a.dim() == 1:\n",
            "            return a.unsqueeze(0)\n",
            "        else:\n",
            "            return a.mean(axis=0).squeeze().unsqueeze(0)\n",
            "\n",
            "    \n",
            "    job_skills = []\n",
            "    for job_id in tqdm(range(data['jobs'].num_nodes)):\n",
            "        e= skills_avg(data['jobs', 'rev_job_skill', 'skills'].edge_index,job_id)\n",
            "        job = data['jobs'].x[job_id,:].unsqueeze(0)\n",
            "        \n",
            "        job_skills.append(torch.cat((job,e),dim=1))\n",
            "    \n",
            "    learning_skills = []\n",
            "    for learning_id in tqdm(range(data['courses_and_programs'].num_nodes)):\n",
            "        e  = skills_avg(data['courses_and_programs', 'rev_course_and_program_skill', 'skills'].edge_index,learning_id)\n",
            "        learning = data['courses_and_programs'].x[learning_id,:].unsqueeze(0)\n",
            "        learning_skills.append(torch.cat((learning,e),dim=1))\n",
            "      \n",
            "        \n",
            "        \n",
            "    jobs_skills = torch.cat((job_skills),dim=0)\n",
            "    \n",
            "    #torch.save(torch.cat((learning_skills),dim=0),ROOT_FOLDER+'learnings/'+split_name+'/learnings.pt')\n",
            "    #del learning_skills\n",
            "\n",
            "    def avg_of_computed(edge_index_to_skill, opposite_entity_id, opposite_datax):\n",
            "        # eg job->skill, oposite_entity_id = job 254\n",
            "        mask1 = edge_index_to_skill[0,:]==opposite_entity_id\n",
            "        mask2 = edge_index_to_skill[1,:][mask1].squeeze()\n",
            "        if torch.sum(mask1)==0:\n",
            "            return torch.zeros(1, opposite_datax.shape[1])\n",
            "        a = opposite_datax[mask2]\n",
            "        if a.dim() == 1:\n",
            "            return a.unsqueeze(0)\n",
            "        else:\n",
            "            return a.mean(axis=0).squeeze().unsqueeze(0)\n",
            "    \n",
            "    def avg_onehot_of_computed(edge_index_to_skill, opposite_entity_id, opposite_name):\n",
            "        # eg job->skill, oposite_entity_id = job 254\n",
            "        mask1 = edge_index_to_skill[0,:]==opposite_entity_id\n",
            "        mask2 = edge_index_to_skill[1,:][mask1].squeeze()\n",
            "        #onehot = torch.zeros(1,data[opposite_name].num_nodes)\n",
            "        if mask2.numel()==0:\n",
            "            return torch.tensor([[-1]])\n",
            "        elif mask2.dim()==0:\n",
            "            return torch.tensor([[mask2.item()]])\n",
            "        else:\n",
            "            return torch.tensor([[mask2[0].item()]])\n",
            "\n",
            "    \n",
            "    \n",
            "\n",
            "    persons = []\n",
            "\n",
            "\n",
            "    \n",
            "\n",
            "    \n",
            "    for person_i in tqdm(range(data['people'].x.shape[0])):\n",
            "        pid = person_i \n",
            "        supervisor = avg_onehot_of_computed(data['people','supervisor_supervisee','people'].edge_index,person_i,'people')\n",
            "        organization = avg_onehot_of_computed(data['people', 'organization_student', 'organizations'].edge_index,person_i,'organizations')\n",
            "\n",
            "        jobs = avg_of_computed(data['people','rev_job_student','jobs'].edge_index, person_i, jobs_skills)\n",
            "        person = data['people'].x[person_i,:].unsqueeze(0)\n",
            "\n",
            "        persons.append(torch.cat((person,jobs,supervisor,organization),dim=1)) # \n",
            "    \n",
            "    persons = torch.cat((persons),dim=0)\n",
            "    \n",
            "    \n",
            "    dataset = HeteroData()\n",
            "    dataset['people'].x = persons\n",
            "    dataset['courses_and_programs'].x = learning_skills\n",
            "    dataset['people', 'completed','courses_and_programs'].edge_index = data['people', 'rev_course_and_programs_student', 'courses_and_programs'].edge_index\n",
            "    a = data['courses_and_programs','course_and_programs_student','people'].edge_label_index\n",
            "    \n",
            "    dataset['people', 'completed','courses_and_programs'].edge_label_index = torch.cat((a[1,:].unsqueeze(0),a[0,:].unsqueeze(0)),dim=0)\n",
            "    \n",
            "\n",
            "\n",
            "\n",
            "    filename = ROOT_FOLDER+f'FactorizationMachines_Dataset_{split_name}_v1.pt'\n",
            "    if os.path.exists(filename):\n",
            "        raise Exception('File already exists')\n",
            "    else:\n",
            "        torch.save(dataset.to_dict(), filename)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {
            "application/vnd.databricks.v1+cell": {
               "cellMetadata": {
                  "byteLimit": 2048000,
                  "rowLimit": 10000
               },
               "inputWidgets": {},
               "nuid": "e0df9f13-a96a-4552-8944-80b0ce72deaa",
               "showTitle": false,
               "title": ""
            }
         },
         "outputs": [],
         "source": [
            "make_ds(train_data,'train')\n",
            "make_ds(val_data, 'val')\n",
            "make_ds(test_data, 'test') "
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {
            "application/vnd.databricks.v1+cell": {
               "cellMetadata": {
                  "byteLimit": 2048000,
                  "rowLimit": 10000
               },
               "inputWidgets": {},
               "nuid": "de49a9b9-a6ca-481e-80ae-4056fd0016cd",
               "showTitle": false,
               "title": ""
            }
         },
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {
            "application/vnd.databricks.v1+cell": {
               "cellMetadata": {
                  "byteLimit": 2048000,
                  "rowLimit": 10000
               },
               "inputWidgets": {},
               "nuid": "07c96b13-7705-4d79-9ada-53ba8eda9e91",
               "showTitle": false,
               "title": ""
            }
         },
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {
            "application/vnd.databricks.v1+cell": {
               "cellMetadata": {
                  "byteLimit": 2048000,
                  "rowLimit": 10000
               },
               "inputWidgets": {},
               "nuid": "9e467664-94b5-4952-aaea-d1d552b3e5f4",
               "showTitle": false,
               "title": ""
            }
         },
         "outputs": [],
         "source": [
            "\n",
            "    "
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {
            "application/vnd.databricks.v1+cell": {
               "cellMetadata": {
                  "byteLimit": 2048000,
                  "rowLimit": 10000
               },
               "inputWidgets": {},
               "nuid": "e32855ef-db41-4c8c-87fc-cf99c7f3ce6e",
               "showTitle": false,
               "title": ""
            }
         },
         "outputs": [],
         "source": [
            "# sampler\n",
            "\n",
            "def nf_sampler(batch_size, neg_sample_ratio=1, edge_label_index, total_num_target_nodes, num_organizations):\n",
            "    # triplet mode only\n",
            "    # sample some random edges\n",
            "    num_samples = batch_size\n",
            "    sampled_indices = torch.randint(0, edge_label_index.shape[1], (num_samples,))\n",
            "    sampled_edges = edge_label_index[:, sampled_indices]\n",
            "\n",
            "    neg_samples = batch_size*neg_sample_ratio\n",
            "    \n",
            "    s = sampled_edges[0,:].unsqueeze(0)\n",
            "    src_edges = s\n",
            "    for i in range(neg_sample_ratio-1):\n",
            "        src_edges= torch.cat((src_edges,s),dim=1)\n",
            "\n",
            "    sampled_negatives = torch.randint(0, num_organizations, (neg_samples,)).squeeze().unsqueeze(0)\n",
            "   \n",
            "\n",
            "    negative_edge_label_index = torch.cat((src_edges, sampled_negatives),dim=0)\n",
            "    edge_label_indices = torch.cat((sampled_edges, negative_edge_label_index),dim=1)\n",
            "    \n",
            "    return edge_label_indices, torch.cat((torch.ones(batch_size), torch.zeros(neg_samples)))\n",
            "    \n",
            "    \n",
            "    "
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 1,
         "metadata": {},
         "outputs": [
            {
               "ename": "NameError",
               "evalue": "name 'test_data' is not defined",
               "output_type": "error",
               "traceback": [
                  "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                  "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
                  "\u001b[1;32m/home/amos/programming/create_graphds/MakeDataset_for_FactorizationMachine.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/amos/programming/create_graphds/MakeDataset_for_FactorizationMachine.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m test_data\n",
                  "\u001b[0;31mNameError\u001b[0m: name 'test_data' is not defined"
               ]
            }
         ],
         "source": [
            "test_data"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 23,
         "metadata": {
            "application/vnd.databricks.v1+cell": {
               "cellMetadata": {
                  "byteLimit": 2048000,
                  "rowLimit": 10000
               },
               "inputWidgets": {},
               "nuid": "6e5ebb89-6d67-4b33-9bc8-a0b57a6c7e68",
               "showTitle": false,
               "title": ""
            }
         },
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "  0%|          | 0/55638 [00:00<?, ?it/s]"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "100%|██████████| 55638/55638 [00:25<00:00, 2158.97it/s]\n",
                  "100%|██████████| 55796/55796 [00:13<00:00, 4131.37it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "torch.Size([55796, 26])\n",
                  "tensor([293444.,  55638., 264052., 264052., 264052., 264052., 264052., 264052.,\n",
                  "        264052., 264052., 264052., 264052., 264052., 264052., 264052., 264052.,\n",
                  "        264052., 264052., 264052., 264052., 264052., 264052., 264052., 264052.,\n",
                  "        264052., 264052., 264052., 264052., 264052., 264052., 264052., 264052.,\n",
                  "        264052., 264052., 264052., 264052., 264052., 264052., 264052., 264052.,\n",
                  "        264052., 264052., 264052., 264052., 264052., 264052., 264052., 264052.,\n",
                  "        264052., 264052., 264052., 264052., 293444., 293444.,  13613.,  13613.]) torch.Size([56])\n",
                  "tensor([ 55796., 264052., 264052., 264052., 264052., 264052., 264052., 264052.,\n",
                  "        264052., 264052., 264052., 264052., 264052., 264052., 264052., 264052.,\n",
                  "        264052., 264052., 264052., 264052., 264052., 264052., 264052., 264052.,\n",
                  "        264052., 264052.]) torch.Size([26])\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "  0%|          | 192/293444 [00:00<02:32, 1918.57it/s]"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "torch.Size([293444, 56])\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "100%|██████████| 293444/293444 [03:08<00:00, 1554.99it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Filled tensor\n",
                  "persons\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "100%|██████████| 55638/55638 [00:39<00:00, 1395.71it/s]\n",
                  "100%|██████████| 55796/55796 [00:15<00:00, 3510.39it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "torch.Size([55796, 26])\n",
                  "tensor([293444.,  55638., 264052., 264052., 264052., 264052., 264052., 264052.,\n",
                  "        264052., 264052., 264052., 264052., 264052., 264052., 264052., 264052.,\n",
                  "        264052., 264052., 264052., 264052., 264052., 264052., 264052., 264052.,\n",
                  "        264052., 264052., 264052., 264052., 264052., 264052., 264052., 264052.,\n",
                  "        264052., 264052., 264052., 264052., 264052., 264052., 264052., 264052.,\n",
                  "        264052., 264052., 264052., 264052., 264052., 264052., 264052., 264052.,\n",
                  "        264052., 264052., 264052., 264052., 293444., 293444.,  13613.,  13613.]) torch.Size([56])\n",
                  "tensor([ 55796., 264052., 264052., 264052., 264052., 264052., 264052., 264052.,\n",
                  "        264052., 264052., 264052., 264052., 264052., 264052., 264052., 264052.,\n",
                  "        264052., 264052., 264052., 264052., 264052., 264052., 264052., 264052.,\n",
                  "        264052., 264052.]) torch.Size([26])\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "  0%|          | 123/293444 [00:00<04:00, 1222.02it/s]"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "torch.Size([293444, 56])\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "100%|██████████| 293444/293444 [03:53<00:00, 1257.41it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Filled tensor\n",
                  "persons\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "100%|██████████| 55638/55638 [00:40<00:00, 1388.04it/s]\n",
                  "100%|██████████| 55796/55796 [00:16<00:00, 3313.85it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "torch.Size([55796, 26])\n",
                  "tensor([293444.,  55638., 264052., 264052., 264052., 264052., 264052., 264052.,\n",
                  "        264052., 264052., 264052., 264052., 264052., 264052., 264052., 264052.,\n",
                  "        264052., 264052., 264052., 264052., 264052., 264052., 264052., 264052.,\n",
                  "        264052., 264052., 264052., 264052., 264052., 264052., 264052., 264052.,\n",
                  "        264052., 264052., 264052., 264052., 264052., 264052., 264052., 264052.,\n",
                  "        264052., 264052., 264052., 264052., 264052., 264052., 264052., 264052.,\n",
                  "        264052., 264052., 264052., 264052., 293444., 293444.,  13613.,  13613.]) torch.Size([56])\n",
                  "tensor([ 55796., 264052., 264052., 264052., 264052., 264052., 264052., 264052.,\n",
                  "        264052., 264052., 264052., 264052., 264052., 264052., 264052., 264052.,\n",
                  "        264052., 264052., 264052., 264052., 264052., 264052., 264052., 264052.,\n",
                  "        264052., 264052.]) torch.Size([26])\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "  0%|          | 107/293444 [00:00<04:35, 1063.08it/s]"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "torch.Size([293444, 56])\n"
               ]
            },
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "100%|██████████| 293444/293444 [04:00<00:00, 1219.64it/s]\n"
               ]
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Filled tensor\n",
                  "persons\n"
               ]
            }
         ],
         "source": [
            "# this makes label encoded dataset\n",
            "import torch\n",
            "from tqdm.auto import tqdm\n",
            "from torch_geometric.data import HeteroData\n",
            "import os \n",
            "\n",
            "def make_ds_labelencoding(data, split_name):\n",
            "    def get_label_encoding(edge_index_to_skill, entity_id, first_n):\n",
            "        # eg job->skill, entity_id = job 254\n",
            "        mask1 = edge_index_to_skill[0,:]==entity_id\n",
            "        mask2 = edge_index_to_skill[1,:][mask1].squeeze()\n",
            "        \n",
            "        # sort mask2 by its values\n",
            "        if mask2.numel()==0:\n",
            "            return torch.zeros(first_n, dtype=torch.long).unsqueeze(0)\n",
            "        elif mask2.dim()==0:\n",
            "            a = torch.zeros(first_n, dtype=torch.long)\n",
            "            a[0] = mask2.item()+1\n",
            "            return a.unsqueeze(0)\n",
            "        \n",
            "        mask2 = mask2[torch.argsort(mask2)][:first_n]\n",
            "        \n",
            "        # create a Long Tensor of length 50 with zero values\n",
            "        a = torch.zeros(first_n, dtype=torch.long)\n",
            "        # fill the first values with the mask2 values\n",
            "        a[:mask2.shape[0]] = mask2+1\n",
            "        return a.unsqueeze(0)\n",
            "\n",
            "    \n",
            "    job_skills = []\n",
            "    for job_id in tqdm(range(data['jobs'].num_nodes)):\n",
            "        e= get_label_encoding(data['jobs', 'rev_job_skill', 'skills'].edge_index,job_id, 50)\n",
            "        job_id = torch.tensor([[job_id]])\n",
            "       \n",
            "        job_skills.append(torch.cat((job_id,e),dim=1))\n",
            "    \n",
            "    learning_skills = []\n",
            "    for learning_id in tqdm(range(data['courses_and_programs'].num_nodes)):\n",
            "        e  = get_label_encoding(data['courses_and_programs', 'rev_course_and_program_skill', 'skills'].edge_index,learning_id, 25)\n",
            "        learning_id = torch.tensor([[learning_id]])\n",
            "        learning_skills.append(torch.cat((learning_id,e),dim=1))\n",
            "\n",
            "        \n",
            "        \n",
            "    jobs_skills = torch.cat((job_skills),dim=0)\n",
            "    learning_skills  = torch.cat((learning_skills),dim=0)\n",
            "    learning_skills = learning_skills.long()\n",
            "    \n",
            "    #torch.save(torch.cat((learning_skills),dim=0),ROOT_FOLDER+'learnings/'+split_name+'/learnings.pt')\n",
            "    #del learning_skills\n",
            "\n",
            "    # def avg_of_computed(edge_index_to_skill, opposite_entity_id, first_n):\n",
            "    #     # eg job->skill, oposite_entity_id = job 254\n",
            "    #     mask1 = edge_index_to_skill[0,:]==opposite_entity_id\n",
            "    #     mask2 = edge_index_to_skill[1,:][mask1].squeeze()\n",
            "        \n",
            "    #     # sort mask2 by its values\n",
            "    #     mask2 = mask2[torch.argsort(mask2)][:3]\n",
            "        \n",
            "    #     # create a Long Tensor of length 50 with zero values\n",
            "    #     a = torch.zeros(first_n, dtype=torch.long)\n",
            "    #     # fill the first values with the mask2 values\n",
            "    #     a[:mask2.shape[0]] = mask2+1\n",
            "    #     return a\n",
            "  \n",
            "    \n",
            "    def get_job(edge_index_to_skill, opposite_entity_id, datax):\n",
            "        # eg job->skill, oposite_entity_id = job 254\n",
            "        mask1 = edge_index_to_skill[0,:]==opposite_entity_id\n",
            "        mask2 = edge_index_to_skill[1,:][mask1].squeeze()\n",
            "        #onehot = torch.zeros(1,data[opposite_name].num_nodes)\n",
            "        if mask2.numel()==0:\n",
            "            return torch.tensor([[0]])\n",
            "        elif mask2.dim()==0:\n",
            "            return datax[mask2.item()]\n",
            "        else:\n",
            "            return datax[mask2[0].item()]\n",
            "       \n",
            "    \n",
            "    person_dim = 1\n",
            "    jobs_dim = 1\n",
            "    skills_dim = 50\n",
            "    supervisor_dim = 2\n",
            "    organization_dim = 2\n",
            "    \n",
            "    print(learning_skills.shape)\n",
            "    \n",
            "    num_persons= test_data['people'].x.shape[0]\n",
            "    num_jobs = test_data['jobs'].x.shape[0]\n",
            "    num_skills = test_data['skills'].x.shape[0]\n",
            "    num_supervisors = num_persons\n",
            "    num_organizations = test_data['organizations'].x.shape[0]\n",
            "    \n",
            "    \n",
            "    # 1 person, 1 job, 50 skill, 2 supervisor, 2 organization\n",
            "    labelencoding_person = torch.zeros((person_dim+jobs_dim+skills_dim+supervisor_dim+organization_dim))\n",
            "    \n",
            "    # make label encoding vector which has the number of each entity for each dimension\n",
            "    # make a long tensor of size (num_persons, person_dim+jobs_dim+supervisor_dim+organization_dim)\n",
            "    \n",
            "    labelencoding_person[:person_dim] = num_persons\n",
            "    labelencoding_person[person_dim:person_dim+jobs_dim] = num_jobs\n",
            "    labelencoding_person[person_dim+jobs_dim:person_dim+jobs_dim+skills_dim] = num_skills\n",
            "    labelencoding_person[person_dim+jobs_dim+skills_dim:person_dim+jobs_dim+skills_dim+supervisor_dim] = num_supervisors\n",
            "    labelencoding_person[person_dim+jobs_dim+skills_dim+supervisor_dim:] = num_organizations\n",
            "    print(labelencoding_person,labelencoding_person.shape)\n",
            "    learnings_dim = 1\n",
            "    skills_dim2 = 25\n",
            "    num_learnings = test_data['courses_and_programs'].x.shape[0]\n",
            "    labelencoding_learnings = torch.zeros((learnings_dim+skills_dim2))\n",
            "    labelencoding_learnings[:learnings_dim] = num_learnings\n",
            "    labelencoding_learnings[learnings_dim:] = num_skills\n",
            "    print(labelencoding_learnings,labelencoding_learnings.shape)\n",
            "    persons = torch.zeros((data['people'].x.shape[0], person_dim+jobs_dim+skills_dim+supervisor_dim+organization_dim))\n",
            "    xx=True\n",
            "    for person_i in tqdm(range(data['people'].x.shape[0])):\n",
            "        supervisor = get_label_encoding(data['people','supervisor_supervisee','people'].edge_index, person_i, supervisor_dim)\n",
            "        organization = get_label_encoding(data['people', 'organization_student', 'organizations'].edge_index, person_i, organization_dim)\n",
            "\n",
            "        jobs = get_job(data['people','rev_job_student','jobs'].edge_index, person_i, jobs_skills)\n",
            "        person = torch.LongTensor([[person_i]])\n",
            "\n",
            "        # Assign each feature to the corresponding row in the tensor\n",
            "        persons[person_i, :person_dim] = person\n",
            "        persons[person_i, person_dim:person_dim+jobs_dim+skills_dim] = jobs\n",
            "        persons[person_i, person_dim+jobs_dim+skills_dim:person_dim+jobs_dim+skills_dim+supervisor_dim] = supervisor\n",
            "        persons[person_i, person_dim+jobs_dim+skills_dim+supervisor_dim:] = organization\n",
            "        \n",
            "        if xx:\n",
            "            xx=False\n",
            "            print(persons.shape)\n",
            "\n",
            "    print('Filled tensor')\n",
            "\n",
            "    \n",
            "    \n",
            "    dataset = HeteroData()\n",
            "    print('persons')\n",
            "    dataset['people'].x = persons.long()\n",
            "    dataset['people'].labelencoding = labelencoding_person.long()\n",
            "    dataset['courses_and_programs'].x = learning_skills.long()\n",
            "    dataset['courses_and_programs'].labelencoding = labelencoding_learnings.long()\n",
            "    dataset['people', 'completed','courses_and_programs'].edge_index = data['people', 'rev_course_and_programs_student', 'courses_and_programs'].edge_index\n",
            "    a = data['courses_and_programs','course_and_programs_student','people'].edge_label_index\n",
            "    \n",
            "    dataset['people', 'completed','courses_and_programs'].edge_label_index = torch.cat((a[1,:].unsqueeze(0),a[0,:].unsqueeze(0)),dim=0)\n",
            "    \n",
            "\n",
            "    filename = ROOT_FOLDER+f'FactorizationMachines_Dataset_{split_name}_labelencoded_v2.pt'\n",
            "    if os.path.exists(filename):\n",
            "        raise Exception('File already exists')\n",
            "    else:\n",
            "        torch.save(dataset.to_dict(), filename)\n",
            "\n",
            "make_ds_labelencoding(train_data,'train')\n",
            "make_ds_labelencoding(val_data,'val')\n",
            "make_ds_labelencoding(test_data,'test')"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 16,
         "metadata": {},
         "outputs": [],
         "source": [
            "person_dim = 1\n",
            "jobs_dim = 51\n",
            "supervisor_dim = 2\n",
            "organization_dim = 2\n",
            "\n",
            "num_persons= test_data['people'].x.shape[0]\n",
            "num_jobs = test_data['jobs'].x.shape[0]\n",
            "num_supervisors = num_persons\n",
            "num_organizations = test_data['organizations'].x.shape[0]\n",
            "\n",
            "\n",
            "\n",
            "# make label encoding vector which has the number of each entity for each dimension\n",
            "# make a long tensor of size (num_persons, person_dim+jobs_dim+supervisor_dim+organization_dim)\n",
            "labelencoding_person = torch.zeros((person_dim+jobs_dim+supervisor_dim+organization_dim))\n",
            "labelencoding_person[:person_dim] = num_persons\n",
            "labelencoding_person[person_dim:person_dim+jobs_dim] = num_jobs\n",
            "labelencoding_person[person_dim+jobs_dim:person_dim+jobs_dim+supervisor_dim] = num_supervisors\n",
            "labelencoding_person[person_dim+jobs_dim+supervisor_dim:] = num_organizations\n",
            "\n",
            "learnings_dim = 1\n",
            "skills_dim = 50\n",
            "num_skills = test_data['skills'].x.shape[0]\n",
            "num_learnings = test_data['courses_and_programs'].x.shape[0]\n",
            "labelencoding_learnings = torch.zeros((learnings_dim+skills_dim))\n",
            "labelencoding_learnings[:learnings_dim] = num_learnings\n",
            "labelencoding_learnings[learnings_dim:] = num_skills"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 26,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "'FactorizationMachines_Dataset_train_labelencoded_v1.pt'"
                  ]
               },
               "execution_count": 26,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "ROOT_FOLDER+f'FactorizationMachines_Dataset_{\"train\"}_labelencoded_v1.pt'"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 27,
         "metadata": {},
         "outputs": [],
         "source": [
            "data = HeteroData.from_dict(torch.load(ROOT_FOLDER+f'FactorizationMachines_Dataset_{\"train\"}_labelencoded_v1.pt'))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 32,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "torch.float32"
                  ]
               },
               "execution_count": 32,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "data['people'].x.dtype"
         ]
      }
   ],
   "metadata": {
      "application/vnd.databricks.v1+notebook": {
         "dashboards": [],
         "language": "python",
         "notebookMetadata": {
            "pythonIndentUnit": 4
         },
         "notebookName": "MakeDataset_for_FactorizationMachine",
         "widgets": {}
      },
      "kernelspec": {
         "display_name": "pyg_torch21",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.10.12"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 0
}
