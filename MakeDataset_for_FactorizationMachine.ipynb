{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fbc6e4a8-59f7-4d4a-bfa6-6824af347441",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import pytroch geometric hetero data\n",
    "# from torch_geometric.data import HeteroData\n",
    "# import torch\n",
    "# data = HeteroData.from_dict(torch.load('HeteroData_Learnings_normalized_triangles_withadditionaldata_v1.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "995d537c-463c-456e-b823-1578ec3f3389",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if \"DATABRICKS_RUNTIME_VERSION\" in os.environ and not 'installed_libs' in globals():\n",
    "  #CUDA = 'cu121' \n",
    "  installed_libs = True\n",
    "  \n",
    "  \n",
    "  !pip install torch==2.1.0  torchvision==0.16.0 torchtext==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu121\n",
    "  import torch\n",
    "  #os.environ['TORCH'] = torch.__version__\n",
    "  #print(torch.__version__)\n",
    "  #torch_version = '2.0.0+cu118'\n",
    "  \n",
    "  #!pip install pyg_lib torch_scatter torch_sparse torch_cluster -f https://data.pyg.org/whl/torch-2.1.0+${CUDA}.html # torch_spline_conv\n",
    "  !pip install torch_geometric\n",
    "  !pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.1.0+cu121.html\n",
    "  #!pip install torch_sparse -f https://data.pyg.org/whl/torch-2.1.0+${CUDA}.html\n",
    "  #!pip install torch_scatter -f https://data.pyg.org/whl/torch-2.1.0+${CUDA}.html\n",
    "  #!pip install pyg_lib -f https://data.pyg.org/whl/torch-2.1.0+${CUDA}.html\n",
    "  !pip install sentence-transformers\n",
    "  !pip install torcheval\n",
    "  !pip install matplotlib\n",
    "  !pip install pandas\n",
    "  !pip install tensorboard\n",
    "  \n",
    "if \"DATABRICKS_RUNTIME_VERSION\" in os.environ:\n",
    "  ROOT_FOLDER = '/dbfs/FileStore/GraphNeuralNetworks/'\n",
    "else:\n",
    "  ROOT_FOLDER = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3529f9f-8ec0-4554-ac0f-9562ea79b6e4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from learnings_sampler_v1 import get_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "148b0a02-d22f-4202-a5fa-7115c0b66e45",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_data, val_data, test_data = get_datasets(get_edge_attr=False,filename=ROOT_FOLDER+'HeteroData_Learnings_normalized_triangles_withadditionaldata_v1.pt', filter_top_k=True, top_k=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a0a3b3c-ed0b-4390-a571-02fc765958b3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# people have jobs, if multiple, we average\n",
    "# jobs have skills, if multiple, we average\n",
    "#  \n",
    "\n",
    "# so row is [pid, lid][person learning person_features person_jobs job_skills target_watched]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5309cdcf-906d-40b1-935a-ad538d63ecf9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a52bf379-b6d1-4741-b56f-2e2ba8521dc6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from torch_geometric.data import HeteroData\n",
    "import os \n",
    "\n",
    "def make_ds(data, split_name):\n",
    "    def skills_avg(edge_index_to_skill, entity_id):\n",
    "        # eg job->skill, entity_id = job 254\n",
    "        mask1 = edge_index_to_skill[0,:]==entity_id\n",
    "        mask2 = edge_index_to_skill[1,:][mask1].squeeze()\n",
    "        if torch.sum(mask1)==0:\n",
    "            return torch.zeros(1, data['skills'].x.shape[1])\n",
    "        a = data['skills'].x[mask2]\n",
    "        if a.dim() == 1:\n",
    "            return a.unsqueeze(0)\n",
    "        else:\n",
    "            return a.mean(axis=0).squeeze().unsqueeze(0)\n",
    "\n",
    "    \n",
    "    job_skills = []\n",
    "    for job_id in tqdm(range(data['jobs'].num_nodes)):\n",
    "        e= skills_avg(data['jobs', 'rev_job_skill', 'skills'].edge_index,job_id)\n",
    "        job = data['jobs'].x[job_id,:].unsqueeze(0)\n",
    "        \n",
    "        job_skills.append(torch.cat((job,e),dim=1))\n",
    "    \n",
    "    learning_skills = []\n",
    "    for learning_id in tqdm(range(data['courses_and_programs'].num_nodes)):\n",
    "        e  = skills_avg(data['courses_and_programs', 'rev_course_and_program_skill', 'skills'].edge_index,learning_id)\n",
    "        learning = data['courses_and_programs'].x[learning_id,:].unsqueeze(0)\n",
    "        learning_skills.append(torch.cat((learning,e),dim=1))\n",
    "      \n",
    "        \n",
    "        \n",
    "    jobs_skills = torch.cat((job_skills),dim=0)\n",
    "    \n",
    "    torch.save(torch.cat((learning_skills),dim=0),ROOT_FOLDER+'learnings/'+split_name+'/learnings.pt')\n",
    "    del learning_skills\n",
    "\n",
    "    def avg_of_computed(edge_index_to_skill, opposite_entity_id, opposite_datax):\n",
    "        # eg job->skill, oposite_entity_id = job 254\n",
    "        mask1 = edge_index_to_skill[0,:]==opposite_entity_id\n",
    "        mask2 = edge_index_to_skill[1,:][mask1].squeeze()\n",
    "        if torch.sum(mask1)==0:\n",
    "            return torch.zeros(1, opposite_datax.shape[1])\n",
    "        a = opposite_datax[mask2]\n",
    "        if a.dim() == 1:\n",
    "            return a.unsqueeze(0)\n",
    "        else:\n",
    "            return a.mean(axis=0).squeeze().unsqueeze(0)\n",
    "    \n",
    "    def avg_onehot_of_computed(edge_index_to_skill, opposite_entity_id, opposite_name):\n",
    "        # eg job->skill, oposite_entity_id = job 254\n",
    "        mask1 = edge_index_to_skill[0,:]==opposite_entity_id\n",
    "        mask2 = edge_index_to_skill[1,:][mask1].squeeze()\n",
    "        #onehot = torch.zeros(1,data[opposite_name].num_nodes)\n",
    "        if mask2.numel()==0:\n",
    "            return torch.tensor([[-1]])\n",
    "        elif mask2.dim()==0:\n",
    "            return torch.tensor([[mask2.item()]])\n",
    "        else:\n",
    "            return torch.tensor([[mask2[0].item()]])\n",
    "        if mask2.dim()==0:\n",
    "            onehot[0,mask2.item()] = 1\n",
    "        \n",
    "        else:\n",
    "            for i in mask2:\n",
    "                onehot[0,i] = 1\n",
    "\n",
    "        return onehot\n",
    "    \n",
    "    \n",
    "\n",
    "    persons = []\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    for person_i in tqdm(range(data['people'].x.shape[0])):\n",
    "        pid = person_i \n",
    "        supervisor = avg_onehot_of_computed(data['people','supervisor_supervisee','people'].edge_index,person_i,'people')\n",
    "        organization = avg_onehot_of_computed(data['people', 'organization_student', 'organizations'].edge_index,person_i,'organizations')\n",
    "\n",
    "        jobs = avg_of_computed(data['people','rev_job_student','jobs'].edge_index, person_i, jobs_skills)\n",
    "        person = data['people'].x[person_i,:].unsqueeze(0)\n",
    "\n",
    "        persons.append(torch.cat((person,jobs,supervisor,organization),dim=1)) # \n",
    "    \n",
    "    persons = torch.cat((persons),dim=0)\n",
    "    \n",
    "    dataset = HeteroData()\n",
    "    dataset['people'].x = persons\n",
    "  \n",
    "    dataset['courses_and_programs'].x =  torch.load(ROOT_FOLDER+'learnings/'+split_name+'/learnings.pt')\n",
    "    dataset['people', 'completed','courses_and_programs']['edge_index'] = data['people', 'rev_course_and_programs_student', 'courses_and_programs'].edge_index\n",
    "    a = data['courses_and_programs','course_and_programs_student','people'].edge_label_index\n",
    "    \n",
    "    dataset['people', 'completed','courses_and_programs']['edge_label_index'] = torch.cat((a[1,:].unsqueeze(0),a[0,:].unsqueeze(0)),dim=0)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    filename = ROOT_FOLDER+f'FactorizationMachines_Dataset_{split_name}_v1.pt'\n",
    "    if os.path.exists(filename):\n",
    "        raise Exception('File already exists')\n",
    "    else:\n",
    "        torch.save(dataset.to_dict(), filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0df9f13-a96a-4552-8944-80b0ce72deaa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#make_ds(train_data,'train')\n",
    "make_ds(val_data, 'val')\n",
    "make_ds(test_data, 'test') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de49a9b9-a6ca-481e-80ae-4056fd0016cd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07c96b13-7705-4d79-9ada-53ba8eda9e91",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e467664-94b5-4952-aaea-d1d552b3e5f4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e32855ef-db41-4c8c-87fc-cf99c7f3ce6e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# sampler\n",
    "\n",
    "def nf_sampler(batch_size, neg_sample_ratio=1, edge_label_index, total_num_target_nodes, num_organizations):\n",
    "    # triplet mode only\n",
    "    # sample some random edges\n",
    "    num_samples = batch_size\n",
    "    sampled_indices = torch.randint(0, edge_label_index.shape[1], (num_samples,))\n",
    "    sampled_edges = edge_label_index[:, sampled_indices]\n",
    "\n",
    "    neg_samples = batch_size*neg_sample_ratio\n",
    "    \n",
    "    s = sampled_edges[0,:].unsqueeze(0)\n",
    "    src_edges = s\n",
    "    for i in range(neg_sample_ratio-1):\n",
    "        src_edges= torch.cat((src_edges,s),dim=1)\n",
    "\n",
    "    sampled_negatives = torch.randint(0, num_organizations, (neg_samples,)).squeeze().unsqueeze(0)\n",
    "   \n",
    "\n",
    "    negative_edge_label_index = torch.cat((src_edges, sampled_negatives),dim=0)\n",
    "    edge_label_indices = torch.cat((sampled_edges, negative_edge_label_index),dim=1)\n",
    "    \n",
    "    return edge_label_indices, torch.cat((torch.ones(batch_size), torch.zeros(neg_samples)))\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e5ebb89-6d67-4b33-9bc8-a0b57a6c7e68",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "MakeDataset_for_FactorizationMachine",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "pyg_torch21",
   "language": "python",
   "name": "pyg_torch21"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
