{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Reciprocal Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if \"DATABRICKS_RUNTIME_VERSION\" in os.environ and not 'installed_libs' in globals():\n",
    "  #CUDA = 'cu121' \n",
    "  installed_libs = True\n",
    "  \n",
    "  \n",
    "  !pip install torch==2.1.0  torchvision==0.16.0 torchtext==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu121\n",
    "  import torch\n",
    "  #os.environ['TORCH'] = torch.__version__\n",
    "  #print(torch.__version__)\n",
    "  #torch_version = '2.0.0+cu118'\n",
    "  \n",
    "  #!pip install pyg_lib torch_scatter torch_sparse torch_cluster -f https://data.pyg.org/whl/torch-2.1.0+${CUDA}.html # torch_spline_conv\n",
    "  !pip install torch_geometric\n",
    "  !pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.1.0+cu121.html\n",
    "  #!pip install torch_sparse -f https://data.pyg.org/whl/torch-2.1.0+${CUDA}.html\n",
    "  #!pip install torch_scatter -f https://data.pyg.org/whl/torch-2.1.0+${CUDA}.html\n",
    "  #!pip install pyg_lib -f https://data.pyg.org/whl/torch-2.1.0+${CUDA}.html\n",
    "  !pip install sentence-transformers\n",
    "  !pip install torcheval\n",
    "  !pip install matplotlib\n",
    "  !pip install pandas\n",
    "  !pip install tensorboard\n",
    "  !pip install torchfm\n",
    "  \n",
    "if \"DATABRICKS_RUNTIME_VERSION\" in os.environ:\n",
    "  ROOT_FOLDER = '/dbfs/FileStore/GraphNeuralNetworks/'\n",
    "else:\n",
    "  ROOT_FOLDER = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampler\n",
    "\n",
    "def nf_sampler(batch_size, neg_sample_ratio, edge_label_index, edge_label, num_learnings):\n",
    "    # triplet mode only\n",
    "    # sample some random edges\n",
    "    edge_label_index1 = edge_label_index[edge_label==1]\n",
    "    num_samples = batch_size\n",
    "    #sampled_indices = torch.randint(0, edge_label_index.shape[1], (num_samples,), replacement=False)\n",
    "    sampled_indices = torch.randperm(edge_label_index1.shape[1])[:num_samples]\n",
    "    sampled_edges = edge_label_index1[:, sampled_indices]\n",
    "    # remove sampled edges from edge_label_index with mask\n",
    "    mask = torch.ones(edge_label_index1.shape[1], dtype=torch.bool)\n",
    "    mask[sampled_indices] = False\n",
    "    edge_label_index1 = edge_label_index1[:, mask]\n",
    "    \n",
    "    assert neg_sample_ratio >= 1\n",
    "    neg_samples = sampled_indices.shape[0]*neg_sample_ratio\n",
    "    \n",
    "    s = sampled_edges[0,:].unsqueeze(0)\n",
    "    src_edges = s\n",
    "    for i in range(neg_sample_ratio-1):\n",
    "        src_edges= torch.cat((src_edges,s),dim=1)\n",
    "\n",
    "    sampled_negatives = torch.randint(0, num_learnings, (neg_samples,)).squeeze().unsqueeze(0)\n",
    "   \n",
    "   \n",
    "    negative_edge_label_index = torch.cat((src_edges, sampled_negatives),dim=0)\n",
    "    edge_label_indices = torch.cat((sampled_edges, negative_edge_label_index),dim=1)\n",
    "    new_edge_label_index = edge_label_index\n",
    "    batch_edge_label_index = edge_label_indices\n",
    "    return new_edge_label_index, batch_edge_label_index, torch.cat((torch.ones(batch_size), torch.zeros(neg_samples)))\n",
    "\n",
    "def nf_loader(edge_label_index, batch_size, num_learnings, neg_sample_ratio):\n",
    "    while edge_label_index.shape[1] > 0:\n",
    "        new_edge_label_index, batch_edge_label_index, batch_labels = nf_sampler(batch_size, neg_sample_ratio, edge_label_index, num_learnings)\n",
    "        edge_label_index = new_edge_label_index\n",
    "        yield batch_edge_label_index, batch_labels\n",
    "    \n",
    "\n",
    "def get_total_minibatch_count_fm(batch_size, edge_label_index):\n",
    "    return int((edge_label_index.shape[1]+batch_size)//batch_size)\n",
    "import torch\n",
    "from torch_geometric.data import HeteroData\n",
    "#data = HeteroData(torch.load('factorization_machines_dataset.pt'))\n",
    "train_data = HeteroData(torch.load(ROOT_FOLDER+'FactorizationMachines_Dataset_train_labelencoded_v2.pt'))\n",
    "val_data = HeteroData(torch.load(ROOT_FOLDER+'FactorizationMachines_Dataset_val_labelencoded_v2.pt'))\n",
    "test_data = HeteroData(torch.load(ROOT_FOLDER+'FactorizationMachines_Dataset_test_labelencoded_v2.pt'))\n",
    "\n",
    "train_embeddings = HeteroData(torch.load(ROOT_FOLDER+'FactorizationMachines_Dataset_train_v1.pt'))\n",
    "val_embeddings = HeteroData(torch.load(ROOT_FOLDER+'FactorizationMachines_Dataset_val_v1.pt'))\n",
    "val_embeddings = HeteroData(torch.load(ROOT_FOLDER+'FactorizationMachines_Dataset_val_v1.pt'))\n",
    "test_embeddings = HeteroData(torch.load(ROOT_FOLDER+'FactorizationMachines_Dataset_val_v1.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([56]) torch.Size([26])\n",
      "tensor([293444,  55638, 264052, 264052, 264052, 264052, 264052, 264052, 264052,\n",
      "        264052, 264052, 264052, 264052, 264052, 264052, 264052, 264052, 264052,\n",
      "        264052, 264052, 264052, 264052, 264052, 264052, 264052, 264052, 264052,\n",
      "        264052, 264052, 264052, 264052, 264052, 264052, 264052, 264052, 264052,\n",
      "        264052, 264052, 264052, 264052, 264052, 264052, 264052, 264052, 264052,\n",
      "        264052, 264052, 264052, 264052, 264052, 264052, 264052, 293444, 293444,\n",
      "         13613,  13613,  55796, 264052, 264052, 264052, 264052, 264052, 264052,\n",
      "        264052, 264052, 264052, 264052, 264052, 264052, 264052, 264052, 264052,\n",
      "        264052, 264052, 264052, 264052, 264052, 264052, 264052, 264052, 264052,\n",
      "        264052])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (node_type_embedding): Embedding(6, 1)\n",
       "  (head): TransE(6, num_relations=22, hidden_channels=1)\n",
       "  (fm): FactorizationMachineModel(\n",
       "    (embedding): FeaturesEmbedding(\n",
       "      (embedding): Embedding(20822892, 16)\n",
       "    )\n",
       "    (linear): FeaturesLinear(\n",
       "      (fc): Embedding(20822892, 1)\n",
       "    )\n",
       "    (fm): FactorizationMachine()\n",
       "  )\n",
       "  (layer1): Linear(in_features=3167, out_features=512, bias=True)\n",
       "  (layer2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (layer3): Linear(in_features=257, out_features=256, bias=True)\n",
       "  (fc_output): Linear(in_features=256, out_features=256, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from models.TransE import TransE\n",
    "from models.DistMult import DistMult\n",
    "from models.FactorizationMachineModel import FactorizationMachineModel\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, fm : torch.nn.Module, head, node_types, edge_types, ggn_output_dim, pnorm=1, num_supervisors=0, num_organizations=0):\n",
    "        super().__init__()\n",
    "        # edge_type onehot lookup table with keys\n",
    "        # node_type onehot lookup table with keys\n",
    "        self.node_type_embedding = torch.nn.Embedding(len(node_types), ggn_output_dim) # hidden channels should be the output dim of gnn\n",
    "        self.num_supervisors = num_supervisors\n",
    "        self.num_organizations = num_organizations\n",
    "        self.edge_types = edge_types\n",
    "        for edge_type in edge_types:\n",
    "            if edge_type[1].startswith('rev_'):\n",
    "                self.edge_types.remove(edge_type)\n",
    "        \n",
    "        # create edge to int mapping\n",
    "        self.edgeindex_lookup = {edge_type:torch.tensor(i)  for i, edge_type in enumerate(edge_types)}\n",
    "            \n",
    "        if head=='TransE': \n",
    "            self.head = TransE(len(node_types), len(edge_types) , ggn_output_dim, p_norm= pnorm)  # KGE head with loss function\n",
    "        elif head=='DistMult':\n",
    "            self.head = DistMult(len(node_types), len(edge_types) , ggn_output_dim, p_norm= pnorm)  # KGE head with loss function\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        \n",
    "        self.fm = fm\n",
    "       \n",
    "     \n",
    "        self.layer1 = torch.nn.Linear(3167,512)\n",
    "        self.layer2 = torch.nn.Linear(512,256)\n",
    "        self.layer3 = torch.nn.Linear(257,256)\n",
    "        self.fc_output = torch.nn.Linear(256, 256)\n",
    "\n",
    "    def forward(self, hetero_data, hetero_data_embeddings, edge_label_index, edge_label):\n",
    "        \n",
    "    \n",
    "        people = hetero_data['people'].x[edge_label_index[0,:],:]\n",
    "        # last two columns in people are the indices of onehot, so change them to full onehot supervisor and organization\n",
    "        #supervisors = torch.nn.functional.one_hot(people[:,-2].to(torch.int64), num_classes=self.num_supervisors).to(torch.float32)\n",
    "        #organizations = torch.nn.functional.one_hot(people[:,-1].to(torch.int64), num_classes=self.num_organizations).to(torch.float32)\n",
    "        #people = torch.cat((people[:,:-2], supervisors, organizations), dim=1)\n",
    "        people_embeddings = hetero_data_embeddings['people'].x[edge_label_index[0,:],:]\n",
    "                        \n",
    "        learnings = hetero_data['courses_and_programs'].x[edge_label_index[1,:],:]\n",
    "        learning_embeddings = hetero_data_embeddings['courses_and_programs'].x[edge_label_index[1,:],:]\n",
    "        \n",
    "        x1 = torch.cat((people_embeddings, learning_embeddings),dim=1)\n",
    "        x1 = self.layer1(x1).relu()\n",
    "        x1 = self.layer2(x1).relu()\n",
    "        x2 = torch.cat((people,learnings),dim=1)\n",
    "        x2 = self.fm(x2)\n",
    "        #scores = x2\n",
    "        x3 = self.layer3(torch.cat((x1,x2.unsqueeze(1)),dim=1)).relu()\n",
    "        scores = self.fc_output(x3).relu()\n",
    "        return scores\n",
    "        pos_scores = scores[edge_label==1]\n",
    "        neg_scores = scores[edge_label==0]\n",
    "            \n",
    "        \n",
    "        return F.margin_ranking_loss(\n",
    "            pos_scores,\n",
    "            neg_scores,\n",
    "            target=torch.ones_like(pos_scores), # 1 for similarity, -1 for dissimilarity\n",
    "            margin=0.5\n",
    "        )\n",
    "        \n",
    "    \n",
    "out_channels = 1\n",
    "hidden_channels = 16\n",
    "num_heads = 0\n",
    "num_layers = 0\n",
    "pnorm = 2\n",
    "head = 'TransE'\n",
    "#gnn = HGT(hidden_channels=out_channels, out_channels=out_channels, num_heads=num_heads, num_layers=num_layers, node_types=train_data.node_types, data_metadata=metadata)\n",
    "filename = 'HeteroData_Learnings_normalized_triangles_withadditionaldata_v1.pt'\n",
    "data_forlookup = HeteroData.from_dict(torch.load(ROOT_FOLDER+filename))\n",
    "num_supervisors = data_forlookup['people'].num_nodes\n",
    "num_organizations = data_forlookup['organizations'].num_nodes\n",
    "metadata = data_forlookup.metadata()\n",
    "# add selfloops\n",
    "for node_type in data_forlookup.node_types:\n",
    "    metadata[1].append((node_type, 'self_loop', node_type))  \n",
    "    \n",
    "    \n",
    "\n",
    "del data_forlookup\n",
    "print(train_data['people'].labelencoding.shape, train_data['courses_and_programs'].labelencoding.shape)  \n",
    "field_dims = torch.cat((train_data['people'].labelencoding,train_data['courses_and_programs'].labelencoding), dim=0)\n",
    "print(field_dims)\n",
    "# convert the field dims to integer\n",
    "field_dims = field_dims.to(torch.int64)\n",
    "fm = FactorizationMachineModel(\n",
    "    field_dims=field_dims,\n",
    "        embed_dim=hidden_channels)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fm_and_dense_folderfile = 'models/learningpeople_factorizationmachines_densemargin05aee_20231104_161222_pnorm2_llr2e-05_bs32_neighbors__head_TransE_hiddenchannels_16_outchannels_1_numheads_0_numlayers_0/model_samplesseen713728.pt'\n",
    "\n",
    "\n",
    "modelfmdense = Model(fm, head=head, node_types=metadata[0], edge_types=metadata[1], ggn_output_dim=out_channels, pnorm=pnorm, num_supervisors=num_supervisors, num_organizations=num_organizations)\n",
    "#torch_geometric.compile(model, dynamic=True)\n",
    "modelfmdense.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'EdgeStorage' object has no attribute 'edge_label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/amos/programming/create_graphds/learnings_eval_v1_factorizationmachine_and_dense.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/amos/programming/create_graphds/learnings_eval_v1_factorizationmachine_and_dense.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m start_epoch \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/amos/programming/create_graphds/learnings_eval_v1_factorizationmachine_and_dense.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m batch_size \u001b[39m=\u001b[39m \u001b[39m32\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/amos/programming/create_graphds/learnings_eval_v1_factorizationmachine_and_dense.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m train_loader \u001b[39m=\u001b[39m nf_loader(train_data[\u001b[39m'\u001b[39m\u001b[39mpeople\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mcompleted\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mcourses_and_programs\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39medge_label_index\u001b[39m.\u001b[39mto(\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m), train_data[\u001b[39m'\u001b[39;49m\u001b[39mpeople\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mcompleted\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mcourses_and_programs\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49medge_label\u001b[39m.\u001b[39mto(\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m), batch_size, num_learnings, neg_sample_ratio)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/amos/programming/create_graphds/learnings_eval_v1_factorizationmachine_and_dense.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m val_loader \u001b[39m=\u001b[39m nf_loader(val_data[\u001b[39m'\u001b[39m\u001b[39mpeople\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mcompleted\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mcourses_and_programs\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39medge_label_index\u001b[39m.\u001b[39mto(\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m),val_data[\u001b[39m'\u001b[39m\u001b[39mpeople\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mcompleted\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mcourses_and_programs\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39medge_label\u001b[39m.\u001b[39mto(\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m), batch_size, num_learnings, neg_sample_ratio)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/amos/programming/create_graphds/learnings_eval_v1_factorizationmachine_and_dense.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mepoch1\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/mambaforge/envs/pyg_torch21/lib/python3.10/site-packages/torch_geometric/data/storage.py:87\u001b[0m, in \u001b[0;36mBaseStorage.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[key]\n\u001b[1;32m     86\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[0;32m---> 87\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[1;32m     88\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     89\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'EdgeStorage' object has no attribute 'edge_label'"
     ]
    }
   ],
   "source": [
    "### init model\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "train_data = train_data.to(device)\n",
    "val_data = val_data.to(device)\n",
    "train_embeddings = train_embeddings.to(device)\n",
    "val_embeddings = val_embeddings.to(device)\n",
    "modelfmdense.train()\n",
    "start_epoch = 1\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "train_loader = nf_loader(train_data['people','completed','courses_and_programs'].edge_label_index.to('cpu'), train_data['people','completed','courses_and_programs'].edge_label.to('cpu'), batch_size, num_learnings, neg_sample_ratio)\n",
    "val_loader = nf_loader(val_data['people','completed','courses_and_programs'].edge_label_index.to('cpu'),val_data['people','completed','courses_and_programs'].edge_label.to('cpu'), batch_size, num_learnings, neg_sample_ratio)\n",
    "print('epoch1')\n",
    "modelfmdense.eval()\n",
    "modelfmdense.to(device)\n",
    "for i, (batch_edge_label_index, labels) in tqdm(enumerate(train_loader), total=1):\n",
    "    if not batch_edge_label_index.shape[1] != labels.shape[0]:\n",
    "        \n",
    "        loss = modelfmdense(train_data, train_embeddings, batch_edge_label_index.to(device), labels.to(device))\n",
    "        break\n",
    "modelfmdense.to('cpu')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'edge_index': tensor([[ 47782, 110396, 140611,  ..., 230612, 245078, 150101],\n",
       "        [  8108,  38872,  25608,  ...,  25609,  28551,  25046]],\n",
       "       device='cuda:0'), 'edge_label_index': tensor([[237571, 232648, 223362,  ..., 136880, 291335, 243006],\n",
       "        [ 33929,  15584,  28839,  ...,  25372,  34527,  27229]],\n",
       "       device='cuda:0')}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['people','completed','courses_and_programs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelfmdense.load_state_dict(torch.load(fm_and_dense_folderfile)['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from models.TransE import TransE\n",
    "from models.DistMult import DistMult\n",
    "from models.FactorizationMachineModel import FactorizationMachineModel\n",
    "import torch_geometric\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, fm : torch.nn.Module, head, node_types, edge_types, ggn_output_dim, pnorm=1, num_supervisors=0, num_organizations=0):\n",
    "        super().__init__()\n",
    "        # edge_type onehot lookup table with keys\n",
    "        # node_type onehot lookup table with keys\n",
    "        self.node_type_embedding = torch.nn.Embedding(len(node_types), ggn_output_dim) # hidden channels should be the output dim of gnn\n",
    "        self.num_supervisors = num_supervisors\n",
    "        self.num_organizations = num_organizations\n",
    "        self.edge_types = edge_types\n",
    "        for edge_type in edge_types:\n",
    "            if edge_type[1].startswith('rev_'):\n",
    "                self.edge_types.remove(edge_type)\n",
    "        \n",
    "        # create edge to int mapping\n",
    "        self.edgeindex_lookup = {edge_type:torch.tensor(i)  for i, edge_type in enumerate(edge_types)}\n",
    "            \n",
    "        if head=='TransE': \n",
    "            self.head = TransE(len(node_types), len(edge_types) , ggn_output_dim, p_norm= pnorm)  # KGE head with loss function\n",
    "        elif head=='DistMult':\n",
    "            self.head = DistMult(len(node_types), len(edge_types) , ggn_output_dim, p_norm= pnorm)  # KGE head with loss function\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        \n",
    "        self.fm = fm\n",
    "       \n",
    "     \n",
    "        self.layer1 = torch.nn.Linear(3167,512)\n",
    "        self.layer2 = torch.nn.Linear(512,256)\n",
    "        self.layer3 = torch.nn.Linear(257,256)\n",
    "        self.fc_output = torch.nn.Linear(256, 256)\n",
    "\n",
    "    def forward(self, hetero_data, hetero_data_embeddings, edge_label_index, edge_label):\n",
    "        \n",
    "    \n",
    "        people = hetero_data['people'].x[edge_label_index[0,:],:]\n",
    "        # last two columns in people are the indices of onehot, so change them to full onehot supervisor and organization\n",
    "        #supervisors = torch.nn.functional.one_hot(people[:,-2].to(torch.int64), num_classes=self.num_supervisors).to(torch.float32)\n",
    "        #organizations = torch.nn.functional.one_hot(people[:,-1].to(torch.int64), num_classes=self.num_organizations).to(torch.float32)\n",
    "        #people = torch.cat((people[:,:-2], supervisors, organizations), dim=1)\n",
    "        #people_embeddings = hetero_data_embeddings['people'].x[edge_label_index[0,:],:]\n",
    "                        \n",
    "        learnings = hetero_data['courses_and_programs'].x[edge_label_index[1,:],:]\n",
    "        #learning_embeddings = hetero_data_embeddings['courses_and_programs'].x[edge_label_index[1,:],:]\n",
    "        \n",
    "        #x1 = torch.cat((people_embeddings, learning_embeddings),dim=1)\n",
    "        #x1 = self.layer1(x1).relu()\n",
    "        #x1 = self.layer2(x1).relu()\n",
    "        x2 = torch.cat((people,learnings),dim=1)\n",
    "        x2 = self.fm(x2)\n",
    "        scores = x2\n",
    "        #x3 = self.layer3(torch.cat((x1,x2.unsqueeze(1)),dim=1)).relu()\n",
    "        #scores = self.fc_output(x3).relu()\n",
    "        return scores\n",
    "        pos_scores = scores[edge_label==1]\n",
    "        neg_scores = scores[edge_label==0]\n",
    "        \n",
    "\n",
    "        return F.margin_ranking_loss(\n",
    "            pos_scores,\n",
    "            neg_scores,\n",
    "            target=torch.ones_like(pos_scores), # 1 for similarity, -1 for dissimilarity\n",
    "            margin=0.5\n",
    "        )\n",
    "        \n",
    "    \n",
    "out_channels = 1\n",
    "hidden_channels = 16\n",
    "num_heads = 0\n",
    "num_layers = 0\n",
    "pnorm = 2\n",
    "head = 'TransE'\n",
    "#gnn = HGT(hidden_channels=out_channels, out_channels=out_channels, num_heads=num_heads, num_layers=num_layers, node_types=train_data.node_types, data_metadata=metadata)\n",
    "filename = 'HeteroData_Learnings_normalized_triangles_withadditionaldata_v1.pt'\n",
    "data_forlookup = HeteroData.from_dict(torch.load(ROOT_FOLDER+filename))\n",
    "num_supervisors = data_forlookup['people'].num_nodes\n",
    "num_organizations = data_forlookup['organizations'].num_nodes\n",
    "metadata = data_forlookup.metadata()\n",
    "# add selfloops\n",
    "for node_type in data_forlookup.node_types:\n",
    "    metadata[1].append((node_type, 'self_loop', node_type))  \n",
    "    \n",
    "    \n",
    "\n",
    "del data_forlookup\n",
    "print(train_data['people'].labelencoding.shape, train_data['courses_and_programs'].labelencoding.shape)  \n",
    "field_dims = torch.cat((train_data['people'].labelencoding,train_data['courses_and_programs'].labelencoding), dim=0)\n",
    "print(field_dims)\n",
    "# convert the field dims to integer\n",
    "field_dims = field_dims.to(torch.int64)\n",
    "fm = FactorizationMachineModel(\n",
    "    field_dims=field_dims,\n",
    "        embed_dim=hidden_channels)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fm_only_folderfile = 'modelsmodels/learningpeople_factorizationmachines_densemargin05AAAFMONLY_20231104_172955_pnorm2_llr2e-05_bs32_neighbors__head_TransE_hiddenchannels_16_outchannels_1_numheads_0_numlayers_0/model_samplesseen1267456.pt'\n",
    "\n",
    "\n",
    "modelfmonly = Model(fm, head=head, node_types=metadata[0], edge_types=metadata[1], ggn_output_dim=out_channels, pnorm=pnorm, num_supervisors=num_supervisors, num_organizations=num_organizations)\n",
    "#torch_geometric.compile(model, dynamic=True)\n",
    "modelfmonly.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model on test set\n",
    "# init dimensions of model by training it\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime\n",
    "import numpy as np \n",
    "\n",
    "def evaluate(model, n_negatives, model_folder, on='test'):\n",
    "    num_neighbors = [int(x) for x in model_folder.split('neighbors_')[1].split('head')[0].strip('_').split('_')]\n",
    "    \n",
    "    model.to(device)\n",
    "    mrrs = []\n",
    "   \n",
    "    \n",
    "    #test_sampler = get_hgt_linkloader(test_data, input_edgetype, 1, False, 'triplet', n_negatives, num_neighbors, num_workers=0, prefetch_factor=None, pin_memory=True)\n",
    "    if on=='test':\n",
    "        test_sampler = nf_loader(test_data['people','completed','courses_and_programs'].edge_label_index.to('cpu'),test_data['people','completed','courses_and_programs'].edge_label.to('cpu'), batch_size, num_learnings, neg_sample_ratio)\n",
    "    elif on=='train':\n",
    "        test_sampler = nf_loader(train_data['people','completed','courses_and_programs'].edge_label_index.to('cpu'),train_data['people','completed','courses_and_programs'].edge_label.to('cpu'), batch_size, num_learnings, neg_sample_ratio)\n",
    "        \n",
    "        \n",
    "    # test data\n",
    "    best_mrr, best_differences, best_src_nodes, best_dst_nodes = 0, None, None, None\n",
    "    for i, (batch_edge_label_index, labels) in tqdm(enumerate(test_sampler)):\n",
    "        if i==1000:\n",
    "            break\n",
    "        model.eval()\n",
    "        if on == 'test':\n",
    "            \n",
    "            differences = model(test_data.to(device), batch_edge_label_index.to(device), labels.to(device))\n",
    "        elif on == 'train':\n",
    "            differences = model(train_data.to(device), batch_edge_label_index.to(device), labels.to(device))\n",
    "        #optimizer.zero_grad()\n",
    "        #loss.backward()\n",
    "        edge_label = lables\n",
    "        # define mrr with differences and labels\n",
    "        # get rank of positive edge from tensor, positive edge is first in batch\n",
    "\n",
    "        differences = -1* differences.cpu().detach().numpy()\n",
    "        edge_label = edge_label.cpu().detach().numpy()\n",
    "        rank = (differences < differences[0]).sum()\n",
    "\n",
    "        # reciprocal\n",
    "        mrr = 1/(rank+1)\n",
    "        if mrr > best_mrr:\n",
    "            best_mrr = mrr\n",
    "            # best_differences = differences\n",
    "            # best_src_nodes = global_src_nodes\n",
    "            # best_dst_nodes = global_dst_nodes\n",
    "            print('new best mrr', best_mrr)\n",
    "            \n",
    "    \n",
    "        mrrs.append(mrr)\n",
    "\n",
    "        \n",
    "        if False:\n",
    "            jobpeople = test_data_text['jobs', 'job_student', 'people']\n",
    "            job_edge = jobpeople.edge_index[1,:] == global_src_nodes[0]\n",
    "            \n",
    "            \n",
    "            if torch.sum(job_edge) != 0:\n",
    "                job_idx = jobpeople.edge_index[0,:][job_edge]\n",
    "                \n",
    "            else:\n",
    "                job_idx = torch.tensor([0])\n",
    "\n",
    "            job_edge = jobpeople.edge_label_index[1,:] == global_src_nodes[0]\n",
    "            if torch.sum(job_edge) != 0:\n",
    "                job_idx2 = jobpeople.edge_label_index[0,:][job_edge]\n",
    "                torch.cat((job_idx, job_idx2)).squeeze()\n",
    "                \n",
    "                \n",
    "            \n",
    "        \n",
    "            print('==============')\n",
    "            print('==============')\n",
    "            print('==============')\n",
    "            # (differences < differences[0])\n",
    "            print('mrr',mrr)\n",
    "            print('rank',rank)\n",
    "            for idx in job_idx:\n",
    "                jobtitle = test_data_text['jobs'].TITLE[idx.item()]\n",
    "                print('job title', jobtitle)\n",
    "                \n",
    "            print('original', test_data_text['courses_and_programs'].TITLE[global_dst_nodes[0]])\n",
    "            print('original', test_data_text['courses_and_programs'].DESCRIPTION[global_dst_nodes[0]])\n",
    "            \n",
    "            # first 10 higher ranked\n",
    "            mask = torch.where(torch.tensor((differences < differences[0])))\n",
    "            indices = torch.argsort(torch.tensor(differences[mask]))\n",
    "            for i in range(10):\n",
    "                index = indices[i]\n",
    "                global_index = global_dst_nodes[mask][index]\n",
    "                print('------')\n",
    "                print(differences[mask][index])\n",
    "                print(test_data_text['courses_and_programs'].TITLE[global_index])\n",
    "                print(test_data_text['courses_and_programs'].DESCRIPTION[global_index])\n",
    "\n",
    "    print('mean mrr',np.mean(mrrs))\n",
    "    print('mean rank',1/np.mean(mrrs))\n",
    "    # mean rank\n",
    "    model.to('cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'evaluate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/amos/programming/create_graphds/learnings_eval_v1_factorizationmachine_and_dense.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/amos/programming/create_graphds/learnings_eval_v1_factorizationmachine_and_dense.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m evaluate(modelfmdense, \u001b[39m10000\u001b[39m, fm_and_dense_folderfile, on\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/amos/programming/create_graphds/learnings_eval_v1_factorizationmachine_and_dense.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m evaluate(modelfmonly, \u001b[39m10000\u001b[39m, fm_only_folderfile, on\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'evaluate' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "evaluate(modelfmdense, 10000, fm_and_dense_folderfile, on='test')\n",
    "evaluate(modelfmonly, 10000, fm_only_folderfile, on='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = set(test_data['courses_and_programs', 'course_and_programs_student', 'people'].edge_label_index[0,:].unique().tolist())\n",
    "a2 = set(train_data['courses_and_programs', 'course_and_programs_student', 'people'].edge_label_index[0,:].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = set(torch.cat((train_data['courses_and_programs', 'course_and_programs_student', 'people'].edge_index[0,:].unique(),train_data['courses_and_programs', 'course_and_programs_student', 'people'].edge_label_index[0,:].unique())).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9335"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a.intersection(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of dataset on disk:  2.279761238 gb\n",
      "loading saved heterodata object\n",
      "for skill job edges keep top k edges per job, k is  50\n",
      "keep tensor(1208056) of total 16289586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:06,  6.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new best mrr 0.0024752475247524753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:12,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new best mrr 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:14,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new best mrr 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [45:27,  2.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean mrr 0.17139854320945072\n",
      "mean rank 5.834355305914065\n"
     ]
    }
   ],
   "source": [
    "# evaluate(model_3layereuclid, 10000, model_folder3layereuclid, on='test')\n",
    "# evaluate(model_2layereuclid, 10000, model_folder2layereuclid, on='test')\n",
    "evaluate(model_2layerp1, 10000, model_folder2layerp1, on='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of dataset on disk:  2.279761238 gb\n",
      "loading saved heterodata object\n",
      "for skill job edges keep top k edges per job, k is  50\n",
      "keep tensor(1208056) of total 16289586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:15, 15.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new best mrr 8.13206473123526e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:23, 10.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new best mrr 0.000500751126690035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:36,  8.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new best mrr 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [01:00,  6.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new best mrr 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [23:41,  7.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean mrr 0.13983406037281088\n",
      "mean rank 7.151333497245987\n",
      "size of dataset on disk:  2.279761238 gb\n",
      "loading saved heterodata object\n",
      "for skill job edges keep top k edges per job, k is  50\n",
      "keep tensor(1208056) of total 16289586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:09,  9.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new best mrr 0.0001484560570071259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:13,  6.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new best mrr 0.005494505494505495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:18,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new best mrr 0.16666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:27,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new best mrr 0.3333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31it [01:25,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new best mrr 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [09:34,  2.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean mrr 0.08684513895969696\n",
      "mean rank 11.514749264942502\n",
      "size of dataset on disk:  2.279761238 gb\n",
      "loading saved heterodata object\n",
      "for skill job edges keep top k edges per job, k is  50\n",
      "keep tensor(1208056) of total 16289586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:05,  5.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new best mrr 0.00016452780519907864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:07,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new best mrr 0.02127659574468085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:12,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new best mrr 0.1111111111111111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:20,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new best mrr 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [10:11,  3.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean mrr 0.11901925778350261\n",
      "mean rank 8.402001647657823\n"
     ]
    }
   ],
   "source": [
    "evaluate(model_3layereuclid, 10000, model_folder3layereuclid, on='train')\n",
    "evaluate(model_2layereuclid, 10000, model_folder2layereuclid, on='train')\n",
    "evaluate(model_2layerp1, 10000, model_folder2layerp1, on='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(modele4, 50000, model_foldere4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(modele4euclidean, 50000, model_foldere4euclidean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(modele5, 50000, model_foldere5, on='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(modele4, 50000, model_foldere4, on='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(modele4euclidean, 30000, model_foldere4euclidean, on='train')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
