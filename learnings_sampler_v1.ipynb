{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading saved heterodata object\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch_geometric.data import HeteroData\n",
    "\n",
    "\n",
    "filename = 'HeteroData_Learnings_v1.pt'\n",
    "if os.path.exists('./'+filename):\n",
    "    data = HeteroData.from_dict(torch.load('./'+filename))\n",
    "    print('loading saved heterodata object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of file on disk:  1.790098703 gb\n"
     ]
    }
   ],
   "source": [
    "# get size of the data on disk in gb\n",
    "import os\n",
    "size = os.path.getsize('./'+filename)\n",
    "print('size of file on disk: ', size/1e9, 'gb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampler for Heterogeneous Graph Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each node type, add a new edge type only consisting of self loops\n",
    "# this is done to allow HGT to attend to the previous node representations\n",
    "# for node_type in data.node_types:\n",
    "#     data[node_type, 'self_loop', node_type] = torch.cat((torch.arange(data[node_type].num_nodes),torch.arange(data[node_type].num_nodes)), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  courses_and_programs={\n",
       "    TITLE=[55796],\n",
       "    DESCRIPTION=[55796],\n",
       "    x=[55796, 814],\n",
       "  },\n",
       "  qualifications={\n",
       "    TITLE=[1242],\n",
       "    DESCRIPTION=[1242],\n",
       "    x=[1242, 785],\n",
       "  },\n",
       "  skills={\n",
       "    TITLE=[138698],\n",
       "    x=[138698, 772],\n",
       "  },\n",
       "  people={ x=[293444, 24] },\n",
       "  jobs={\n",
       "    TITLE=[55638],\n",
       "    x=[55638, 773],\n",
       "  },\n",
       "  organizations={\n",
       "    num_nodes=13613,\n",
       "    x=[13613, 2],\n",
       "  },\n",
       "  (skills, qualification_skill, qualifications)={ edge_index=[2, 1596] },\n",
       "  (skills, course_and_program_skill, courses_and_programs)={ edge_index=[2, 258099] },\n",
       "  (courses_and_programs, course_qualification, qualifications)={ edge_index=[2, 2099] },\n",
       "  (courses_and_programs, course_and_programs_student, people)={\n",
       "    edge_index=[2, 553454],\n",
       "    edge_attr=[553454, 3],\n",
       "  },\n",
       "  (jobs, job_student, people)={ edge_index=[2, 293444] },\n",
       "  (people, supervisor_supervisee, people)={ edge_index=[2, 217922] },\n",
       "  (people, organization_student, organizations)={ edge_index=[2, 292060] },\n",
       "  (jobs, job_job, jobs)={\n",
       "    edge_index=[2, 18384],\n",
       "    edge_attr=[18384, 1],\n",
       "  },\n",
       "  (skills, job_skill, jobs)={\n",
       "    edge_index=[2, 16289586],\n",
       "    edge_attr=[16289586, 1],\n",
       "  },\n",
       "  (jobs, broader_job_job, jobs)={ edge_index=[2, 54586] },\n",
       "  (qualifications, rev_qualification_skill, skills)={ edge_index=[2, 1596] },\n",
       "  (courses_and_programs, rev_course_and_program_skill, skills)={ edge_index=[2, 258099] },\n",
       "  (qualifications, rev_course_qualification, courses_and_programs)={ edge_index=[2, 2099] },\n",
       "  (people, rev_course_and_programs_student, courses_and_programs)={\n",
       "    edge_index=[2, 553454],\n",
       "    edge_attr=[553454, 3],\n",
       "  },\n",
       "  (people, rev_job_student, jobs)={ edge_index=[2, 293444] },\n",
       "  (people, rev_supervisor_supervisee, people)={ edge_index=[2, 217922] },\n",
       "  (organizations, rev_organization_student, people)={ edge_index=[2, 292060] },\n",
       "  (jobs, rev_job_job, jobs)={\n",
       "    edge_index=[2, 18384],\n",
       "    edge_attr=[18384, 1],\n",
       "  },\n",
       "  (jobs, rev_job_skill, skills)={\n",
       "    edge_index=[2, 16289586],\n",
       "    edge_attr=[16289586, 1],\n",
       "  },\n",
       "  (jobs, rev_broader_job_job, jobs)={ edge_index=[2, 54586] }\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric import seed_everything\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "\n",
    "edge_types = []\n",
    "rev_edge_types = []\n",
    "for edge_type in data.edge_types:\n",
    "    if edge_type[1].startswith('rev_'):\n",
    "        rev_edge_types.append(edge_type)\n",
    "    else:\n",
    "        edge_types.append(edge_type)\n",
    "\n",
    "transform = T.RandomLinkSplit(\n",
    "    is_undirected=True,\n",
    "    edge_types=edge_types,\n",
    "    rev_edge_types=rev_edge_types,\n",
    "    num_val=0.02,\n",
    "    num_test=0.02,\n",
    "    add_negative_train_samples=False, # only adds neg samples for val and test, neg train are added by LinkNeighborLoader. This means for each train batch, negs. are different, for val and train they stay the same\n",
    "    neg_sampling_ratio=1.0,\n",
    "    disjoint_train_ratio=0, #  training edges are shared for message passing and supervision\n",
    "    )\n",
    "\n",
    "seed_everything(14)\n",
    "train_data, val_data, test_data = transform(data)\n",
    "\n",
    "\n",
    "\n",
    "# train_data = add_self_loops(train_data)\n",
    "# val_data = add_self_loops(val_data)\n",
    "# test_data = add_self_loops(test_data)\n",
    "\n",
    "# train_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "from torch_geometric.loader import HGTLoader\n",
    "from torch_geometric.sampler import NegativeSampling\n",
    "\n",
    "num_neighbors_linkloader = {}\n",
    "for edge_type in train_data.edge_types:\n",
    "    # if edge_type[1] == 'self_loop':\n",
    "    #     num_neighbors[edge_type] = [0,0]\n",
    "    num_neighbors[edge_type] = [0,0]\n",
    "    # num_neighbors['qualifications', 'self_loops', 'qualifications'] = [1,0]\n",
    "    # num_neighbors['qualifications', 'rev_qualification_skill', 'skills'] = [10,0]\n",
    "\n",
    "negative_sampling = NegativeSampling(\n",
    "        mode='binary',\n",
    "        amount=10  # ratio, like Graphsage\n",
    "        #weight=  # \"Probabilities\" of nodes to be sampled: Node degree follows power law distribution\n",
    "        )\n",
    "num_workers = 0\n",
    "# delete edge_attr of every edge type\n",
    "for edge_type in train_data.edge_types:\n",
    "    del train_data[edge_type].edge_attr \n",
    "\n",
    "# delete all keys for every node type except 'x' (e.g. description and title)\n",
    "for node_type in train_data.node_types:\n",
    "    keys = list(train_data[node_type].keys())\n",
    "    for key in keys:\n",
    "        if key != 'x':\n",
    "            del train_data[node_type][key]\n",
    "\n",
    "linkNeighborLoader = LinkNeighborLoader(\n",
    "        train_data,\n",
    "        num_neighbors=num_neighbors_linkloader,\n",
    "        edge_label_index=(('skills', 'qualification_skill', 'qualifications'), train_data['skills', 'qualification_skill', 'qualifications'].edge_label_index), # if (edge, None), None means all edges are considered\n",
    "     \n",
    "        neg_sampling=negative_sampling, # adds negative samples\n",
    "        batch_size=64,\n",
    "        shuffle=True,\n",
    "        #drop_last=True,\n",
    "        num_workers=num_workers,\n",
    "        directed=True,  # contains only edges which are followed, False: contains full node induced subgraph\n",
    "        #disjoint=True # sampled seed node creates its own, disjoint from the rest, subgraph, will add \"batch vector\" to loader output\n",
    "        pin_memory=True, # faster data transfer to gpu\n",
    "        #num_workers=2,\n",
    "        #prefetch_factor=2\n",
    ")\n",
    "\n",
    "def get_hgt(data, )\n",
    "    hgtLoader = HGTLoader(\n",
    "        hetero_data,\n",
    "        # Sample 512 nodes per type and per iteration for 4 iterations\n",
    "        num_samples={key: [512] * 4 for key in hetero_data.node_types},\n",
    "        # Use a batch size of 128 for sampling training nodes of type paper\n",
    "        batch_size=128,\n",
    "        input_nodes=('paper', hetero_data['paper'].train_mask),\n",
    "    )\n",
    "\n",
    "\n",
    "def add_self_loops(data):\n",
    "    for node_type in data.node_types:\n",
    "        data[node_type, 'self_loop', node_type].edge_index = torch.arange(data[node_type].num_nodes).repeat(2,1)\n",
    "    return data \n",
    "# add a yield wrapper\n",
    "def get_loader_with_selfloops(loader):\n",
    "    for batch in loader:\n",
    "        yield add_self_loops(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loader_with_selfloops = get_loader_with_selfloops(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/amos/programming/create_graphds/learnings_sampler_v1.ipynb Cell 10\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/amos/programming/create_graphds/learnings_sampler_v1.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch_geometric\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mloader\u001b[39;00m \u001b[39mimport\u001b[39;00m HGTLoader\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/amos/programming/create_graphds/learnings_sampler_v1.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch_geometric\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m OGB_MAG\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/amos/programming/create_graphds/learnings_sampler_v1.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m hetero_data \u001b[39m=\u001b[39m OGB_MAG(path)[\u001b[39m0\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/amos/programming/create_graphds/learnings_sampler_v1.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m loader \u001b[39m=\u001b[39m HGTLoader(\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/amos/programming/create_graphds/learnings_sampler_v1.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     hetero_data,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/amos/programming/create_graphds/learnings_sampler_v1.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39m# Sample 512 nodes per type and per iteration for 4 iterations\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/amos/programming/create_graphds/learnings_sampler_v1.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     input_nodes\u001b[39m=\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mpaper\u001b[39m\u001b[39m'\u001b[39m, hetero_data[\u001b[39m'\u001b[39m\u001b[39mpaper\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mtrain_mask),\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/amos/programming/create_graphds/learnings_sampler_v1.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/amos/programming/create_graphds/learnings_sampler_v1.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m sampled_hetero_data \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(loader))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'path' is not defined"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import HGTLoader\n",
    "from torch_geometric.datasets import OGB_MAG\n",
    "\n",
    "hetero_data = OGB_MAG(path)[0]\n",
    "\n",
    "loader = HGTLoader(\n",
    "    hetero_data,\n",
    "    # Sample 512 nodes per type and per iteration for 4 iterations\n",
    "    num_samples={key: [512] * 4 for key in hetero_data.node_types},\n",
    "    # Use a batch size of 128 for sampling training nodes of type paper\n",
    "    batch_size=128,\n",
    "    input_nodes=('paper', hetero_data['paper'].train_mask),\n",
    ")\n",
    "\n",
    "sampled_hetero_data = next(iter(loader))\n",
    "print(sampled_data.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import HGTLoader\n",
    "from torch_geometric.datasets import OGB_MAG\n",
    "\n",
    "hetero_data = OGB_MAG('tests/')[0]\n",
    "\n",
    "loader = HGTLoader(\n",
    "    hetero_data,\n",
    "    # Sample 512 nodes per type and per iteration for 4 iterations\n",
    "    num_samples={key: [512] * 4 for key in hetero_data.node_types},\n",
    "    # Use a batch size of 128 for sampling training nodes of type paper\n",
    "    batch_size=736389,\n",
    "    input_nodes=('paper', None),\n",
    ")\n",
    "\n",
    "sampled_hetero_data = next(iter(loader))\n",
    "#print(sampled_hetero_data.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "631619"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  paper={\n",
       "    x=[736389, 128],\n",
       "    year=[736389],\n",
       "    y=[736389],\n",
       "    train_mask=[736389],\n",
       "    val_mask=[736389],\n",
       "    test_mask=[736389],\n",
       "    n_id=[736389],\n",
       "    input_id=[736389],\n",
       "    batch_size=736389,\n",
       "  },\n",
       "  author={\n",
       "    num_nodes=2048,\n",
       "    n_id=[2048],\n",
       "  },\n",
       "  institution={\n",
       "    num_nodes=0,\n",
       "    n_id=[0],\n",
       "  },\n",
       "  field_of_study={\n",
       "    num_nodes=0,\n",
       "    n_id=[0],\n",
       "  },\n",
       "  (author, affiliated_with, institution)={\n",
       "    edge_index=[2, 0],\n",
       "    e_id=[0],\n",
       "  },\n",
       "  (author, writes, paper)={\n",
       "    edge_index=[2, 94946],\n",
       "    e_id=[94946],\n",
       "  },\n",
       "  (paper, cites, paper)={\n",
       "    edge_index=[2, 4710815],\n",
       "    e_id=[4710815],\n",
       "  },\n",
       "  (paper, has_topic, field_of_study)={\n",
       "    edge_index=[2, 0],\n",
       "    e_id=[0],\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(loader))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyg_torch21",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
