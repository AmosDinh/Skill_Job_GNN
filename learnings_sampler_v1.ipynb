{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling\n",
    "# 1. Sample using HGT Sampler as outlined in the paper, using pyg implementations\n",
    "# 2. The sampling is adapted to link prediction, by first sampling random supervision edges of which the nodes create the supervision nodes\n",
    "# a. Dataset is divided across multiple dimensions:\n",
    "#   a.1. Split into Train, Val, Test split (96, 2, 2)\n",
    "#   a.2. Training only: Edges are split into those which are used solely for message passing and those solely used for supervision (80, 20). \n",
    "#        Because an expressive model (HGT) is used, this prevents the model from memorizing supervision edges by their appearance as message passing edges\n",
    "#   a.3. This means Training consists of 96%*80% Message passing Edges, 96%*20% supervision edges, Val contains 2% Supervision Edges, Test contains 2% supervison Edges\n",
    "#   a.4. Validation and Test edges use the Training Message passing Edges as well.\n",
    "# b. For mini-batch sampling in the training phase, first x random edges are sampled as supervision edges. \n",
    "#    For the nodes of these supervision edges, we apply batch-wise HGT Sampling. Due to implementation limitations, for each supervision entity type, the hgt sampling is separate. \n",
    "#    This limitation does not apply for sampled neighbor entity types\n",
    "# during sampling, also the reverse edge of the supervision edge is removed to avoid data leakage\n",
    "\n",
    "\n",
    "# HGT Sampler (See Paper for further reference)\n",
    "# The probablity of a neighbor node s to be sampled depends on the normalized degree of all its edge types connecting it to all source nodes\n",
    "# If neighbor node s is connected to a and b by edge type r, and a has 2 neighbors through edge type r and b has 1 neighbor (node s) through edge type r, \n",
    "# then the sampling probablity of s is (1/2+1)**2 / 2**2, if it were connected through other edge types to the nodes as well, those degrees would be added to the numerator and denominator.\n",
    "# Nodes are sampled without replacement.\n",
    "# This sampling strategy creates more dense mini-batches, because neighbor nodes which are connected to multiple source nodes and by multiple relationship types are sampled more frequently.\n",
    "# Therefore, training is sped up since less node representations have to be computed. Furthermore, as stated in the paper, the sampling method allows to sample a \n",
    "# similar number of neighbors for each edge type, because high-count edge types and low-count edge types are weighted equally. For each neighbor node type T, a fixed number n of nodes is sampled.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amos/mambaforge/envs/pyg_torch21/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading saved heterodata object\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch_geometric.data import HeteroData\n",
    "\n",
    "\n",
    "filename = 'HeteroData_Learnings_v1.pt'\n",
    "if os.path.exists('./'+filename):\n",
    "    data = HeteroData.from_dict(torch.load('./'+filename))\n",
    "    print('loading saved heterodata object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of file on disk:  2.27811871 gb\n"
     ]
    }
   ],
   "source": [
    "# get size of the data on disk in gb\n",
    "import os\n",
    "size = os.path.getsize('./'+filename)\n",
    "print('size of file on disk: ', size/1e9, 'gb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampler for Heterogeneous Graph Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each node type, add a new edge type only consisting of self loops\n",
    "# this is done to allow HGT to attend to the previous node representations\n",
    "# for node_type in data.node_types:\n",
    "#     data[node_type, 'self_loop', node_type] = torch.cat((torch.arange(data[node_type].num_nodes),torch.arange(data[node_type].num_nodes)), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric import seed_everything\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.utils import sort_edge_index\n",
    "\n",
    "edge_types = []\n",
    "rev_edge_types = []\n",
    "for edge_type in data.edge_types:\n",
    "    if edge_type[1].startswith('rev_'):\n",
    "        rev_edge_types.append(edge_type)\n",
    "    else:\n",
    "        edge_types.append(edge_type)\n",
    "\n",
    "transform = T.RandomLinkSplit(\n",
    "    is_undirected=True,\n",
    "    edge_types=edge_types,\n",
    "    rev_edge_types=rev_edge_types,\n",
    "    num_val=0.02,\n",
    "    num_test=0.02,\n",
    "    add_negative_train_samples=False, # only adds neg samples for val and test, neg train are added by LinkNeighborLoader. This means for each train batch, negs. are different, for val and train they stay the same\n",
    "    neg_sampling_ratio=1.0,\n",
    "    disjoint_train_ratio=0.3, #  training edges are shared for message passing and supervision\n",
    "    )\n",
    "\n",
    "seed_everything(14)\n",
    "# sort by col to speed up sampling later (we can sepcify is_sorted=True in link neighbor loader)\n",
    "def sort_edges(data):\n",
    "    for edge_type in data.edge_types:\n",
    "        if 'edge_attr' in data[edge_type].keys():\n",
    "            data[edge_type].edge_index, data[edge_type].edge_attr = sort_edge_index(data[edge_type].edge_index, data[edge_type].edge_attr, sort_by_row=False) \n",
    "        else:\n",
    "            data[edge_type].edge_index = sort_edge_index(data[edge_type].edge_index, sort_by_row=False) \n",
    "    return data\n",
    "        \n",
    "train_data, val_data, test_data = transform(data)\n",
    "train_data = sort_edges(train_data)\n",
    "val_data = sort_edges(val_data)\n",
    "test_data = sort_edges(test_data)\n",
    "\n",
    "\n",
    "# train_data = add_self_loops(train_data)\n",
    "# val_data = add_self_loops(val_data)\n",
    "# test_data = add_self_loops(test_data)\n",
    "\n",
    "# train_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "from torch_geometric.loader import HGTLoader\n",
    "from torch_geometric.sampler import NegativeSampling\n",
    "from copy import deepcopy\n",
    "\n",
    "    # num_neighbors['qualifications', 'self_loops', 'qualifications'] = [1,0]\n",
    "    # num_neighbors['qualifications', 'rev_qualification_skill', 'skills'] = [10,0]\n",
    "\n",
    "\n",
    "num_workers = 0\n",
    "# delete edge_attr of every edge type\n",
    "for edge_type in train_data.edge_types:\n",
    "    del train_data[edge_type].edge_attr \n",
    "\n",
    "# delete all keys for every node type except 'x' (e.g. description and title)\n",
    "for node_type in train_data.node_types:\n",
    "    keys = list(train_data[node_type].keys())\n",
    "    for key in keys:\n",
    "        if key != 'x':\n",
    "            del train_data[node_type][key]\n",
    "\n",
    "\n",
    "def get_hgt_linkloader(data, target_edge, batch_size, is_training, sampling_mode, neg_ratio, num_neighbors_hgtloader):\n",
    "    # first sample some edges in linkNeighborLoader\n",
    "    # use the nodes of the sampled edges to sample from hgt loader\n",
    "    \n",
    "    \n",
    "    num_neighbors_linkloader = [0]\n",
    "    #for edge_type in data.edge_types:\n",
    "    #    num_neighbors_linkloader[edge_type] = [0,0]\n",
    "    \n",
    "    negative_sampling = NegativeSampling(\n",
    "        mode=sampling_mode, # binary or triplet\n",
    "        amount=neg_ratio  # ratio, like Graphsage # 10\n",
    "        #weight=  # \"Probabilities\" of nodes to be sampled: Node degree follows power law distribution\n",
    "        )\n",
    "    \n",
    "    if sampling_mode == 'triplet':\n",
    "        data[target_edge].edge_label = None\n",
    "\n",
    "    linkNeighborLoader = LinkNeighborLoader(\n",
    "            data,\n",
    "            num_neighbors=num_neighbors_linkloader,\n",
    "            edge_label_index=(target_edge, data[target_edge].edge_label_index), # if (edge, None), None means all edges are considered\n",
    "        \n",
    "            neg_sampling=negative_sampling, # adds negative samples\n",
    "            batch_size=batch_size,\n",
    "            shuffle=is_training, #is_training\n",
    "            #drop_last=True,\n",
    "            num_workers=num_workers,\n",
    "            directed=False,  # True contains only edges which are followed, False: contains full node induced subgraph, we want false so we can later filter out the reverse edges as well\n",
    "            #disjoint=True # sampled seed node creates its own, disjoint from the rest, subgraph, will add \"batch vector\" to loader output\n",
    "            pin_memory=True, # faster data transfer to gpu\n",
    "            #num_workers=2,\n",
    "            #prefetch_factor=2\n",
    "            is_sorted = False\n",
    "    )\n",
    "    \n",
    "   \n",
    "    #num_neighbors_hgtloader = {}\n",
    "    #for node_type in data.node_types:\n",
    "    #    num_neighbors_hgtloader[node_type] = [5,5]\n",
    "    #num_neighbors_hgtloader = [batch_size,batch_size]\n",
    "    # sample same amount of neighbors of each edge type\n",
    "    def get_hgt(data, input_nodetype, input_mask):\n",
    "        return next(iter(HGTLoader(\n",
    "                data,\n",
    "                # Sample 512 nodes per type and per iteration for 4 iterations\n",
    "                num_samples=num_neighbors_hgtloader,\n",
    "                batch_size=input_mask.shape[0],\n",
    "                input_nodes=(input_nodetype, input_mask),\n",
    "            )))\n",
    "        \n",
    "    \n",
    "    def add_self_loops(data):\n",
    "        for node_type in data.node_types:\n",
    "            data[node_type, 'self_loop', node_type].edge_index = torch.arange(data[node_type].num_nodes).repeat(2,1)\n",
    "        return data \n",
    "\n",
    "            \n",
    "    def get_hgt_with_selfloops(loader):\n",
    "        \n",
    "        \n",
    "        for batch in loader:\n",
    "            if sampling_mode=='triplet':      \n",
    "                # original edge_label_index from the whole data object\n",
    "                unmapped_batchids = torch.cat((batch[target_edge[0]].src_index,batch[target_edge[2]].dst_pos_index, batch[target_edge[2]].dst_neg_index)).unique()\n",
    "                original_edge_label_nodes = torch.LongTensor(batch[target_edge[0]].n_id[unmapped_batchids])\n",
    "\n",
    "                src = batch[target_edge[0]].n_id[batch[target_edge[0]].src_index].unsqueeze(0)\n",
    "                dst = batch[target_edge[2]].n_id[torch.cat((batch[target_edge[2]].dst_pos_index, batch[target_edge[2]].dst_neg_index),dim=0)].unsqueeze(0)\n",
    "                global_edge_label_index = torch.cat((src, dst),dim=0)\n",
    "                edge_label = torch.cat((torch.ones(batch[target_edge[2]].dst_pos_index.shape[1]), torch.zeros(batch[target_edge[2]].dst_neg_index)))\n",
    "                \n",
    "            elif sampling_mode=='binary':\n",
    "                unmapped_batchids = batch[target_edge].edge_label_index.flatten().unique()\n",
    "                original_edge_label_nodes = torch.LongTensor(batch[target_edge[0]].n_id[unmapped_batchids])\n",
    "                \n",
    "                src = batch[target_edge[0]].n_id[batch[target_edge].edge_label_index[0,:]].unsqueeze(0)\n",
    "                dst = batch[target_edge[2]].n_id[batch[target_edge].edge_label_index[1,:]].unsqueeze(0)\n",
    "                global_edge_label_index = torch.cat((src, dst),dim=0)\n",
    "            else:\n",
    "                raise Exception('binary or triplet sampling mode')\n",
    "                \n",
    "                \n",
    "            hgt_batch = get_hgt(data, target_edge[0], original_edge_label_nodes) # 0,1,3,4,5,6,7,8,9,\n",
    "            # ** We dont need to remove any edges ** since the supervision edges wont be sampled by hgt\n",
    "            # remove the supervision edges and their reverse from edge_index\n",
    "\n",
    "         \n",
    "                \n",
    "            src = (hgt_batch[target_edge[0]].n_id.unsqueeze(0) == global_edge_label_index[0,:].unsqueeze(1)).nonzero()[:,1].unsqueeze(0) \n",
    "            dst = (hgt_batch[target_edge[2]].n_id.unsqueeze(0) == global_edge_label_index[1,:].unsqueeze(1)).nonzero()[:,1].unsqueeze(0) \n",
    "\n",
    "            local_edge_level_index = torch.cat((src, dst),dim=0)\n",
    "            if sampling_mode=='triplet':\n",
    "                \n",
    "                \n",
    "                #src = batch[target_edge[0]].src_index.unsqueeze(0)\n",
    "                #pos_edge_label_index = torch.cat((src, batch[target_edge[0]].dst_pos_index.unsqueeze(0)), dim=0)\n",
    "                #neg_edge_label_index = torch.cat((src, batch[target_edge[0]].dst_neg_index.unsqueeze(0)), dim=0)\n",
    "                #edge_label_index = torch.cat((pos_edge_label_index,neg_edge_label_index), dim=1)\n",
    "                #edge_label = torch.cat((torch.ones(pos_edge_label_index.shape[1]), torch.zeros(neg_edge_label_index.shape[1])))\n",
    "\n",
    "                # I think below is the incorrect way:\n",
    "                #src = batch[target_edge[0]].n_id[batch[target_edge[0]].src_index].unsqueeze(0)\n",
    "                #pos_edge_label_index = torch.cat((src, batch[target_edge[0]].n_id[batch[target_edge[0]].dst_pos_index].unsqueeze(0)), dim=0)\n",
    "                #neg_edge_label_index = torch.cat((src, batch[target_edge[0]].n_id[batch[target_edge[0]].dst_neg_index].unsqueeze(0)), dim=0)\n",
    "                #edge_label_index = torch.cat((pos_edge_label_index,neg_edge_label_index), dim=1)\n",
    "                #edge_label = torch.cat((torch.ones(pos_edge_label_index.shape[1]), torch.zeros(neg_edge_label_index.shape[1])))\n",
    "                \n",
    "                # return message passing edges, and supervision edges/labels, ignore labels/label_indices in the message passing edges\n",
    "                yield add_self_loops(hgt_batch), local_edge_level_index, edge_label, batch[target_edge].input_id\n",
    "            else: # sampling_mode=='binary':\n",
    "                # return message passing edges, and supervision edges/labels, ignore labels/label_indices in the message passing edges, as well as original edge indices\n",
    "                yield add_self_loops(hgt_batch), local_edge_level_index, batch[target_edge].edge_label, batch[target_edge].input_id\n",
    "    \n",
    "    def get_hgt_2types_with_selfloops(loader):\n",
    "        for batch in loader:\n",
    "            if sampling_mode=='triplet':   \n",
    "                original_edge_label_index_class1 = torch.LongTensor(batch[target_edge[0]].n_id[batch[target_edge[0]].src_index.unique()])\n",
    "                original_edge_label_index_class2 = torch.LongTensor(batch[target_edge[2]].n_id[torch.cat((batch[target_edge[2]].dst_pos_index, batch[target_edge[2]].dst_neg_index)).unique()])\n",
    "                \n",
    "                src = batch[target_edge[0]].n_id[batch[target_edge[0]].src_index].unsqueeze(0)\n",
    "                dst = batch[target_edge[2]].n_id[torch.cat((batch[target_edge[2]].dst_pos_index, batch[target_edge[2]].dst_neg_index),dim=0)].unsqueeze(0)\n",
    "                global_edge_label_index = torch.cat((src, dst),dim=0)\n",
    "                edge_label = torch.cat((torch.ones(batch[target_edge[2]].dst_pos_index.shape[1]), torch.zeros(batch[target_edge[2]].dst_neg_index)))\n",
    "            \n",
    "            elif sampling_mode=='binary':\n",
    "                original_edge_label_index_class1 = batch[target_edge[0]].n_id[batch[target_edge].edge_label_index[0,:].unique()]\n",
    "                original_edge_label_index_class2 = batch[target_edge[2]].n_id[batch[target_edge].edge_label_index[1,:].unique()]\n",
    "\n",
    "                src = batch[target_edge[0]].n_id[batch[target_edge].edge_label_index[0,:]].unsqueeze(0)\n",
    "                dst = batch[target_edge[2]].n_id[batch[target_edge].edge_label_index[1,:]].unsqueeze(0)\n",
    "                global_edge_label_index = torch.cat((src, dst),dim=0)\n",
    "            else:\n",
    "                raise Exception('binary or triplet sampling mode')\n",
    "\n",
    "            # batch the start and end supervision nodes separately\n",
    "            hgt_batch1 = get_hgt(data, target_edge[0], original_edge_label_index_class1)\n",
    "            hgt_batch2 = get_hgt(data, target_edge[2], original_edge_label_index_class2)\n",
    "            \n",
    "            # ** We dont need to remove any edges ** since the supervision edges wont be sampled by hgt\n",
    "            src = (hgt_batch1[target_edge[0]].n_id.unsqueeze(0) == global_edge_label_index[0,:].unsqueeze(1)).nonzero()[:,1].unsqueeze(0) \n",
    "            dst = (hgt_batch2[target_edge[2]].n_id.unsqueeze(0) == global_edge_label_index[1,:].unsqueeze(1)).nonzero()[:,1].unsqueeze(0) \n",
    "            local_edge_level_index = torch.cat((src, dst),dim=0)\n",
    "            if sampling_mode=='triplet':\n",
    "                src = batch[target_edge[0]].src_index.unsqueeze(0)\n",
    "                pos_edge_label_index = torch.cat((src, batch[target_edge[2]].dst_pos_index.unsqueeze(0)), dim=0)\n",
    "                neg_edge_label_index = torch.cat((src, batch[target_edge[2]].dst_neg_index.unsqueeze(0)), dim=0)\n",
    "                edge_label_index = torch.cat((pos_edge_label_index,neg_edge_label_index), dim=1)\n",
    "                edge_label = torch.cat((torch.ones(pos_edge_label_index.shape[1]), torch.zeros(neg_edge_label_index.shape[1])))\n",
    "                \n",
    "                add_self_loops(hgt_batch1), add_self_loops(hgt_batch2), local_edge_label_index, edge_label, batch[target_edge].input_id\n",
    "            else: # sampling_mode=='binary':\n",
    "                # we can access the corresponding nodes of edge_label_index[0,:] in hgt_batch1[target_edge[0]], those of [1,:] in hgt_batch2...\n",
    "                yield add_self_loops(hgt_batch1), add_self_loops(hgt_batch2), local_edge_label_index, batch[target_edge].edge_label, batch[target_edge].input_id\n",
    "\n",
    "    \n",
    "        \n",
    "    if target_edge[0] == target_edge[2]:\n",
    "        # same edge type, only need to sample once\n",
    "        return get_hgt_with_selfloops(linkNeighborLoader)\n",
    "    else:\n",
    "        return get_hgt_2types_with_selfloops(linkNeighborLoader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "input_edgetype = ('jobs', 'job_job', 'jobs')\n",
    "loader = get_hgt_linkloader(train_data, input_edgetype, 4, True, 'binary', 1, [10])\n",
    "minibatch, edge_label_index, edge_label, input_edge_ids = next(iter(loader))\n",
    "\n",
    "#input_nodetype = ('skills', 'qualification_skill', 'qualifications')\n",
    "#loader = get_hgt_linkloader(train_data, input_nodetype, 8, True, 'triplet', 1, [10])\n",
    "#minibatchpart1, minibatchpart2, edge_label_index, edge_label, input_edge_id = next(iter(loader))\n",
    "#input_edge_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([34265,234234,235325,32434,546546])\n",
    "y = torch.tensor([34265,234234,546546,34265, 34265])\n",
    "torch.argwhere(torch.isin(y,x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set([str(x) for x in list(train_data[('skills', 'qualification_skill', 'qualifications')].edge_index.T.numpy().tolist())]).intersection(set([str(x) for x in list(train_data[('skills', 'qualification_skill', 'qualifications')].edge_label_index.T.numpy().tolist())]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# initial tensors\n",
    "tensor1 = torch.tensor([1, 2, 3, 4])\n",
    "tensor2 = torch.tensor([2, 2, 3, 1])\n",
    "\n",
    "# sort tensor1\n",
    "sorted_tensor1, indices = tensor1.sort()\n",
    "\n",
    "# use searchsorted to find the indices\n",
    "sorted_indices = sorted_tensor1.searchsorted(tensor2)\n",
    "\n",
    "# index into original indices to get the indices in the original unsorted tensor\n",
    "result = indices[sorted_indices]\n",
    "\n",
    "print(result)  # prints tensor([1, 1, 2, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([13,152,1223])\n",
    "b = torch.tensor([152,13, 1223, 1223, 13,13])\n",
    "c = torch.tensor([152,13, 13, 1223, 13,13])\n",
    "\n",
    "(a.unsqueeze(0) == b.unsqueeze(1)).nonzero()[:,1]\n",
    "(a.unsqueeze(0) == c.unsqueeze(1)).nonzero()[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[('skills', 'qualification_skill', 'qualifications')].edge_label_index[:,344]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = a[input_nodetype[0]].n_id[a[input_nodetype].edge_index[0,:]]\n",
    "v = a[input_nodetype[2]].n_id[a[input_nodetype].edge_index[1,:]]\n",
    "a[input_nodetype]\n",
    "a[input_nodetype]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b, edge_label_index, edge_label  = next(iter(loader)) # 229512 304"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['skills', 'qualification_skill', 'qualifications'].edge_index[:,820]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['skills', 'qualification_skill', 'qualifications']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['qualifications'].dst_pos_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['qualifications'].dst_neg_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['qualifications'].n_id[46]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_data\n",
    "target_edge=input_nodetype\n",
    "num_neighbors_linkloader = {}\n",
    "for edge_type in data.edge_types:\n",
    "    num_neighbors_linkloader[edge_type] = [0,0]\n",
    "\n",
    "#data[target_edge].edge_label = None\n",
    "negative_sampling = NegativeSampling(\n",
    "    mode='binary', # binary or triplet\n",
    "    amount=1  # ratio, like Graphsage # 10\n",
    "    #weight=  # \"Probabilities\" of nodes to be sampled: Node degree follows power law distribution\n",
    "    )\n",
    "\n",
    "\n",
    "linkNeighborLoader = LinkNeighborLoader(\n",
    "        data,\n",
    "        num_neighbors=num_neighbors_linkloader,\n",
    "        edge_label_index=(target_edge, data[target_edge].edge_label_index), # if (edge, None), None means all edges are considered\n",
    "    \n",
    "        neg_sampling=negative_sampling, # adds negative samples\n",
    "        batch_size=28,\n",
    "        shuffle=True, #is_training\n",
    "        #drop_last=True,\n",
    "        num_workers=0,\n",
    "        directed=False,  # True contains only edges which are followed, False: contains full node induced subgraph, we want false so we can later filter out the reverse edges as well\n",
    "        #disjoint=True # sampled seed node creates its own, disjoint from the rest, subgraph, will add \"batch vector\" to loader output\n",
    "        pin_memory=True, # faster data transfer to gpu\n",
    "        #num_workers=2,\n",
    "        #prefetch_factor=2\n",
    "        is_sorted = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = next(iter(linkNeighborLoader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['skills', 'qualification_skill', 'qualifications'].edge_index[:,202]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['skills', 'qualification_skill', 'qualifications'].edge_index[:,214]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(a['qualifications'].dst_neg_index.numpy()).intersection(set(a['qualifications'].dst_pos_index.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['qualifications'].x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['qualifications'].dst_neg_index.max(), a['qualifications'].dst_pos_index.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['qualifications'].n_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['qualifications']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['qualifications'].n_id[45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['skills']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['skills'].n_id[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = train_data['skills', 'qualification_skill', 'qualifications'].edge_index\n",
    "ax[0,ax[1]==881]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_data\n",
    "target_edge = 'skills', 'qualification_skill', 'qualifications'\n",
    "num_neighbors_linkloader = {}\n",
    "for edge_type in data.edge_types:\n",
    "    num_neighbors_linkloader[edge_type] = [0,0]\n",
    "\n",
    "negative_sampling = NegativeSampling(\n",
    "    mode='triplet', # binary\n",
    "    amount=1  \n",
    "    #weight=  # \"Probabilities\" of nodes to be sampled: Node degree follows power law distribution\n",
    "    )\n",
    "\n",
    "data[target_edge].edge_label = None\n",
    "linkNeighborLoader = LinkNeighborLoader(\n",
    "        data,\n",
    "        num_neighbors=num_neighbors_linkloader,\n",
    "        edge_label_index=(target_edge, data[target_edge].edge_label_index), \n",
    "        neg_sampling=negative_sampling, \n",
    "        batch_size=32,\n",
    "        shuffle=True, \n",
    "        num_workers=0,\n",
    "        directed=False,  \n",
    "        pin_memory=True, \n",
    "        is_sorted = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = next(iter(linkNeighborLoader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['qualifications'].n_id[a['qualifications'].dst_pos_index[0]], a['skills'].n_id[a['skills'].src_index[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['skills', 'qualification_skill', 'qualifications'].input_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[target_edge].edge_label_index[:,221]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyg_torch21",
   "language": "python",
   "name": "pyg_torch21"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
