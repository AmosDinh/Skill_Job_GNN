{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7kMzXI99v30",
        "outputId": "7a9b9b16-0ecb-4ae6-a458-c72f12fab3ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "  from google.colab import drive\n",
        "  colab_path = '/content/'\n",
        "  drive.mount('/content/drive',force_remount=True)\n",
        "  DRIVE_FOLDER = Path('/content/drive/MyDrive/DataExplorationProject/Skill_Ontology_GNN')\n",
        "  colab = True\n",
        "else:\n",
        "  colab_path = ''\n",
        "  colab = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kMPbBOCDDKIG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from matplotlib import pyplot as plt\n",
        "import gc\n",
        "\n",
        "class Trainer:\n",
        "    def __init__(self, model, criterion, optimizer, device, metrics=[]):\n",
        "        self.model = model\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        self.device = device\n",
        "        self.metrics_history = self.create_metrics_history(metrics)\n",
        "        self.epoch = 0\n",
        "\n",
        "    def create_metrics_history(self, metrics):\n",
        "        metrics = set(metrics)\n",
        "        metrics.add('epoch')\n",
        "        metrics.add('minibatch')\n",
        "        metrics.add('accuracy')\n",
        "        metrics.add('loss')\n",
        "\n",
        "        metrics = list(metrics)\n",
        "        metrics_history={}\n",
        "        for split in ['train','val']:\n",
        "            metrics_history[split]={}\n",
        "            for metric in metrics:\n",
        "                metrics_history[split][metric]=[]\n",
        "        return metrics_history\n",
        "\n",
        "    def free_memory(self):\n",
        "        \"\"\"Clears the GPU cache and triggers garbage collection, to reduce OOMs.\"\"\"\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "    def train(self, dataloader, n_epochs, save_interval, save_path):\n",
        "        self.free_memory()\n",
        "        self.model.train()\n",
        "        for epoch in range(self.epoch, self.epoch+n_epochs):\n",
        "            print(f'=============== Epoch {epoch} ===============')\n",
        "            for batch_idx, (data, target) in enumerate(dataloader):\n",
        "                data, target = data.to(self.device), target.to(self.device)\n",
        "                self.optimizer.zero_grad()\n",
        "                output = self.model(data)\n",
        "                loss = self.criterion(output, target)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                self.train_losses.append(loss.item())\n",
        "                if batch_idx % save_interval == 0:\n",
        "                    self.save_checkpoint(batch_idx, save_path)\n",
        "\n",
        "                print(f'Mini-Batch {batch_idx}, Loss: {loss}')\n",
        "\n",
        "    def validate(self, dataloader):\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            for data, target in dataloader:\n",
        "                data, target = data.to(self.device), target.to(self.device)\n",
        "                output = self.model(data)\n",
        "                loss = self.criterion(output, target)\n",
        "                self.val_losses.append(loss.item())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def save_checkpoint(self, batch_idx, save_path):\n",
        "        print('save')\n",
        "        torch.save({\n",
        "            'model_state_dict': self.model.state_dict(),\n",
        "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "            'metrics_history': self.metrics_history,\n",
        "        }, f'{save_path}/checkpoint_{batch_idx}.pt')\n",
        "\n",
        "    def load_checkpoint(self, load_path):\n",
        "        checkpoint = torch.load(load_path)\n",
        "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        self.train_losses = checkpoint['train_losses']\n",
        "        self.val_losses = checkpoint['val_losses']\n",
        "\n",
        "    def plot_losses(self):\n",
        "        plt.figure(figsize=(10,5))\n",
        "        plt.title(\"Training and Validation Loss\")\n",
        "        plt.plot(self.train_losses,label=\"train\")\n",
        "        plt.plot(self.val_losses,label=\"val\")\n",
        "        plt.xlabel(\"iterations\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.legend()\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "bCh0sDNr-I8D",
        "outputId": "c78900b5-79c1-412b-8f99-b991c20e376a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.1+cu118\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torch_geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting transformers<5.0.0,>=4.6.0 (from sentence-transformers)\n",
            "  Downloading transformers-4.33.3-py3-none-any.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.15.2+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (3.8.1)\n",
            "Collecting sentencepiece (from sentence-transformers)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub>=0.4.0 (from sentence-transformers)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.12.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers) (16.0.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.6.3)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers<5.0.0,>=4.6.0->sentence-transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m100.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers<5.0.0,>=4.6.0->sentence-transformers)\n",
            "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=f6c740d9a784edc8cb45b0ccad7e80ad2054fc36c54302e7fa64433e9905fdd2\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: tokenizers, sentencepiece, safetensors, huggingface-hub, transformers, sentence-transformers\n",
            "Successfully installed huggingface-hub-0.17.3 safetensors-0.3.3 sentence-transformers-2.2.2 sentencepiece-0.1.99 tokenizers-0.13.3 transformers-4.33.3\n",
            "Collecting torcheval\n",
            "  Downloading torcheval-0.0.7-py3-none-any.whl (179 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.2/179.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torcheval) (4.5.0)\n",
            "Installing collected packages: torcheval\n",
            "Successfully installed torcheval-0.0.7\n",
            "Archive:  /content/drive/MyDrive/DataExplorationProject/Skill_Ontology_GNN/neo4jgraph.zip\n",
            "   creating: neo4jgraph/\n",
            "  inflating: neo4jgraph/.DS_Store    \n",
            "  inflating: __MACOSX/neo4jgraph/._.DS_Store  \n",
            "  inflating: neo4jgraph/skills.csv   \n",
            "  inflating: __MACOSX/neo4jgraph/._skills.csv  \n",
            "  inflating: neo4jgraph/onet_broader.csv  \n",
            "  inflating: __MACOSX/neo4jgraph/._onet_broader.csv  \n",
            "  inflating: neo4jgraph/onet_related_occupations.csv  \n",
            "  inflating: __MACOSX/neo4jgraph/._onet_related_occupations.csv  \n",
            "  inflating: neo4jgraph/onet_skills_unique.csv  \n",
            "  inflating: __MACOSX/neo4jgraph/._onet_skills_unique.csv  \n",
            "  inflating: neo4jgraph/skill_skill_edges.csv  \n",
            "  inflating: __MACOSX/neo4jgraph/._skill_skill_edges.csv  \n",
            "  inflating: neo4jgraph/tfidf_skill_job_edge.csv  \n",
            "  inflating: __MACOSX/neo4jgraph/._tfidf_skill_job_edge.csv  \n",
            "  inflating: content/neo4jgraph/onet_alt_titles_unique.csv  \n",
            "  inflating: content/neo4jgraph/onet_broader.csv  \n",
            "  inflating: content/neo4jgraph/onet_related_occupations.csv  \n",
            "  inflating: content/neo4jgraph/onet_skills_unique.csv  \n",
            "  inflating: content/neo4jgraph/skills.csv  \n",
            "  inflating: content/neo4jgraph/skill_skill_edges.csv  \n",
            "  inflating: content/neo4jgraph/tfidf_skill_job_edge.csv  \n"
          ]
        }
      ],
      "source": [
        "if colab:\n",
        "    # Install required packages.\n",
        "    import os\n",
        "    import torch\n",
        "    os.environ['TORCH'] = torch.__version__\n",
        "    print(torch.__version__)\n",
        "\n",
        "    !pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "    !pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "    !pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "    !pip install sentence-transformers\n",
        "    !pip install torcheval\n",
        "    # unpack datasets\n",
        "    if not 'unzipped' in globals():\n",
        "        !unzip /content/drive/MyDrive/DataExplorationProject/Skill_Ontology_GNN/neo4jgraph.zip\n",
        "        unzipped =True"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dFUH8XJGsiaq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "p1oM_TnG9udQ",
        "outputId": "094d85e4-269c-4906-ee4b-396d85fec6d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-ced2f3d2c268>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    import torch_g'display.max_rows', 50)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from torch_geometric.data import HeteroData\n",
        "import torcheometric.transforms as T\n",
        "pd.set_option(\n",
        "import torch_g'display.max_rows', 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hb6bIOsz9udU"
      },
      "outputs": [],
      "source": [
        "# only use skill nodes which have normalized_name != NaN, this is some indication of quality skill (?)\n",
        "skill_nodes = pd.read_csv(colab_path+'neo4jgraph/skills.csv').dropna(subset=['normalized_name']).reset_index()\n",
        "job_nodes = pd.read_csv(colab_path+'neo4jgraph/onet_skills_unique.csv')\n",
        "\n",
        "# drop some skills \"or\"\n",
        "skill_nodes = skill_nodes.loc[~skill_nodes.skill.isin(['or','technology'])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Jj8pvb49udV"
      },
      "outputs": [],
      "source": [
        "# There are duplicate normalized names\n",
        "skill_nodes.shape[0]-skill_nodes.normalized_name.unique().shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTuAjvSa9udV"
      },
      "outputs": [],
      "source": [
        "# There are not as many skill names which are duplicate\n",
        "skill_nodes.shape[0]-skill_nodes.skill.unique().shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LwaRmpWL9udW"
      },
      "outputs": [],
      "source": [
        "# we can not use normalized name instead of skill, because it is ambiguous, e.g. communication points to different normalized names\n",
        "skill_nodes.loc[skill_nodes.skill=='communication']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GIlL1tPh9udW"
      },
      "outputs": [],
      "source": [
        "skill_nodes.drop_duplicates(subset='skill', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zPzgTNR79udW"
      },
      "outputs": [],
      "source": [
        "\n",
        "skill_job_edges = pd.read_csv(colab_path+'neo4jgraph/tfidf_skill_job_edge.csv')\n",
        "#skill_job_edges = skill_job_edges.loc[skill_job_edges.scaled_tfidf>8]\n",
        "# only use edges where we have the skill and job for from the other files\n",
        "skill_job_edges = skill_job_edges.loc[skill_job_edges['skill'].isin(skill_nodes['skill'])]\n",
        "skill_job_edges = skill_job_edges.loc[skill_job_edges['alt_title'].isin(job_nodes.index)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVB9kvu49udX"
      },
      "outputs": [],
      "source": [
        "skill_job_edges"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gppNxu5m9udX"
      },
      "outputs": [],
      "source": [
        "#for each alt title select the first 20 skill_job edges, ordered by tfidf\n",
        "skill_job_edges = skill_job_edges.groupby('alt_title').apply(lambda group: group.nlargest(20,'scaled_tfidf')).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0twUk4Pf9udX"
      },
      "outputs": [],
      "source": [
        "skill_job_edges"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCzFw-fn9udY"
      },
      "outputs": [],
      "source": [
        "skillmapping ={}\n",
        "for i,skill in enumerate(skill_nodes.skill.unique()):\n",
        "    skillmapping[skill] =i\n",
        "\n",
        "jobmapping ={}\n",
        "for i,index in enumerate(job_nodes['index'].unique()):\n",
        "    jobmapping[index] =i\n",
        "\n",
        "inverted_skillmapping = {v:k for k,v in skillmapping.items()}\n",
        "inverted_jobmapping = {v:k for k,v in jobmapping.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHirmQzn9udY"
      },
      "outputs": [],
      "source": [
        "skill_job_edges['skill_dst'] = skill_job_edges['skill'].apply(lambda x:skillmapping[x])\n",
        "skill_job_edges['job_src'] = skill_job_edges['alt_title'].apply(lambda x:jobmapping[x])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Yfi1fRd9udY"
      },
      "outputs": [],
      "source": [
        "onet_alttitles = pd.read_csv(colab_path+'/content/neo4jgraph/onet_alt_titles_unique.csv')\n",
        "del onet_alttitles['Unnamed: 0']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8FgE8nyo9udY"
      },
      "outputs": [],
      "source": [
        "onet_alttitle_str_mapping = {}\n",
        "for i,row in onet_alttitles.iterrows():\n",
        "    onet_alttitle_str_mapping[row['index']] = row['Alternate Title']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E1_J7gV59udY"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1yTzdBoU9udZ"
      },
      "outputs": [],
      "source": [
        "# create alttitle sbert embeddings to get pca dim\n",
        "\n",
        "alttitle_sbert_embeddings = embedder.encode(list(onet_alttitle_str_mapping.values()), convert_to_tensor=False, device='cuda')\n",
        "#alttitle_sbert_indices = [k for k,v in temp]\n",
        "#corpus_embeddings = util.normalize_embeddings(corpus_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "de19o3FI9udZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "v = alttitle_sbert_embeddings[0]\n",
        "np.matmul(v.T,v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQsE8smF9udZ"
      },
      "outputs": [],
      "source": [
        "skill_sbert_embeddings = embedder.encode(list(skillmapping.keys()), convert_to_tensor=False, device='cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAT18fhw9udZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.decomposition import PCA\n",
        "X = np.concatenate([alttitle_sbert_embeddings,skill_sbert_embeddings])\n",
        "\n",
        "# print('Original:',X.shape[1])\n",
        "# for variance_retained in [0.99,0.95,0.9,0.8,0.75,0.7]:\n",
        "#     pca = PCA(n_components=variance_retained)\n",
        "#     pca.fit(X)\n",
        "#     n_components_retained = pca.n_components_\n",
        "#     print(n_components_retained,' components retained', variance_retained, ' variance retained')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vK1p6Rf-9udZ"
      },
      "outputs": [],
      "source": [
        "# choose 128\n",
        "pca = PCA(n_components=128)\n",
        "pca.fit(X)\n",
        "\n",
        "skill_sbert_embeddings = pca.transform(embedder.encode(skill_nodes['skill'].tolist(), convert_to_numpy=True, device='cuda'))\n",
        "job_sbert_embeddings = pca.transform(embedder.encode(job_nodes['Alternate Title'].tolist(), convert_to_numpy=True, device='cuda'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vD1fRkf9udZ"
      },
      "outputs": [],
      "source": [
        "# add job-job edges, dataset see https://www.onetcenter.org/dictionary/26.3/excel/related_occupations.html\n",
        "job_job_edges = pd.read_csv(colab_path+'neo4jgraph/onet_related_occupations.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMsTH1Sx9udZ"
      },
      "outputs": [],
      "source": [
        "job_job_edges"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1lR651a9uda"
      },
      "outputs": [],
      "source": [
        "job_job_edges['job_src'] = job_job_edges['index_x'].apply(lambda x: jobmapping[x])\n",
        "job_job_edges['job_dst'] = job_job_edges['index_y'].apply(lambda x: jobmapping[x])\n",
        "relatedness_weight = {\n",
        "    'Supplemental':1,\n",
        "    'Primary-Long':2,\n",
        "    'Primary-Short':4\n",
        "}\n",
        "job_job_edges['relatedness_weight'] = job_job_edges['Relatedness Tier'].apply(lambda x: relatedness_weight[x])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1Wc7CIL9uda"
      },
      "outputs": [],
      "source": [
        "skill_skill_edges = pd.read_csv(colab_path+'neo4jgraph/skill_skill_edges.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8qOHTGfL9uda"
      },
      "outputs": [],
      "source": [
        "#filter out potentially bad skills (which are not in our original skillmapping)\n",
        "skill_skill_edges = skill_skill_edges.loc[(skill_skill_edges.skill.isin(list(skillmapping.keys()))) & (skill_skill_edges.related_skill.isin(list(skillmapping.keys())))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQhTLGTV9uda"
      },
      "outputs": [],
      "source": [
        "skill_skill_edges['skill_src'] = skill_skill_edges['skill'].apply(lambda x: skillmapping[x])\n",
        "skill_skill_edges['skill_dst'] = skill_skill_edges['related_skill'].apply(lambda x: skillmapping[x])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DahEKZBB9uda"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "La85Q2M59uda"
      },
      "outputs": [],
      "source": [
        "data = HeteroData()\n",
        "data['Skill'].x = torch.tensor(skill_sbert_embeddings)\n",
        "data['Job'].x = torch.tensor(job_sbert_embeddings)\n",
        "\n",
        "data['Job','REQUIRES','Skill'].edge_index = torch.tensor(skill_job_edges[['job_src','skill_dst']].to_numpy().T)\n",
        "data['Skill','IS_SIMILAR_SKILL','Skill'].edge_index = torch.tensor(skill_skill_edges[['skill_src','skill_dst']].to_numpy().T)\n",
        "data['Job','IS_SIMILAR_JOB','Job'].edge_index = torch.tensor(job_job_edges[['job_src','job_dst']].to_numpy().T)\n",
        "\n",
        "\n",
        "data['Job','REQUIRES','Skill'].edge_weight = torch.tensor(skill_job_edges['scaled_tfidf'].to_numpy()).to(torch.float)\n",
        "data['Skill','IS_SIMILAR_SKILL','Skill'].edge_weight = torch.tensor(skill_skill_edges['cosine_sim_score'].to_numpy()).to(torch.float)\n",
        "data['Job','IS_SIMILAR_JOB','Job'].edge_weight = torch.tensor(job_job_edges['relatedness_weight'].to_numpy()).to(torch.float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M7tf8glw9uda"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZAF_riX9uda"
      },
      "outputs": [],
      "source": [
        "data.has_isolated_nodes(), data.has_self_loops()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5MjvjO09uda"
      },
      "outputs": [],
      "source": [
        "#data = data.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMAfCM0u9uda"
      },
      "outputs": [],
      "source": [
        "import torch_geometric.transforms as T\n",
        "\n",
        "transform = T.Compose([\n",
        "       T.RemoveIsolatedNodes(),\n",
        "       T.RemoveDuplicatedEdges(),\n",
        "       T.ToUndirected(merge=False) # don't merge reversed edges into the original edge type\n",
        "])\n",
        "\n",
        "data = transform(data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yk4D68v69udb"
      },
      "outputs": [],
      "source": [
        "transform = T.RandomLinkSplit(\n",
        "    is_undirected=True,\n",
        "    edge_types=[\n",
        "        ('Job', 'REQUIRES', 'Skill'),\n",
        "        ('Skill', 'IS_SIMILAR_SKILL', 'Skill'),\n",
        "        ('Job', 'IS_SIMILAR_JOB', 'Job')\n",
        "        ],\n",
        "    # rev_edge_types=[\n",
        "    #     ('Skill', 'rev_REQUIRES', 'Job'),\n",
        "    #     ('Skill', 'rev_IS_SIMILAR_SKILL', 'Skill'),\n",
        "    #     ('Job', 'rev_IS_SIMILAR_JOB', 'Job')\n",
        "    # ],\n",
        "    num_val=0.001,\n",
        "    num_test=0.001,\n",
        "    add_negative_train_samples=False, # only adds neg samples for val and test, neg train are added by LinkNeighborLoader. This means for each train batch, negs. are different, for val and train they stay the same\n",
        "    neg_sampling_ratio=1.0,\n",
        "    disjoint_train_ratio=0 #  training edges are shared for message passing and supervision\n",
        "\n",
        "    )\n",
        "train_data, val_data, test_data = transform(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zG7w63019udb"
      },
      "outputs": [],
      "source": [
        "# from torch_geometric.loader import NeighborLoader\n",
        "\n",
        "# train_loader = NeighborLoader(\n",
        "#     train_data,\n",
        "#     # Sample 15 neighbors for each node and each edge type for 2 iterations:\n",
        "#     num_neighbors={\n",
        "#          ('Job', 'REQUIRES', 'Skill'):[1000,10], # [add x neighbors, add y neighbors for every x neighbor]\n",
        "#          ('Skill', 'rev_REQUIRES', 'Job'):[10,0],\n",
        "#         ('Skill', 'IS_SIMILAR_SKILL', 'Skill'):[10,10],\n",
        "#         ('Skill', 'rev_IS_SIMILAR_SKILL', 'Skill'):[0,0],\n",
        "#         ('Job', 'IS_SIMILAR_JOB', 'Job'):[0,20], # can't sample job-job in first iteration\n",
        "#         ('Job', 'rev_IS_SIMILAR_JOB', 'Job'):[0,20],\n",
        "#          },\n",
        "#     # num_neighbors = [10,10],\n",
        "#     # Use a batch size of 128 for sampling training nodes of type \"paper\":\n",
        "#     batch_size=200,\n",
        "#     input_nodes='Job', #if not set, we consider all nodes\n",
        "#     shuffle=True,\n",
        "#     drop_last=True,\n",
        "#     num_workers=4,\n",
        "#     directed=True,  # contains only edges which are followed randomly, False: contains full node induced subgraph\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1n7iu1YK9udb"
      },
      "outputs": [],
      "source": [
        "from itertools import cycle\n",
        "from typing import Tuple, List, Union\n",
        "from torch_geometric.loader import LinkNeighborLoader\n",
        "from torch_geometric.sampler import NegativeSampling\n",
        "\n",
        "def create_loader(data:HeteroData, edge:Tuple[str,str,str], num_neighbors:List[int], batch_size:int, is_training:bool)->LinkNeighborLoader:\n",
        "\n",
        "    print('create mini-batches for', edge)\n",
        "\n",
        "    negative_sampling = NegativeSampling(\n",
        "        mode='binary',\n",
        "        amount=20  # ratio, like Graphsage\n",
        "        #weight=  # \"Probabilities\" of nodes to be sampled: Node degree follows power law distribution\n",
        "        )\n",
        "\n",
        "    loader = LinkNeighborLoader(\n",
        "        data,\n",
        "        num_neighbors={\n",
        "            ('Job', 'REQUIRES', 'Skill'):num_neighbors,\n",
        "            ('Skill', 'rev_REQUIRES', 'Job'):num_neighbors,\n",
        "            ('Skill', 'IS_SIMILAR_SKILL', 'Skill'):num_neighbors, # In this example, index 0 will never be used, since neighboring edge to a job node can't be a skill-skill edge\n",
        "            ('Skill', 'rev_IS_SIMILAR_SKILL', 'Skill'):num_neighbors,\n",
        "            ('Job', 'IS_SIMILAR_JOB', 'Job'):num_neighbors,\n",
        "            ('Job', 'rev_IS_SIMILAR_JOB', 'Job'):num_neighbors,\n",
        "        },\n",
        "        edge_label_index=(edge, None), # None means all edges are considered\n",
        "        #edge_label =train_data[edge].edge_label,\n",
        "        neg_sampling=negative_sampling, # adds negative samples\n",
        "        batch_size=batch_size,\n",
        "        shuffle=is_training,\n",
        "        #drop_last=True,\n",
        "        num_workers=2,\n",
        "        directed=True,  # contains only edges which are followed, False: contains full node induced subgraph\n",
        "        #disjoint=True # sampled seed node creates its own, disjoint from the rest, subgraph, will add \"batch vector\" to loader output\n",
        "    )\n",
        "\n",
        "    return loader\n",
        "\n",
        "\n",
        "batch_size=256\n",
        "num_neighbors = [5,2]\n",
        "\n",
        "train_loaders, val_loaders, test_loaders = [], [], []\n",
        "for edge_type in train_data.edge_types:\n",
        "    # create mini-batches for each edge type, because LinkNeighborLoader only allows one target edge type\n",
        "\n",
        "    datasets = {\n",
        "        'train':train_data,\n",
        "        'val': val_data,\n",
        "        'test': test_data\n",
        "    }\n",
        "    loader = create_loader(\n",
        "        data=train_data,\n",
        "        edge=edge_type,\n",
        "        num_neighbors=num_neighbors,\n",
        "        batch_size=batch_size,\n",
        "        is_training=True\n",
        "    )\n",
        "    train_loaders.append(loader)\n",
        "\n",
        "    loader = create_loader(\n",
        "        data=val_data,\n",
        "        edge=edge_type,\n",
        "        num_neighbors=num_neighbors,\n",
        "        batch_size=batch_size,\n",
        "        is_training=False\n",
        "    )\n",
        "\n",
        "    val_loaders.append(loader)\n",
        "\n",
        "    loader = create_loader(\n",
        "        data=test_data,\n",
        "        edge=edge_type,\n",
        "        num_neighbors=num_neighbors,\n",
        "        batch_size=batch_size,\n",
        "        is_training=False\n",
        "    )\n",
        "\n",
        "    test_loaders.append(loader)\n",
        "\n",
        "def combined_iterator(iterables):\n",
        "  # creates an iterator which has as many elements as the longest iterable\n",
        "  # other iterables will be repeated until the longest is done\n",
        "  length = 0\n",
        "  index = 0\n",
        "  for i, iterable in enumerate(iterables):\n",
        "    l = len(iterable)\n",
        "    if l>length:\n",
        "      length = l\n",
        "      index = i\n",
        "\n",
        "  longest_iterable = iterables.pop(index)\n",
        "  iterators = [longest_iterable] + [cycle(it) for it in iterables]\n",
        "  return zip(*iterables)\n",
        "\n",
        "\n",
        "train_iterator = combined_iterator(train_loaders)\n",
        "val_iterator = combined_iterator(val_loaders)\n",
        "test_iterator = combined_iterator(test_loaders)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnWJyyeC9udb"
      },
      "outputs": [],
      "source": [
        "# helpful article\n",
        "# https://medium.com/stanford-cs224w/a-tour-of-pygs-data-loaders-9f2384e48f8f\n",
        "\n",
        "# some info\n",
        "\n",
        "# HeteroData(\n",
        "#   Job={\n",
        "#     x=[9222, 128], # node features\n",
        "#     n_id=[9222] # the ids of the nodes in the original train_data set\n",
        "#   },\n",
        "#   (Job, REQUIRES, Skill)={\n",
        "#     edge_index=[2, 14498], # sampled edges\n",
        "#     edge_attr=[14498, 1],  # edge attributes of sampled edges\n",
        "#     edge_label=[509170], # 1 if it is a true edge, 0 if it is a false\n",
        "#     edge_label_index=[2, 509170], # all edges?\n",
        "#     e_id=[14498] # edge ids of edges in the original train_data set\n",
        "\n",
        "\n",
        "\n",
        "# if batchsize is 16 for the edge and we have neg_sampling=binary, we will have\n",
        "# this many jobs:\n",
        "#  Job={\n",
        "#     x=[64, 128],\n",
        "#     n_id=[64]\n",
        "#   },\n",
        "# since we sample a negative and a positive edge each, and each edge has 2 Job nodes (if our target is the job nodes)\n",
        "\n",
        "# LinkNeighborloader will sample negative edges for the target edges only, as we expect it\n",
        "# so for the \"neighbor\"-edges we get only positive ones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dI4AQ3kq9udc"
      },
      "outputs": [],
      "source": [
        "from typing import Tuple, Union\n",
        "from torch import Tensor\n",
        "from torch_geometric.nn import to_hetero, HeteroDictLinear, Linear\n",
        "from torch_geometric.nn.conv import GraphConv, SAGEConv, SimpleConv\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.typing import Adj, OptPairTensor, OptTensor, Size\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# PyG does not implement the exact max pooling aggregation as in the GraphSage paper\n",
        "# with GraphConvWithPool we manually extend it by adding a linear layer on x before .propagate\n",
        "# as our activation function is monotonically increasing, this modification corresponds to the max pooling aggregation\n",
        "\n",
        "class GraphConvWithPool(GraphConv):\n",
        "    def __init__(self, in_channels, out_channels: int, aggr: str = 'add', bias: bool = True, **kwargs):\n",
        "        super().__init__(in_channels, out_channels, aggr, bias, **kwargs)\n",
        "        self.linear = torch.nn.Linear(in_channels, in_channels, bias=False)\n",
        "\n",
        "    def forward(self, x: Union[Tensor, OptPairTensor], edge_index: Adj,\n",
        "                edge_weight: OptTensor = None, size: Size = None) -> Tensor:\n",
        "\n",
        "        if isinstance(x, Tensor):\n",
        "            x: OptPairTensor = (x, x)\n",
        "\n",
        "        x = self.linear(x) # added this\n",
        "\n",
        "        out = self.propagate(edge_index, x=x, edge_weight=edge_weight,\n",
        "                             size=size)\n",
        "        out = self.lin_rel(out)\n",
        "\n",
        "        x_r = x[1]\n",
        "        if x_r is not None:\n",
        "            out = out + self.lin_root(x_r)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "class WeightedSkillSage(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels, out_channels, aggregator='max'):\n",
        "        super().__init__()\n",
        "        #self.linear1 = Linear(-1,-1)\n",
        "        #self.conv1 = SimpleConv(aggr='sum')\n",
        "        self.conv1 = GraphConv(in_channels=-1, out_channels=hidden_channels)\n",
        "        self.conv2 = GraphConv(in_channels=hidden_channels, out_channels=hidden_channels)\n",
        "        self.linear3 = Linear(hidden_channels,out_channels)\n",
        "\n",
        "    def forward(self, x: HeteroData, edge_index, edge_weight):\n",
        "        x = self.conv1(x, edge_index, edge_weight=edge_weight)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index, edge_weight=edge_weight)\n",
        "        x = F.relu(x)\n",
        "        x = self.linear3(x)\n",
        "        return x\n",
        "\n",
        "model = WeightedSkillSage(hidden_channels=64, out_channels=64)\n",
        "model = to_hetero(model, train_data.metadata(), aggr='sum')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQbpUFGwF-Zx"
      },
      "outputs": [],
      "source": [
        "from torcheval.metrics import BinaryAccuracy, BinaryPrecision, BinaryRecall, BinaryF1Score, BinaryAUPRC\n",
        "\n",
        "class GNNTrainer(Trainer):\n",
        "    def __init__(self, model, criterion, optimizer, device):\n",
        "        super().__init__(model, criterion, optimizer, device, metrics=['f1','accuracy','precision','recall', 'aucpr'])\n",
        "\n",
        "    def get_supervision_edge_type(self, heterodata):\n",
        "        for edge_type in heterodata.edge_types:\n",
        "            if 'input_id' in heterodata[edge_type].keys():\n",
        "                return edge_type\n",
        "\n",
        "    def calculate_metrics(self, split_name, y_hat, y):\n",
        "        y = y.to(torch.int)\n",
        "        acc, prec, rec, f1, aucpr = BinaryAccuracy(threshold=0.5).update(y_hat, y).compute().item(), BinaryPrecision(threshold=0.5).update(y_hat, y).compute().item(), BinaryRecall(threshold=0.5).update(y_hat, y).compute().item(), BinaryF1Score(threshold=0.5).update(y_hat, y).compute().item(), BinaryAUPRC().update(y_hat, y).compute().item()\n",
        "        '''  self.metrics_history[split_name]['accuracy'].append(acc)\n",
        "        self.metrics_history[split_name]['precision'].append(prec)\n",
        "        self.metrics_history[split_name]['recall'].append(rec)\n",
        "        self.metrics_history[split_name]['f1'].append(f1)\n",
        "        self.metrics_history[split_name]['aucpr'].append(aucpr) '''\n",
        "        print(f'{split_name}: F1: {f1}, AUC-PR: {aucpr}, (acc: {acc}, prec: {prec}, rec: {rec})')\n",
        "\n",
        "    def train(self, train_iterator, val_iterator, start_epoch, n_epochs, save_interval, save_path):\n",
        "        self.free_memory()\n",
        "\n",
        "        self.model.train()\n",
        "        for epoch in range(start_epoch, start_epoch+n_epochs):\n",
        "            print(f'=============== Epoch {epoch} ===============')\n",
        "            for batch_idx, edge_batches in enumerate(train_iterator):\n",
        "                self.optimizer.zero_grad()\n",
        "                minibatch_loss = 0\n",
        "\n",
        "                y_hat, y = [], []\n",
        "                for i,batch in enumerate(edge_batches):  # each batch here is one edge type, since we want to learn for all edge types\n",
        "                    print(i,end='\\r')\n",
        "                    batch = batch.to(self.device)\n",
        "                    hetero_out = model(batch.x_dict, batch.edge_index_dict, batch.edge_weight_dict)  # get model output\n",
        "\n",
        "                    # evaluate, calculate cosine sim and compute cross-entropy loss\n",
        "                    supervision_edge_type = self.get_supervision_edge_type(batch)\n",
        "                    src_type, dst_type = supervision_edge_type[0], supervision_edge_type[2]\n",
        "                    edge_label = batch[supervision_edge_type].edge_label\n",
        "                    edge_label_index = batch[supervision_edge_type].edge_label_index\n",
        "                    src_node_embeddings = hetero_out[src_type][edge_label_index[0]]\n",
        "                    dst_node_embeddings = hetero_out[dst_type][edge_label_index[1]]\n",
        "                    logits = F.cosine_similarity(src_node_embeddings, dst_node_embeddings, dim=-1)\n",
        "                    loss = self.criterion(logits, edge_label)\n",
        "                    minibatch_loss += loss\n",
        "\n",
        "                    y_hat.append(torch.sigmoid(logits))\n",
        "                    y.append(edge_label)\n",
        "\n",
        "                minibatch_loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "                # save loss and metrics\n",
        "                self.metrics_history['train']['minibatch'].append(epoch+batch_idx)\n",
        "                self.metrics_history['train']['epoch'].append(epoch+batch_idx)\n",
        "                self.metrics_history['train']['loss'].append(minibatch_loss.item())\n",
        "\n",
        "                y_hat = torch.cat(y_hat)\n",
        "                y = torch.cat(y)\n",
        "                print(\"aa\")\n",
        "                self.calculate_metrics('train', y_hat, y)\n",
        "\n",
        "                if batch_idx % save_interval == 0:\n",
        "                    print('bb')\n",
        "                    self.free_memory()\n",
        "                    self.validate(val_iterator, epoch)\n",
        "                    self.save_checkpoint(batch_idx, save_path)\n",
        "\n",
        "                print(f'Mini-Batch {batch_idx}, Loss: {loss}')\n",
        "\n",
        "    def validate(self, val_iterator, epoch):\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "          y_hat, y = [], []\n",
        "          for edge_batches in tqdm(val_iterator):\n",
        "\n",
        "              for batch in edge_batches:  # each batch here is one edge type, since we want to learn for all edge types\n",
        "\n",
        "                    batch = batch.to(self.device)\n",
        "                    hetero_out = model(batch.x_dict, batch.edge_index_dict, batch.edge_weight_dict)  # get model output\n",
        "\n",
        "                    # evaluate, calculate cosine sim and compute cross-entropy loss\n",
        "                    supervision_edge_type = self.get_supervision_edge_type(batch)\n",
        "                    src_type, dst_type = supervision_edge_type[0], supervision_edge_type[2]\n",
        "                    edge_label = batch[supervision_edge_type].edge_label\n",
        "                    edge_label_index = batch[supervision_edge_type].edge_label_index\n",
        "                    src_node_embeddings = hetero_out[src_type][edge_label_index[0]]\n",
        "                    dst_node_embeddings = hetero_out[dst_type][edge_label_index[1]]\n",
        "                    logits = F.cosine_similarity(src_node_embeddings, dst_node_embeddings, dim=-1)\n",
        "\n",
        "                    y_hat.append(torch.sigmoid(logits))\n",
        "                    y.append(edge_label)\n",
        "\n",
        "\n",
        "          # save loss and metrics\n",
        "          self.metrics_history['val']['epoch'].append(epoch)\n",
        "\n",
        "          y_hat = torch.cat(y_hat)\n",
        "          y = torch.cat(y)\n",
        "          self.calculate_metrics('val', y_hat, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hsOdxQu-FgBD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.000001)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "model = model.to(device)\n",
        "trainer = GNNTrainer(model, criterion, optimizer, device)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "trainer.train(train_iterator, val_iterator, start_epoch=0, n_epochs=10, save_interval=1, save_path='./checkpoints')\n",
        "# trainer.validate(val_dataloader)\n",
        "# trainer.plot_losses()\n",
        "# trainer.load_checkpoint('./checkpoints/checkpoint_100.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9hY5T9f9udc"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "import os\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
        "# with torch.no_grad():  # Initialize lazy modules.\n",
        "#      out = model(batch.x_dict, batch.edge_index_dict, batch.edge_weight_dict)\n",
        "def get_supervision_edge_type(heterodata):\n",
        "    for edge_type in heterodata.edge_types:\n",
        "        if 'input_id' in heterodata[edge_type].keys():\n",
        "            return edge_type\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.000001)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "model.train()\n",
        "for edge_batches in train_iterator:\n",
        "    minibatch_loss = 0\n",
        "\n",
        "\n",
        "    # each batch here is one edge type, since we want to learn for all edge types\n",
        "    for batch in edge_batches:\n",
        "        batch = batch.to(device)\n",
        "        hetero_out = model(batch.x_dict, batch.edge_index_dict, batch.edge_weight_dict)\n",
        "\n",
        "        supervision_edge_type = get_supervision_edge_type(batch)\n",
        "        src_type, dst_type = supervision_edge_type[0], supervision_edge_type[2]\n",
        "        edge_label = batch[supervision_edge_type].edge_label\n",
        "        edge_label_index = batch[supervision_edge_type].edge_label_index\n",
        "        src_node_embeddings = hetero_out[src_type][edge_label_index[0]]\n",
        "        dst_node_embeddings = hetero_out[dst_type][edge_label_index[1]]\n",
        "        logits = F.cosine_similarity(src_node_embeddings, dst_node_embeddings, dim=-1)\n",
        "        loss = loss_fn(logits, edge_label)\n",
        "        minibatch_loss += loss\n",
        "\n",
        "    minibatch_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print('mini-batch loss:',float(batch_loss))\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TV_wLrgk9udg"
      },
      "outputs": [],
      "source": [
        "free_memory()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rr-vuVB49udg"
      },
      "outputs": [],
      "source": [
        "supervision_edge_type = get_supervision_edge_type(batch)\n",
        "src_type, dst_type = supervision_edge_type[0], supervision_edge_type[2]\n",
        "edge_label = batch[supervision_edge_type].edge_label\n",
        "edge_label_index = batch[supervision_edge_type].edge_label_index\n",
        "src_node_embeddings = out[src_type][edge_label_index[0]]\n",
        "dst_node_embeddings = out[dst_type][edge_label_index[1]]\n",
        "torch.min(F.cosine_similarity(src_node_embeddings, dst_node_embeddings, dim=-1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0iKpZ0709udg"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "\n",
        "gc.collect()\n",
        "\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MoCV-11H9udg"
      },
      "outputs": [],
      "source": [
        "batch[supervision_edge_type].edge_label_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgWVOJMI9udg"
      },
      "outputs": [],
      "source": [
        "J2S = ('Job','REQUIRES','Skill')\n",
        "batch[J2S].edge_label_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Ok0V2Mz9udg"
      },
      "outputs": [],
      "source": [
        "batch['Job','REQUIRES','Skill']."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5nrqKUt9udh"
      },
      "outputs": [],
      "source": [
        "batch = next(iter(train_loaders[0]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKBtbRC49udh"
      },
      "outputs": [],
      "source": [
        "batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-95MPpfm9udh"
      },
      "outputs": [],
      "source": [
        "batch.edge_weight_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XauGYI6S9udh"
      },
      "outputs": [],
      "source": [
        "index = batch['Job','IS_SIMILAR_JOB','Job'].e_id\n",
        "labels = batch['Job','IS_SIMILAR_JOB','Job'].edge_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJYX09RM9udh"
      },
      "outputs": [],
      "source": [
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.datasets import OGB_MAG\n",
        "from torch_geometric.nn import SAGEConv, to_hetero\n",
        "\n",
        "\n",
        "dataset = OGB_MAG(root='./data', preprocess='metapath2vec', transform=T.ToUndirected())\n",
        "data = dataset[0]\n",
        "\n",
        "class GNN(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = SAGEConv(-1, hidden_channels)\n",
        "        self.conv2 = SAGEConv(-1, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index).relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "\n",
        "model = GNN(hidden_channels=64, out_channels=dataset.num_classes)\n",
        "model = to_hetero(model, data.metadata(), aggr='sum')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65-tXuE59udh"
      },
      "outputs": [],
      "source": [
        "#https://colab.research.google.com/drive/1GrAxHyZCZ13jpTkMy9vVO_v_U9nHDdvB#scrollTo=wmiFKI0ovYN4\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ssoj9sM_9udh"
      },
      "outputs": [],
      "source": [
        "# intially we use this GraphConv layer and aggregate using mean\n",
        "# this layer allows the addition of edge weights: the adjacency matrix simply consists not of 1s and 0s but the corresponding weights\n",
        "#https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.GraphConv.html\n",
        "\n",
        "# using max pool\n",
        "# https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.global_max_pool.html#torch_geometric.nn.pool.global_max_pool"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "orig_nbformat": 4,
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}