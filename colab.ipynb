{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7kMzXI99v30",
        "outputId": "003b9b01-a6f6-4a0d-b3c5-b7623d62070a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/amos/mambaforge/envs/pyg/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "  from google.colab import drive\n",
        "  colab_path = '/content/'\n",
        "  drive.mount('/content/drive',force_remount=True)\n",
        "  DRIVE_FOLDER = Path('/content/drive/MyDrive/DataExplorationProject/Skill_Ontology_GNN')\n",
        "  colab = True\n",
        "else:\n",
        "  colab_path = ''\n",
        "  colab = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kMPbBOCDDKIG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from matplotlib import pyplot as plt\n",
        "import gc\n",
        "\n",
        "class Trainer:\n",
        "    def __init__(self, model, criterion, optimizer, device, metrics=[]):\n",
        "        self.model = model\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        self.device = device\n",
        "        self.metrics_history = self.create_metrics_history(metrics)\n",
        "        self.epoch = 0\n",
        "    \n",
        "    def create_metrics_history(self, metrics):\n",
        "        metrics = set(metrics)\n",
        "        metrics.add('epoch')\n",
        "        metrics.add('minibatch')\n",
        "        metrics.add('accuracy')\n",
        "        metrics.add('loss')\n",
        "        \n",
        "        metrics = list(metrics)\n",
        "        metrics_history={}\n",
        "        for split in ['train','val']:\n",
        "            metrics_history[split]={}\n",
        "            for metric in metrics:\n",
        "                metrics_history[split][metric]=[]\n",
        "        return metrics_history\n",
        "\n",
        "    def free_memory(self):\n",
        "        \"\"\"Clears the GPU cache and triggers garbage collection, to reduce OOMs.\"\"\"\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "    def train(self, dataloader, n_epochs, save_interval, save_path):\n",
        "        self.free_memory()\n",
        "        self.model.train()\n",
        "        for epoch in range(self.epoch, self.epoch+n_epochs):\n",
        "            print(f'=============== Epoch {epoch} ===============')\n",
        "            for batch_idx, (data, target) in enumerate(dataloader):\n",
        "                data, target = data.to(self.device), target.to(self.device)\n",
        "                self.optimizer.zero_grad()\n",
        "                output = self.model(data)\n",
        "                loss = self.criterion(output, target)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                self.train_losses.append(loss.item())\n",
        "                if batch_idx % save_interval == 0:\n",
        "                    self.save_checkpoint(batch_idx, save_path)\n",
        "                \n",
        "                print(f'Mini-Batch {batch_idx}, Loss: {loss}')\n",
        "\n",
        "    def validate(self, dataloader):\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            for data, target in dataloader:\n",
        "                data, target = data.to(self.device), target.to(self.device)\n",
        "                output = self.model(data)\n",
        "                loss = self.criterion(output, target)\n",
        "                self.val_losses.append(loss.item())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def save_checkpoint(self, batch_idx, save_path):\n",
        "        print('save')\n",
        "        torch.save({\n",
        "            'model_state_dict': self.model.state_dict(),\n",
        "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "            'metrics_history': self.metrics_history,\n",
        "        }, f'{save_path}/checkpoint_{batch_idx}.pt')\n",
        "\n",
        "    def load_checkpoint(self, load_path):\n",
        "        checkpoint = torch.load(load_path)\n",
        "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        self.train_losses = checkpoint['train_losses']\n",
        "        self.val_losses = checkpoint['val_losses']\n",
        "\n",
        "    def plot_losses(self):\n",
        "        plt.figure(figsize=(10,5))\n",
        "        plt.title(\"Training and Validation Loss\")\n",
        "        plt.plot(self.train_losses,label=\"train\")\n",
        "        plt.plot(self.val_losses,label=\"val\")\n",
        "        plt.xlabel(\"iterations\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.legend()\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bCh0sDNr-I8D"
      },
      "outputs": [],
      "source": [
        "if colab:\n",
        "    # Install required packages.\n",
        "    import os\n",
        "    import torch\n",
        "    os.environ['TORCH'] = torch.__version__\n",
        "    print(torch.__version__)\n",
        "\n",
        "    !pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "    !pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "    !pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "    !pip install sentence-transformers\n",
        "    # unpack datasets\n",
        "    if not 'unzipped' in globals():\n",
        "        !unzip /content/drive/MyDrive/DataExplorationProject/Skill_Ontology_GNN/neo4jgraph.zip\n",
        "        unzipped =True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zUS7yZe-vkr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "p1oM_TnG9udQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from torch_geometric.data import HeteroData\n",
        "import torch\n",
        "import torch_geometric.transforms as T\n",
        "pd.set_option('display.max_rows', 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hb6bIOsz9udU"
      },
      "outputs": [],
      "source": [
        "# only use skill nodes which have normalized_name != NaN, this is some indication of quality skill (?)\n",
        "skill_nodes = pd.read_csv(colab_path+'neo4jgraph/skills.csv').dropna(subset=['normalized_name']).reset_index()\n",
        "job_nodes = pd.read_csv(colab_path+'neo4jgraph/onet_skills_unique.csv')\n",
        "\n",
        "# drop some skills \"or\"\n",
        "skill_nodes = skill_nodes.loc[~skill_nodes.skill.isin(['or','technology'])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Jj8pvb49udV",
        "outputId": "72214791-5760-4693-c99f-91040a7f136b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "38692"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# There are duplicate normalized names\n",
        "skill_nodes.shape[0]-skill_nodes.normalized_name.unique().shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTuAjvSa9udV",
        "outputId": "b8d02675-0966-4592-b12e-661256c827d3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2483"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# There are not as many skill names which are duplicate\n",
        "skill_nodes.shape[0]-skill_nodes.skill.unique().shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "LwaRmpWL9udW",
        "outputId": "d6261dd2-64fd-4221-9082-720681e921af"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>skill</th>\n",
              "      <th>category</th>\n",
              "      <th>normalized_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>695</th>\n",
              "      <td>2229</td>\n",
              "      <td>communication</td>\n",
              "      <td>communication</td>\n",
              "      <td>Third-Party Provider Communication</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1292</th>\n",
              "      <td>4059</td>\n",
              "      <td>communication</td>\n",
              "      <td>healthcare</td>\n",
              "      <td>Communication (Including SBAR)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4228</th>\n",
              "      <td>12919</td>\n",
              "      <td>communication</td>\n",
              "      <td>communication</td>\n",
              "      <td>Friendly Communication</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5528</th>\n",
              "      <td>16927</td>\n",
              "      <td>communication</td>\n",
              "      <td>communication</td>\n",
              "      <td>radio/telephone communication</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6311</th>\n",
              "      <td>19452</td>\n",
              "      <td>communication</td>\n",
              "      <td>communication</td>\n",
              "      <td>communication (phone and email)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223829</th>\n",
              "      <td>759817</td>\n",
              "      <td>communication</td>\n",
              "      <td>communication</td>\n",
              "      <td>Calling/Applying</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>224556</th>\n",
              "      <td>762531</td>\n",
              "      <td>communication</td>\n",
              "      <td>communication</td>\n",
              "      <td>Communication</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>238581</th>\n",
              "      <td>818822</td>\n",
              "      <td>communication</td>\n",
              "      <td>communication</td>\n",
              "      <td>Email/Phone Communication</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245411</th>\n",
              "      <td>848577</td>\n",
              "      <td>communication</td>\n",
              "      <td>soft skills</td>\n",
              "      <td>Communication (Phone/Face-to-Face)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>247267</th>\n",
              "      <td>857407</td>\n",
              "      <td>communication</td>\n",
              "      <td>healthcare</td>\n",
              "      <td>Communication (Speech and Hearing)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>76 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         index          skill       category  \\\n",
              "695       2229  communication  communication   \n",
              "1292      4059  communication     healthcare   \n",
              "4228     12919  communication  communication   \n",
              "5528     16927  communication  communication   \n",
              "6311     19452  communication  communication   \n",
              "...        ...            ...            ...   \n",
              "223829  759817  communication  communication   \n",
              "224556  762531  communication  communication   \n",
              "238581  818822  communication  communication   \n",
              "245411  848577  communication    soft skills   \n",
              "247267  857407  communication     healthcare   \n",
              "\n",
              "                           normalized_name  \n",
              "695     Third-Party Provider Communication  \n",
              "1292        Communication (Including SBAR)  \n",
              "4228                Friendly Communication  \n",
              "5528         radio/telephone communication  \n",
              "6311       communication (phone and email)  \n",
              "...                                    ...  \n",
              "223829                    Calling/Applying  \n",
              "224556                       Communication  \n",
              "238581           Email/Phone Communication  \n",
              "245411  Communication (Phone/Face-to-Face)  \n",
              "247267  Communication (Speech and Hearing)  \n",
              "\n",
              "[76 rows x 4 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# we can not use normalized name instead of skill, because it is ambiguous, e.g. communication points to different normalized names\n",
        "skill_nodes.loc[skill_nodes.skill=='communication']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "GIlL1tPh9udW"
      },
      "outputs": [],
      "source": [
        "skill_nodes.drop_duplicates(subset='skill', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "zPzgTNR79udW"
      },
      "outputs": [],
      "source": [
        "\n",
        "skill_job_edges = pd.read_csv(colab_path+'neo4jgraph/tfidf_skill_job_edge.csv')\n",
        "#skill_job_edges = skill_job_edges.loc[skill_job_edges.scaled_tfidf>8]\n",
        "# only use edges where we have the skill and job for from the other files\n",
        "skill_job_edges = skill_job_edges.loc[skill_job_edges['skill'].isin(skill_nodes['skill'])]\n",
        "skill_job_edges = skill_job_edges.loc[skill_job_edges['alt_title'].isin(job_nodes.index)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "mVB9kvu49udX",
        "outputId": "2a450d03-6d16-45b6-a6f0-c213e66970c3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alt_title</th>\n",
              "      <th>skill</th>\n",
              "      <th>scaled_tfidf</th>\n",
              "      <th>n_jobdesc_used</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>55010</td>\n",
              "      <td>design</td>\n",
              "      <td>9.887307</td>\n",
              "      <td>240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>55010</td>\n",
              "      <td>cg</td>\n",
              "      <td>8.744163</td>\n",
              "      <td>240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>55010</td>\n",
              "      <td>visual effects</td>\n",
              "      <td>6.299518</td>\n",
              "      <td>240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>55010</td>\n",
              "      <td>software</td>\n",
              "      <td>5.288013</td>\n",
              "      <td>240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>55010</td>\n",
              "      <td>unity</td>\n",
              "      <td>5.278638</td>\n",
              "      <td>240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7926039</th>\n",
              "      <td>15285</td>\n",
              "      <td>analysis</td>\n",
              "      <td>6.147100</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7926040</th>\n",
              "      <td>15285</td>\n",
              "      <td>software</td>\n",
              "      <td>6.013723</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7926041</th>\n",
              "      <td>15285</td>\n",
              "      <td>engineering</td>\n",
              "      <td>5.864380</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7926050</th>\n",
              "      <td>15285</td>\n",
              "      <td>development</td>\n",
              "      <td>4.434249</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7926055</th>\n",
              "      <td>15285</td>\n",
              "      <td>training</td>\n",
              "      <td>3.974054</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4069186 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         alt_title           skill  scaled_tfidf  n_jobdesc_used\n",
              "1            55010          design      9.887307             240\n",
              "5            55010              cg      8.744163             240\n",
              "10           55010  visual effects      6.299518             240\n",
              "11           55010        software      5.288013             240\n",
              "12           55010           unity      5.278638             240\n",
              "...            ...             ...           ...             ...\n",
              "7926039      15285        analysis      6.147100               1\n",
              "7926040      15285        software      6.013723               1\n",
              "7926041      15285     engineering      5.864380               1\n",
              "7926050      15285     development      4.434249               1\n",
              "7926055      15285        training      3.974054               1\n",
              "\n",
              "[4069186 rows x 4 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "skill_job_edges"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "gppNxu5m9udX"
      },
      "outputs": [],
      "source": [
        "#for each alt title select the first 20 skill_job edges, ordered by tfidf\n",
        "skill_job_edges = skill_job_edges.groupby('alt_title').apply(lambda group: group.nlargest(20,'scaled_tfidf')).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "0twUk4Pf9udX",
        "outputId": "4691295a-49a9-4160-db66-7acee5c176fa"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alt_title</th>\n",
              "      <th>skill</th>\n",
              "      <th>scaled_tfidf</th>\n",
              "      <th>n_jobdesc_used</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7</td>\n",
              "      <td>development</td>\n",
              "      <td>35.545516</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7</td>\n",
              "      <td>physical work environment</td>\n",
              "      <td>14.444801</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7</td>\n",
              "      <td>microsoft teams</td>\n",
              "      <td>13.682348</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7</td>\n",
              "      <td>assessment process</td>\n",
              "      <td>11.763047</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>limited supervision</td>\n",
              "      <td>10.088181</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>282867</th>\n",
              "      <td>55652</td>\n",
              "      <td>communications</td>\n",
              "      <td>6.736089</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>282868</th>\n",
              "      <td>55652</td>\n",
              "      <td>systems</td>\n",
              "      <td>6.629133</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>282869</th>\n",
              "      <td>55652</td>\n",
              "      <td>driving</td>\n",
              "      <td>6.265465</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>282870</th>\n",
              "      <td>55652</td>\n",
              "      <td>highly specialized</td>\n",
              "      <td>5.501605</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>282871</th>\n",
              "      <td>55652</td>\n",
              "      <td>leadership</td>\n",
              "      <td>5.408052</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>282872 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        alt_title                      skill  scaled_tfidf  n_jobdesc_used\n",
              "0               7                development     35.545516               1\n",
              "1               7  physical work environment     14.444801               1\n",
              "2               7            microsoft teams     13.682348               1\n",
              "3               7         assessment process     11.763047               1\n",
              "4               7        limited supervision     10.088181               1\n",
              "...           ...                        ...           ...             ...\n",
              "282867      55652             communications      6.736089               7\n",
              "282868      55652                    systems      6.629133               7\n",
              "282869      55652                    driving      6.265465               7\n",
              "282870      55652         highly specialized      5.501605               7\n",
              "282871      55652                 leadership      5.408052               7\n",
              "\n",
              "[282872 rows x 4 columns]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "skill_job_edges"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "pCzFw-fn9udY"
      },
      "outputs": [],
      "source": [
        "skillmapping ={}\n",
        "for i,skill in enumerate(skill_nodes.skill.unique()):\n",
        "    skillmapping[skill] =i\n",
        "\n",
        "jobmapping ={}\n",
        "for i,index in enumerate(job_nodes['index'].unique()):\n",
        "    jobmapping[index] =i\n",
        "\n",
        "inverted_skillmapping = {v:k for k,v in skillmapping.items()}\n",
        "inverted_jobmapping = {v:k for k,v in jobmapping.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "BHirmQzn9udY"
      },
      "outputs": [],
      "source": [
        "skill_job_edges['skill_dst'] = skill_job_edges['skill'].apply(lambda x:skillmapping[x])\n",
        "skill_job_edges['job_src'] = skill_job_edges['alt_title'].apply(lambda x:jobmapping[x])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "8Yfi1fRd9udY"
      },
      "outputs": [],
      "source": [
        "onet_alttitles = pd.read_csv(colab_path+'neo4jgraph/onet_alt_titles_unique.csv')\n",
        "del onet_alttitles['Unnamed: 0']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "8FgE8nyo9udY"
      },
      "outputs": [],
      "source": [
        "onet_alttitle_str_mapping = {}\n",
        "for i,row in onet_alttitles.iterrows():\n",
        "    onet_alttitle_str_mapping[row['index']] = row['Alternate Title']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "E1_J7gV59udY"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "1yTzdBoU9udZ"
      },
      "outputs": [],
      "source": [
        "# create alttitle sbert embeddings to get pca dim\n",
        "\n",
        "alttitle_sbert_embeddings = embedder.encode(list(onet_alttitle_str_mapping.values()), convert_to_tensor=False)\n",
        "#alttitle_sbert_indices = [k for k,v in temp]\n",
        "#corpus_embeddings = util.normalize_embeddings(corpus_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "de19o3FI9udZ",
        "outputId": "88b82685-cf22-4ec1-903a-5d2b72bda947"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.99999994"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "v = alttitle_sbert_embeddings[0]\n",
        "np.matmul(v.T,v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "kQsE8smF9udZ"
      },
      "outputs": [],
      "source": [
        "skill_sbert_embeddings = embedder.encode(list(skillmapping.keys()), convert_to_tensor=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "yAT18fhw9udZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.decomposition import PCA\n",
        "X = np.concatenate([alttitle_sbert_embeddings,skill_sbert_embeddings])\n",
        "\n",
        "# print('Original:',X.shape[1])\n",
        "# for variance_retained in [0.99,0.95,0.9,0.8,0.75,0.7]:\n",
        "#     pca = PCA(n_components=variance_retained)\n",
        "#     pca.fit(X)\n",
        "#     n_components_retained = pca.n_components_\n",
        "#     print(n_components_retained,' components retained', variance_retained, ' variance retained')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "vK1p6Rf-9udZ"
      },
      "outputs": [],
      "source": [
        "# choose 128\n",
        "pca = PCA(n_components=128)\n",
        "pca.fit(X)\n",
        "\n",
        "skill_sbert_embeddings = pca.transform(embedder.encode(skill_nodes['skill'].tolist(), convert_to_numpy=True))\n",
        "job_sbert_embeddings = pca.transform(embedder.encode(job_nodes['Alternate Title'].tolist(), convert_to_numpy=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "_vD1fRkf9udZ"
      },
      "outputs": [],
      "source": [
        "# add job-job edges, dataset see https://www.onetcenter.org/dictionary/26.3/excel/related_occupations.html\n",
        "job_job_edges = pd.read_csv(colab_path+'neo4jgraph/onet_related_occupations.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "hMsTH1Sx9udZ"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>O*NET-SOC Code</th>\n",
              "      <th>Title</th>\n",
              "      <th>Related O*NET-SOC Code</th>\n",
              "      <th>Related Title</th>\n",
              "      <th>Relatedness Tier</th>\n",
              "      <th>index_x</th>\n",
              "      <th>index_y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11-1011.00</td>\n",
              "      <td>Chief Executives</td>\n",
              "      <td>11-1021.00</td>\n",
              "      <td>General and Operations Managers</td>\n",
              "      <td>Primary-Short</td>\n",
              "      <td>54641</td>\n",
              "      <td>54643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11-1031.00</td>\n",
              "      <td>Legislators</td>\n",
              "      <td>11-1021.00</td>\n",
              "      <td>General and Operations Managers</td>\n",
              "      <td>Supplemental</td>\n",
              "      <td>54644</td>\n",
              "      <td>54643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11-2021.00</td>\n",
              "      <td>Marketing Managers</td>\n",
              "      <td>11-1021.00</td>\n",
              "      <td>General and Operations Managers</td>\n",
              "      <td>Supplemental</td>\n",
              "      <td>54646</td>\n",
              "      <td>54643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11-2022.00</td>\n",
              "      <td>Sales Managers</td>\n",
              "      <td>11-1021.00</td>\n",
              "      <td>General and Operations Managers</td>\n",
              "      <td>Primary-Long</td>\n",
              "      <td>54647</td>\n",
              "      <td>54643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11-2032.00</td>\n",
              "      <td>Public Relations Managers</td>\n",
              "      <td>11-1021.00</td>\n",
              "      <td>General and Operations Managers</td>\n",
              "      <td>Primary-Long</td>\n",
              "      <td>54648</td>\n",
              "      <td>54643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18379</th>\n",
              "      <td>53-2022.00</td>\n",
              "      <td>Airfield Operations Specialists</td>\n",
              "      <td>53-2011.00</td>\n",
              "      <td>Airline Pilots, Copilots, and Flight Engineers</td>\n",
              "      <td>Primary-Short</td>\n",
              "      <td>55590</td>\n",
              "      <td>55587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18380</th>\n",
              "      <td>53-2031.00</td>\n",
              "      <td>Flight Attendants</td>\n",
              "      <td>53-2011.00</td>\n",
              "      <td>Airline Pilots, Copilots, and Flight Engineers</td>\n",
              "      <td>Supplemental</td>\n",
              "      <td>55591</td>\n",
              "      <td>55587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18381</th>\n",
              "      <td>53-5021.00</td>\n",
              "      <td>Captains, Mates, and Pilots of Water Vessels</td>\n",
              "      <td>53-2011.00</td>\n",
              "      <td>Airline Pilots, Copilots, and Flight Engineers</td>\n",
              "      <td>Primary-Short</td>\n",
              "      <td>55608</td>\n",
              "      <td>55587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18382</th>\n",
              "      <td>53-5022.00</td>\n",
              "      <td>Motorboat Operators</td>\n",
              "      <td>53-2011.00</td>\n",
              "      <td>Airline Pilots, Copilots, and Flight Engineers</td>\n",
              "      <td>Supplemental</td>\n",
              "      <td>55609</td>\n",
              "      <td>55587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18383</th>\n",
              "      <td>53-6032.00</td>\n",
              "      <td>Aircraft Service Attendants</td>\n",
              "      <td>53-2011.00</td>\n",
              "      <td>Airline Pilots, Copilots, and Flight Engineers</td>\n",
              "      <td>Supplemental</td>\n",
              "      <td>55614</td>\n",
              "      <td>55587</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>18384 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      O*NET-SOC Code                                         Title  \\\n",
              "0         11-1011.00                              Chief Executives   \n",
              "1         11-1031.00                                   Legislators   \n",
              "2         11-2021.00                            Marketing Managers   \n",
              "3         11-2022.00                                Sales Managers   \n",
              "4         11-2032.00                     Public Relations Managers   \n",
              "...              ...                                           ...   \n",
              "18379     53-2022.00               Airfield Operations Specialists   \n",
              "18380     53-2031.00                             Flight Attendants   \n",
              "18381     53-5021.00  Captains, Mates, and Pilots of Water Vessels   \n",
              "18382     53-5022.00                           Motorboat Operators   \n",
              "18383     53-6032.00                   Aircraft Service Attendants   \n",
              "\n",
              "      Related O*NET-SOC Code                                   Related Title  \\\n",
              "0                 11-1021.00                 General and Operations Managers   \n",
              "1                 11-1021.00                 General and Operations Managers   \n",
              "2                 11-1021.00                 General and Operations Managers   \n",
              "3                 11-1021.00                 General and Operations Managers   \n",
              "4                 11-1021.00                 General and Operations Managers   \n",
              "...                      ...                                             ...   \n",
              "18379             53-2011.00  Airline Pilots, Copilots, and Flight Engineers   \n",
              "18380             53-2011.00  Airline Pilots, Copilots, and Flight Engineers   \n",
              "18381             53-2011.00  Airline Pilots, Copilots, and Flight Engineers   \n",
              "18382             53-2011.00  Airline Pilots, Copilots, and Flight Engineers   \n",
              "18383             53-2011.00  Airline Pilots, Copilots, and Flight Engineers   \n",
              "\n",
              "      Relatedness Tier  index_x  index_y  \n",
              "0        Primary-Short    54641    54643  \n",
              "1         Supplemental    54644    54643  \n",
              "2         Supplemental    54646    54643  \n",
              "3         Primary-Long    54647    54643  \n",
              "4         Primary-Long    54648    54643  \n",
              "...                ...      ...      ...  \n",
              "18379    Primary-Short    55590    55587  \n",
              "18380     Supplemental    55591    55587  \n",
              "18381    Primary-Short    55608    55587  \n",
              "18382     Supplemental    55609    55587  \n",
              "18383     Supplemental    55614    55587  \n",
              "\n",
              "[18384 rows x 7 columns]"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "job_job_edges"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "p1lR651a9uda"
      },
      "outputs": [],
      "source": [
        "job_job_edges['job_src'] = job_job_edges['index_x'].apply(lambda x: jobmapping[x])\n",
        "job_job_edges['job_dst'] = job_job_edges['index_y'].apply(lambda x: jobmapping[x])\n",
        "relatedness_weight = {\n",
        "    'Supplemental':1,\n",
        "    'Primary-Long':2,\n",
        "    'Primary-Short':4\n",
        "}\n",
        "job_job_edges['relatedness_weight'] = job_job_edges['Relatedness Tier'].apply(lambda x: relatedness_weight[x])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "T1Wc7CIL9uda"
      },
      "outputs": [],
      "source": [
        "skill_skill_edges = pd.read_csv(colab_path+'neo4jgraph/skill_skill_edges.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "8qOHTGfL9uda"
      },
      "outputs": [],
      "source": [
        "#filter out potentially bad skills (which are not in our original skillmapping)\n",
        "skill_skill_edges = skill_skill_edges.loc[(skill_skill_edges.skill.isin(list(skillmapping.keys()))) & (skill_skill_edges.related_skill.isin(list(skillmapping.keys())))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "jQhTLGTV9uda"
      },
      "outputs": [],
      "source": [
        "skill_skill_edges['skill_src'] = skill_skill_edges['skill'].apply(lambda x: skillmapping[x])\n",
        "skill_skill_edges['skill_dst'] = skill_skill_edges['related_skill'].apply(lambda x: skillmapping[x])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DahEKZBB9uda"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "La85Q2M59uda"
      },
      "outputs": [],
      "source": [
        "data = HeteroData()\n",
        "data['Skill'].x = torch.tensor(skill_sbert_embeddings)\n",
        "data['Job'].x = torch.tensor(job_sbert_embeddings)\n",
        "\n",
        "data['Job','REQUIRES','Skill'].edge_index = torch.tensor(skill_job_edges[['job_src','skill_dst']].to_numpy().T)\n",
        "data['Skill','IS_SIMILAR_SKILL','Skill'].edge_index = torch.tensor(skill_skill_edges[['skill_src','skill_dst']].to_numpy().T)\n",
        "data['Job','IS_SIMILAR_JOB','Job'].edge_index = torch.tensor(job_job_edges[['job_src','job_dst']].to_numpy().T)\n",
        "\n",
        "\n",
        "data['Job','REQUIRES','Skill'].edge_weight = torch.tensor(skill_job_edges['scaled_tfidf'].to_numpy()).to(torch.float)\n",
        "data['Skill','IS_SIMILAR_SKILL','Skill'].edge_weight = torch.tensor(skill_skill_edges['cosine_sim_score'].to_numpy()).to(torch.float)\n",
        "data['Job','IS_SIMILAR_JOB','Job'].edge_weight = torch.tensor(job_job_edges['relatedness_weight'].to_numpy()).to(torch.float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "M7tf8glw9uda"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "GZAF_riX9uda"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(True, False)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.has_isolated_nodes(), data.has_self_loops()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "u5MjvjO09uda"
      },
      "outputs": [],
      "source": [
        "#data = data.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "aMAfCM0u9uda"
      },
      "outputs": [],
      "source": [
        "import torch_geometric.transforms as T\n",
        "\n",
        "transform = T.Compose([\n",
        "       T.RemoveIsolatedNodes(),\n",
        "       T.RemoveDuplicatedEdges(),\n",
        "       T.ToUndirected(merge=False) # don't merge reversed edges into the original edge type\n",
        "])\n",
        "\n",
        "data = transform(data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "Yk4D68v69udb"
      },
      "outputs": [],
      "source": [
        "transform = T.RandomLinkSplit(\n",
        "    is_undirected=True,\n",
        "    edge_types=[\n",
        "        ('Job', 'REQUIRES', 'Skill'),\n",
        "        ('Skill', 'IS_SIMILAR_SKILL', 'Skill'),\n",
        "        ('Job', 'IS_SIMILAR_JOB', 'Job')\n",
        "        ],\n",
        "    # rev_edge_types=[\n",
        "    #     ('Skill', 'rev_REQUIRES', 'Job'),\n",
        "    #     ('Skill', 'rev_IS_SIMILAR_SKILL', 'Skill'),\n",
        "    #     ('Job', 'rev_IS_SIMILAR_JOB', 'Job')\n",
        "    # ],\n",
        "    num_val=0.001,\n",
        "    num_test=0.001,\n",
        "    add_negative_train_samples=False, # only adds neg samples for val and test, neg train are added by LinkNeighborLoader. This means for each train batch, negs. are different, for val and train they stay the same\n",
        "    neg_sampling_ratio=1.0,\n",
        "    disjoint_train_ratio=0 #  training edges are shared for message passing and supervision\n",
        "\n",
        "    )\n",
        "train_data, val_data, test_data = transform(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "zG7w63019udb"
      },
      "outputs": [],
      "source": [
        "# from torch_geometric.loader import NeighborLoader\n",
        "\n",
        "# train_loader = NeighborLoader(\n",
        "#     train_data,\n",
        "#     # Sample 15 neighbors for each node and each edge type for 2 iterations:\n",
        "#     num_neighbors={\n",
        "#          ('Job', 'REQUIRES', 'Skill'):[1000,10], # [add x neighbors, add y neighbors for every x neighbor]\n",
        "#          ('Skill', 'rev_REQUIRES', 'Job'):[10,0],\n",
        "#         ('Skill', 'IS_SIMILAR_SKILL', 'Skill'):[10,10],\n",
        "#         ('Skill', 'rev_IS_SIMILAR_SKILL', 'Skill'):[0,0],\n",
        "#         ('Job', 'IS_SIMILAR_JOB', 'Job'):[0,20], # can't sample job-job in first iteration\n",
        "#         ('Job', 'rev_IS_SIMILAR_JOB', 'Job'):[0,20],\n",
        "#          },\n",
        "#     # num_neighbors = [10,10],\n",
        "#     # Use a batch size of 128 for sampling training nodes of type \"paper\":\n",
        "#     batch_size=200,\n",
        "#     input_nodes='Job', #if not set, we consider all nodes\n",
        "#     shuffle=True,\n",
        "#     drop_last=True,\n",
        "#     num_workers=4,\n",
        "#     directed=True,  # contains only edges which are followed randomly, False: contains full node induced subgraph\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "1n7iu1YK9udb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "create mini-batches for ('Job', 'REQUIRES', 'Skill')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/amos/mambaforge/envs/pyg/lib/python3.11/site-packages/torch_geometric/sampler/neighbor_sampler.py:60: UserWarning: Using 'NeighborSampler' without a 'pyg-lib' installation is deprecated and will be removed soon. Please install 'pyg-lib' for accelerated neighborhood sampling\n",
            "  warnings.warn(f\"Using '{self.__class__.__name__}' without a \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "create mini-batches for ('Job', 'REQUIRES', 'Skill')\n",
            "create mini-batches for ('Job', 'REQUIRES', 'Skill')\n",
            "create mini-batches for ('Skill', 'IS_SIMILAR_SKILL', 'Skill')\n",
            "create mini-batches for ('Skill', 'IS_SIMILAR_SKILL', 'Skill')\n",
            "create mini-batches for ('Skill', 'IS_SIMILAR_SKILL', 'Skill')\n",
            "create mini-batches for ('Job', 'IS_SIMILAR_JOB', 'Job')\n",
            "create mini-batches for ('Job', 'IS_SIMILAR_JOB', 'Job')\n",
            "create mini-batches for ('Job', 'IS_SIMILAR_JOB', 'Job')\n",
            "create mini-batches for ('Skill', 'rev_REQUIRES', 'Job')\n",
            "create mini-batches for ('Skill', 'rev_REQUIRES', 'Job')\n",
            "create mini-batches for ('Skill', 'rev_REQUIRES', 'Job')\n",
            "create mini-batches for ('Skill', 'rev_IS_SIMILAR_SKILL', 'Skill')\n",
            "create mini-batches for ('Skill', 'rev_IS_SIMILAR_SKILL', 'Skill')\n",
            "create mini-batches for ('Skill', 'rev_IS_SIMILAR_SKILL', 'Skill')\n",
            "create mini-batches for ('Job', 'rev_IS_SIMILAR_JOB', 'Job')\n",
            "create mini-batches for ('Job', 'rev_IS_SIMILAR_JOB', 'Job')\n",
            "create mini-batches for ('Job', 'rev_IS_SIMILAR_JOB', 'Job')\n"
          ]
        }
      ],
      "source": [
        "from itertools import cycle\n",
        "from typing import Tuple, List, Union\n",
        "from torch_geometric.loader import LinkNeighborLoader\n",
        "from torch_geometric.sampler import NegativeSampling\n",
        "\n",
        "def create_loader(data:HeteroData, edge:Tuple[str,str,str], num_neighbors:List[int], batch_size:int, is_training:bool)->LinkNeighborLoader:\n",
        "\n",
        "    print('create mini-batches for', edge)\n",
        "\n",
        "    negative_sampling = NegativeSampling(\n",
        "        mode='binary',\n",
        "        amount=20  # ratio, like Graphsage\n",
        "        #weight=  # \"Probabilities\" of nodes to be sampled: Node degree follows power law distribution\n",
        "        )\n",
        "\n",
        "    loader = LinkNeighborLoader(\n",
        "        data,\n",
        "        num_neighbors={\n",
        "            ('Job', 'REQUIRES', 'Skill'):num_neighbors,\n",
        "            ('Skill', 'rev_REQUIRES', 'Job'):num_neighbors,\n",
        "            ('Skill', 'IS_SIMILAR_SKILL', 'Skill'):num_neighbors, # In this example, index 0 will never be used, since neighboring edge to a job node can't be a skill-skill edge\n",
        "            ('Skill', 'rev_IS_SIMILAR_SKILL', 'Skill'):num_neighbors,\n",
        "            ('Job', 'IS_SIMILAR_JOB', 'Job'):num_neighbors,\n",
        "            ('Job', 'rev_IS_SIMILAR_JOB', 'Job'):num_neighbors,\n",
        "        },\n",
        "        edge_label_index=(edge, None), # None means all edges are considered\n",
        "        #edge_label =train_data[edge].edge_label,\n",
        "        neg_sampling=negative_sampling, # adds negative samples\n",
        "        batch_size=batch_size,\n",
        "        shuffle=is_training,\n",
        "        #drop_last=True,\n",
        "        num_workers=4,\n",
        "        directed=True,  # contains only edges which are followed, False: contains full node induced subgraph\n",
        "        #disjoint=True # sampled seed node creates its own, disjoint from the rest, subgraph, will add \"batch vector\" to loader output\n",
        "    )\n",
        "\n",
        "    return loader\n",
        "\n",
        "\n",
        "batch_size=256\n",
        "num_neighbors = [5,2]\n",
        "\n",
        "train_loaders, val_loaders, test_loaders = [], [], []\n",
        "for edge_type in train_data.edge_types:\n",
        "    # create mini-batches for each edge type, because LinkNeighborLoader only allows one target edge type\n",
        "\n",
        "    datasets = {\n",
        "        'train':train_data,\n",
        "        'val': val_data,\n",
        "        'test': test_data\n",
        "    }\n",
        "    loader = create_loader(\n",
        "        data=train_data,\n",
        "        edge=edge_type,\n",
        "        num_neighbors=num_neighbors,\n",
        "        batch_size=batch_size,\n",
        "        is_training=True\n",
        "    )\n",
        "    train_loaders.append(loader)\n",
        "\n",
        "    loader = create_loader(\n",
        "        data=val_data,\n",
        "        edge=edge_type,\n",
        "        num_neighbors=num_neighbors,\n",
        "        batch_size=batch_size,\n",
        "        is_training=False\n",
        "    )\n",
        "\n",
        "    val_loaders.append(loader)\n",
        "\n",
        "    loader = create_loader(\n",
        "        data=test_data,\n",
        "        edge=edge_type,\n",
        "        num_neighbors=num_neighbors,\n",
        "        batch_size=batch_size,\n",
        "        is_training=False\n",
        "    )\n",
        "\n",
        "    test_loaders.append(loader)\n",
        "\n",
        "\n",
        "def combined_iterator(iterables):\n",
        "    iterators = [cycle(it) for it in iterables]\n",
        "\n",
        "    while True:\n",
        "        yield tuple(next(it) for it in iterators)\n",
        "\n",
        "train_iterator = combined_iterator(train_loaders)\n",
        "val_iterator = combined_iterator(val_loaders)\n",
        "test_iterator = combined_iterator(test_loaders)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "jnWJyyeC9udb"
      },
      "outputs": [],
      "source": [
        "# helpful article\n",
        "# https://medium.com/stanford-cs224w/a-tour-of-pygs-data-loaders-9f2384e48f8f\n",
        "\n",
        "# some info\n",
        "\n",
        "# HeteroData(\n",
        "#   Job={\n",
        "#     x=[9222, 128], # node features\n",
        "#     n_id=[9222] # the ids of the nodes in the original train_data set\n",
        "#   },\n",
        "#   (Job, REQUIRES, Skill)={\n",
        "#     edge_index=[2, 14498], # sampled edges\n",
        "#     edge_attr=[14498, 1],  # edge attributes of sampled edges\n",
        "#     edge_label=[509170], # 1 if it is a true edge, 0 if it is a false\n",
        "#     edge_label_index=[2, 509170], # all edges?\n",
        "#     e_id=[14498] # edge ids of edges in the original train_data set\n",
        "\n",
        "\n",
        "\n",
        "# if batchsize is 16 for the edge and we have neg_sampling=binary, we will have\n",
        "# this many jobs:\n",
        "#  Job={\n",
        "#     x=[64, 128],\n",
        "#     n_id=[64]\n",
        "#   },\n",
        "# since we sample a negative and a positive edge each, and each edge has 2 Job nodes (if our target is the job nodes)\n",
        "\n",
        "# LinkNeighborloader will sample negative edges for the target edges only, as we expect it\n",
        "# so for the \"neighbor\"-edges we get only positive ones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "dI4AQ3kq9udc"
      },
      "outputs": [],
      "source": [
        "from typing import Tuple, Union\n",
        "from torch import Tensor\n",
        "from torch_geometric.nn import to_hetero, HeteroDictLinear, Linear\n",
        "from torch_geometric.nn.conv import GraphConv, SAGEConv, SimpleConv\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.typing import Adj, OptPairTensor, OptTensor, Size\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# PyG does not implement the exact max pooling aggregation as in the GraphSage paper\n",
        "# with GraphConvWithPool we manually extend it by adding a linear layer on x before .propagate\n",
        "# as our activation function is monotonically increasing, this modification corresponds to the max pooling aggregation\n",
        "\n",
        "class GraphConvWithPool(GraphConv):\n",
        "    def __init__(self, in_channels, out_channels: int, aggr: str = 'add', bias: bool = True, **kwargs):\n",
        "        super().__init__(in_channels, out_channels, aggr, bias, **kwargs)\n",
        "        self.linear = torch.nn.Linear(in_channels, in_channels, bias=False)\n",
        "\n",
        "    def forward(self, x: Union[Tensor, OptPairTensor], edge_index: Adj,\n",
        "                edge_weight: OptTensor = None, size: Size = None) -> Tensor:\n",
        "\n",
        "        if isinstance(x, Tensor):\n",
        "            x: OptPairTensor = (x, x)\n",
        "\n",
        "        x = self.linear(x) # added this\n",
        "\n",
        "        out = self.propagate(edge_index, x=x, edge_weight=edge_weight,\n",
        "                             size=size)\n",
        "        out = self.lin_rel(out)\n",
        "\n",
        "        x_r = x[1]\n",
        "        if x_r is not None:\n",
        "            out = out + self.lin_root(x_r)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "class WeightedSkillSage(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels, out_channels, aggregator='max'):\n",
        "        super().__init__()\n",
        "        #self.linear1 = Linear(-1,-1)\n",
        "        #self.conv1 = SimpleConv(aggr='sum')\n",
        "        self.conv1 = GraphConv(in_channels=-1, out_channels=hidden_channels)\n",
        "        self.conv2 = GraphConv(in_channels=hidden_channels, out_channels=hidden_channels)\n",
        "        self.linear3 = Linear(hidden_channels,out_channels)\n",
        "\n",
        "    def forward(self, x: HeteroData, edge_index, edge_weight):\n",
        "        x = self.conv1(x, edge_index, edge_weight=edge_weight)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index, edge_weight=edge_weight)\n",
        "        x = F.relu(x)\n",
        "        x = self.linear3(x)\n",
        "        return x\n",
        "\n",
        "model = WeightedSkillSage(hidden_channels=64, out_channels=64)\n",
        "model = to_hetero(model, train_data.metadata(), aggr='sum')\n",
        "model = model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "TQbpUFGwF-Zx"
      },
      "outputs": [],
      "source": [
        "from torcheval.metrics import BinaryAccuracy, BinaryPrecision, BinaryRecall, BinaryF1Score, BinaryAUPRC\n",
        "\n",
        "class GNNTrainer(Trainer):\n",
        "    def __init__(self, model, criterion, optimizer, device):\n",
        "        super().__init__(model, criterion, optimizer, device, metrics=['f1','accuracy','precision','recall', 'aucpr'])\n",
        "\n",
        "    def get_supervision_edge_type(self, heterodata):\n",
        "        for edge_type in heterodata.edge_types:\n",
        "            if 'input_id' in heterodata[edge_type].keys():\n",
        "                return edge_type\n",
        "            \n",
        "    def calculate_metrics(self, split_name, y_hat, y):\n",
        "        y = y.to(torch.int)\n",
        "        acc, prec, rec, f1, aucpr = BinaryAccuracy(threshold=0.5).update(y_hat, y).compute().item(), BinaryPrecision(threshold=0.5).update(y_hat, y).compute().item(), BinaryRecall(threshold=0.5).update(y_hat, y).compute().item(), BinaryF1Score(threshold=0.5).update(y_hat, y).compute().item(), BinaryAUPRC().update(y_hat, y).compute().item()\n",
        "        self.metrics_history[split_name]['accuracy'].append(acc)\n",
        "        self.metrics_history[split_name]['precision'].append(prec)\n",
        "        self.metrics_history[split_name]['recall'].append(rec)\n",
        "        self.metrics_history[split_name]['f1'].append(f1)\n",
        "        self.metrics_history[split_name]['aucpr'].append(aucpr)\n",
        "        print(f'{split_name}: F1: {f1}, AUC-PR: {aucpr}, (acc: {acc}, prec: {prec}, rec: {rec})')\n",
        "            \n",
        "    def train(self, train_iterator, val_iterator, start_epoch, n_epochs, save_interval, save_path):\n",
        "        self.free_memory()\n",
        "        \n",
        "        self.model.train()\n",
        "        for epoch in range(start_epoch, start_epoch+n_epochs):\n",
        "            print(f'=============== Epoch {epoch} ===============')\n",
        "            for batch_idx, edge_batches in enumerate(train_iterator):\n",
        "                self.optimizer.zero_grad()\n",
        "                minibatch_loss = 0\n",
        "                \n",
        "                y_hat, y = [], []\n",
        "                for i,batch in enumerate(edge_batches):  # each batch here is one edge type, since we want to learn for all edge types\n",
        "                    print(i,end='\\r')\n",
        "                    batch = batch.to(self.device)\n",
        "                    hetero_out = model(batch.x_dict, batch.edge_index_dict, batch.edge_weight_dict)  # get model output\n",
        "\n",
        "                    # evaluate, calculate cosine sim and compute cross-entropy loss\n",
        "                    supervision_edge_type = self.get_supervision_edge_type(batch)\n",
        "                    src_type, dst_type = supervision_edge_type[0], supervision_edge_type[2]\n",
        "                    edge_label = batch[supervision_edge_type].edge_label\n",
        "                    edge_label_index = batch[supervision_edge_type].edge_label_index\n",
        "                    src_node_embeddings = hetero_out[src_type][edge_label_index[0]]\n",
        "                    dst_node_embeddings = hetero_out[dst_type][edge_label_index[1]]\n",
        "                    logits = F.cosine_similarity(src_node_embeddings, dst_node_embeddings, dim=-1)\n",
        "                    loss = self.criterion(logits, edge_label)\n",
        "                    minibatch_loss += loss\n",
        "                    \n",
        "                    y_hat.append(torch.sigmoid(logits))\n",
        "                    y.append(edge_label)\n",
        "\n",
        "                minibatch_loss.backward()\n",
        "                self.optimizer.step()\n",
        "                \n",
        "                # save loss and metrics\n",
        "                self.metrics_history['train']['minibatch'].append(epoch+batch_idx)\n",
        "                self.metrics_history['train']['epoch'].append(epoch+batch_idx)\n",
        "                self.metrics_history['train']['loss'].append(minibatch_loss.item())\n",
        "                \n",
        "                y_hat = torch.cat(y_hat)\n",
        "                y = torch.cat(y)\n",
        "                print(\"aa\")\n",
        "                self.calculate_metrics('train', y_hat, y)\n",
        "                \n",
        "                if batch_idx % save_interval == 0:\n",
        "                    print('bb')\n",
        "                    self.validate(val_iterator, epoch)\n",
        "                    self.save_checkpoint(batch_idx, save_path)\n",
        "                    \n",
        "                print(f'Mini-Batch {batch_idx}, Loss: {loss}')\n",
        "                \n",
        "    def validate(self, val_iterator, epoch):\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            y_hat, y = [], []\n",
        "            for edge_batches in tqdm(enumerate(val_iterator)):\n",
        "                \n",
        "                for batch in edge_batches:  # each batch here is one edge type, since we want to learn for all edge types\n",
        "                    batch = batch.to(self.device)\n",
        "                    hetero_out = model(batch.x_dict, batch.edge_index_dict, batch.edge_weight_dict)  # get model output\n",
        "\n",
        "                    # evaluate, calculate cosine sim and compute cross-entropy loss\n",
        "                    supervision_edge_type = self.get_supervision_edge_type(batch)\n",
        "                    src_type, dst_type = supervision_edge_type[0], supervision_edge_type[2]\n",
        "                    edge_label = batch[supervision_edge_type].edge_label\n",
        "                    edge_label_index = batch[supervision_edge_type].edge_label_index\n",
        "                    src_node_embeddings = hetero_out[src_type][edge_label_index[0]]\n",
        "                    dst_node_embeddings = hetero_out[dst_type][edge_label_index[1]]\n",
        "                    logits = F.cosine_similarity(src_node_embeddings, dst_node_embeddings, dim=-1)\n",
        "                    \n",
        "                    y_hat.append(torch.sigmoid(logits))\n",
        "                    y.append(edge_label)\n",
        "                \n",
        "                \n",
        "            # save loss and metrics\n",
        "            self.metrics_history['val']['epoch'].append(epoch)\n",
        "                \n",
        "            y_hat = torch.cat(y_hat)\n",
        "            y = torch.cat(y)\n",
        "            self.calculate_metrics('val', y_hat, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "hsOdxQu-FgBD"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32m/home/amos/programming/create_graphds/colab.ipynb Cell 43\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/amos/programming/create_graphds/colab.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m criterion \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/amos/programming/create_graphds/colab.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m trainer \u001b[39m=\u001b[39m GNNTrainer(model, criterion, optimizer, device)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/amos/programming/create_graphds/colab.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain(train_iterator, val_iterator, start_epoch\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, n_epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, save_interval\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, save_path\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m./checkpoints\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/amos/programming/create_graphds/colab.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# trainer.validate(val_dataloader)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/amos/programming/create_graphds/colab.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# trainer.plot_losses()\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/amos/programming/create_graphds/colab.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# trainer.load_checkpoint('./checkpoints/checkpoint_100.pt')\u001b[39;00m\n",
            "\u001b[1;32m/home/amos/programming/create_graphds/colab.ipynb Cell 43\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/amos/programming/create_graphds/colab.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(\u001b[39mself\u001b[39m, train_iterator, val_iterator, start_epoch, n_epochs, save_interval, save_path):\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/amos/programming/create_graphds/colab.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfree_memory()\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/amos/programming/create_graphds/colab.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/amos/programming/create_graphds/colab.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(start_epoch, start_epoch\u001b[39m+\u001b[39mn_epochs):\n",
            "\u001b[1;32m/home/amos/programming/create_graphds/colab.ipynb Cell 43\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/amos/programming/create_graphds/colab.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfree_memory\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/amos/programming/create_graphds/colab.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Clears the GPU cache and triggers garbage collection, to reduce OOMs.\"\"\"\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/amos/programming/create_graphds/colab.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m     torch\u001b[39m.\u001b[39;49mcuda\u001b[39m.\u001b[39;49mempty_cache()\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/amos/programming/create_graphds/colab.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m     gc\u001b[39m.\u001b[39mcollect()\n",
            "File \u001b[0;32m~/mambaforge/envs/pyg/lib/python3.11/site-packages/torch/cuda/memory.py:133\u001b[0m, in \u001b[0;36mempty_cache\u001b[0;34m()\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Releases all unoccupied cached memory currently held by the caching\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[39mallocator so that those can be used in other GPU application and visible in\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[39m`nvidia-smi`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[39m    more details about GPU memory management.\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[39mif\u001b[39;00m is_initialized():\n\u001b[0;32m--> 133\u001b[0m     torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_cuda_emptyCache()\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.000001)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "trainer = GNNTrainer(model, criterion, optimizer, device)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "trainer.train(train_iterator, val_iterator, start_epoch=0, n_epochs=10, save_interval=1, save_path='./checkpoints')\n",
        "# trainer.validate(val_dataloader)\n",
        "# trainer.plot_losses()\n",
        "# trainer.load_checkpoint('./checkpoints/checkpoint_100.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9hY5T9f9udc"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "import os\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
        "# with torch.no_grad():  # Initialize lazy modules.\n",
        "#      out = model(batch.x_dict, batch.edge_index_dict, batch.edge_weight_dict)\n",
        "def get_supervision_edge_type(heterodata):\n",
        "    for edge_type in heterodata.edge_types:\n",
        "        if 'input_id' in heterodata[edge_type].keys():\n",
        "            return edge_type\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.000001)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "model.train()\n",
        "for edge_batches in train_iterator:\n",
        "    minibatch_loss = 0\n",
        "\n",
        "\n",
        "    # each batch here is one edge type, since we want to learn for all edge types\n",
        "    for batch in edge_batches:\n",
        "        batch = batch.to(device)\n",
        "        hetero_out = model(batch.x_dict, batch.edge_index_dict, batch.edge_weight_dict)\n",
        "\n",
        "        supervision_edge_type = get_supervision_edge_type(batch)\n",
        "        src_type, dst_type = supervision_edge_type[0], supervision_edge_type[2]\n",
        "        edge_label = batch[supervision_edge_type].edge_label\n",
        "        edge_label_index = batch[supervision_edge_type].edge_label_index\n",
        "        src_node_embeddings = hetero_out[src_type][edge_label_index[0]]\n",
        "        dst_node_embeddings = hetero_out[dst_type][edge_label_index[1]]\n",
        "        logits = F.cosine_similarity(src_node_embeddings, dst_node_embeddings, dim=-1)\n",
        "        loss = loss_fn(logits, edge_label)\n",
        "        minibatch_loss += loss\n",
        "\n",
        "    minibatch_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print('mini-batch loss:',float(batch_loss))\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TV_wLrgk9udg"
      },
      "outputs": [],
      "source": [
        "free_memory()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rr-vuVB49udg"
      },
      "outputs": [],
      "source": [
        "supervision_edge_type = get_supervision_edge_type(batch)\n",
        "src_type, dst_type = supervision_edge_type[0], supervision_edge_type[2]\n",
        "edge_label = batch[supervision_edge_type].edge_label\n",
        "edge_label_index = batch[supervision_edge_type].edge_label_index\n",
        "src_node_embeddings = out[src_type][edge_label_index[0]]\n",
        "dst_node_embeddings = out[dst_type][edge_label_index[1]]\n",
        "torch.min(F.cosine_similarity(src_node_embeddings, dst_node_embeddings, dim=-1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0iKpZ0709udg"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "\n",
        "gc.collect()\n",
        "\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MoCV-11H9udg"
      },
      "outputs": [],
      "source": [
        "batch[supervision_edge_type].edge_label_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgWVOJMI9udg"
      },
      "outputs": [],
      "source": [
        "J2S = ('Job','REQUIRES','Skill')\n",
        "batch[J2S].edge_label_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Ok0V2Mz9udg"
      },
      "outputs": [],
      "source": [
        "batch['Job','REQUIRES','Skill']."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5nrqKUt9udh"
      },
      "outputs": [],
      "source": [
        "batch = next(iter(train_loaders[0]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKBtbRC49udh"
      },
      "outputs": [],
      "source": [
        "batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-95MPpfm9udh"
      },
      "outputs": [],
      "source": [
        "batch.edge_weight_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XauGYI6S9udh"
      },
      "outputs": [],
      "source": [
        "index = batch['Job','IS_SIMILAR_JOB','Job'].e_id\n",
        "labels = batch['Job','IS_SIMILAR_JOB','Job'].edge_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJYX09RM9udh"
      },
      "outputs": [],
      "source": [
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.datasets import OGB_MAG\n",
        "from torch_geometric.nn import SAGEConv, to_hetero\n",
        "\n",
        "\n",
        "dataset = OGB_MAG(root='./data', preprocess='metapath2vec', transform=T.ToUndirected())\n",
        "data = dataset[0]\n",
        "\n",
        "class GNN(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = SAGEConv(-1, hidden_channels)\n",
        "        self.conv2 = SAGEConv(-1, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index).relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "\n",
        "model = GNN(hidden_channels=64, out_channels=dataset.num_classes)\n",
        "model = to_hetero(model, data.metadata(), aggr='sum')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65-tXuE59udh"
      },
      "outputs": [],
      "source": [
        "#https://colab.research.google.com/drive/1GrAxHyZCZ13jpTkMy9vVO_v_U9nHDdvB#scrollTo=wmiFKI0ovYN4\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ssoj9sM_9udh"
      },
      "outputs": [],
      "source": [
        "# intially we use this GraphConv layer and aggregate using mean\n",
        "# this layer allows the addition of edge weights: the adjacency matrix simply consists not of 1s and 0s but the corresponding weights\n",
        "#https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.GraphConv.html\n",
        "\n",
        "# using max pool\n",
        "# https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.pool.global_max_pool.html#torch_geometric.nn.pool.global_max_pool"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
