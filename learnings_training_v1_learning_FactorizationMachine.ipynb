{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3c4b139-0996-4471-990d-08f1a7bbe79a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70ff1fe6-6bf8-4150-ac65-9a9f45fe8df1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if \"DATABRICKS_RUNTIME_VERSION\" in os.environ and not 'installed_libs' in globals():\n",
    "  #CUDA = 'cu121' \n",
    "  installed_libs = True\n",
    "  \n",
    "  \n",
    "  !pip install torch==2.1.0  torchvision==0.16.0 torchtext==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu121\n",
    "  import torch\n",
    "  #os.environ['TORCH'] = torch.__version__\n",
    "  #print(torch.__version__)\n",
    "  #torch_version = '2.0.0+cu118'\n",
    "  \n",
    "  #!pip install pyg_lib torch_scatter torch_sparse torch_cluster -f https://data.pyg.org/whl/torch-2.1.0+${CUDA}.html # torch_spline_conv\n",
    "  !pip install torch_geometric\n",
    "  !pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.1.0+cu121.html\n",
    "  #!pip install torch_sparse -f https://data.pyg.org/whl/torch-2.1.0+${CUDA}.html\n",
    "  #!pip install torch_scatter -f https://data.pyg.org/whl/torch-2.1.0+${CUDA}.html\n",
    "  #!pip install pyg_lib -f https://data.pyg.org/whl/torch-2.1.0+${CUDA}.html\n",
    "  !pip install sentence-transformers\n",
    "  !pip install torcheval\n",
    "  !pip install matplotlib\n",
    "  !pip install pandas\n",
    "  !pip install tensorboard\n",
    "  \n",
    "if \"DATABRICKS_RUNTIME_VERSION\" in os.environ:\n",
    "  ROOT_FOLDER = '/dbfs/FileStore/GraphNeuralNetworks/'\n",
    "else:\n",
    "  ROOT_FOLDER = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "efe06c00-84ff-49e4-89a9-cad18f63b110",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amos/mambaforge/envs/pyg_torch21/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# sampler\n",
    "\n",
    "def nf_sampler(batch_size, neg_sample_ratio, edge_label_index, num_learnings):\n",
    "    # triplet mode only\n",
    "    # sample some random edges\n",
    "    num_samples = batch_size\n",
    "    #sampled_indices = torch.randint(0, edge_label_index.shape[1], (num_samples,), replacement=False)\n",
    "    sampled_indices = torch.randperm(edge_label_index.shape[1])[:num_samples]\n",
    "    sampled_edges = edge_label_index[:, sampled_indices]\n",
    "    # remove sampled edges from edge_label_index with mask\n",
    "    mask = torch.ones(edge_label_index.shape[1], dtype=torch.bool)\n",
    "    mask[sampled_indices] = False\n",
    "    edge_label_index = edge_label_index[:, mask]\n",
    "    \n",
    "    assert neg_sample_ratio >= 1\n",
    "    neg_samples = sampled_indices.shape[0]*neg_sample_ratio\n",
    "    \n",
    "    s = sampled_edges[0,:].unsqueeze(0)\n",
    "    src_edges = s\n",
    "    for i in range(neg_sample_ratio-1):\n",
    "        src_edges= torch.cat((src_edges,s),dim=1)\n",
    "\n",
    "    sampled_negatives = torch.randint(0, num_learnings, (neg_samples,)).squeeze().unsqueeze(0)\n",
    "   \n",
    "   \n",
    "    negative_edge_label_index = torch.cat((src_edges, sampled_negatives),dim=0)\n",
    "    edge_label_indices = torch.cat((sampled_edges, negative_edge_label_index),dim=1)\n",
    "    new_edge_label_index = edge_label_index\n",
    "    batch_edge_label_index = edge_label_indices\n",
    "    return new_edge_label_index, batch_edge_label_index, torch.cat((torch.ones(batch_size), torch.zeros(neg_samples)))\n",
    "\n",
    "def nf_loader(edge_label_index, batch_size, num_learnings, neg_sample_ratio):\n",
    "    while edge_label_index.shape[1] > 0:\n",
    "        new_edge_label_index, batch_edge_label_index, batch_labels = nf_sampler(batch_size, neg_sample_ratio, edge_label_index, num_learnings)\n",
    "        edge_label_index = new_edge_label_index\n",
    "        yield batch_edge_label_index, batch_labels\n",
    "    \n",
    "\n",
    "def get_total_minibatch_count_fm(batch_size, edge_label_index):\n",
    "    return int((edge_label_index.shape[1]+batch_size)//batch_size)\n",
    "import torch\n",
    "from torch_geometric.data import HeteroData\n",
    "#data = HeteroData(torch.load('factorization_machines_dataset.pt'))\n",
    "train_data = HeteroData(torch.load(ROOT_FOLDER+'FactorizationMachines_Dataset_train_labelencoded_v2.pt'))\n",
    "val_data = HeteroData(torch.load(ROOT_FOLDER+'FactorizationMachines_Dataset_val_labelencoded_v2.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([56])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['people'].labelencoding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  _global_store={},\n",
       "  people={\n",
       "    x=[293444, 56],\n",
       "    labelencoding=[56],\n",
       "  },\n",
       "  courses_and_programs={\n",
       "    x=[55796, 26],\n",
       "    labelencoding=[26],\n",
       "  },\n",
       "  (people, completed, courses_and_programs)={\n",
       "    edge_index=[2, 360300],\n",
       "    edge_label_index=[2, 154413],\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d1eaa98-6d39-486c-a20c-67b7bec2fdda",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([56]) torch.Size([26])\n",
      "tensor([293444,  55638, 264052, 264052, 264052, 264052, 264052, 264052, 264052,\n",
      "        264052, 264052, 264052, 264052, 264052, 264052, 264052, 264052, 264052,\n",
      "        264052, 264052, 264052, 264052, 264052, 264052, 264052, 264052, 264052,\n",
      "        264052, 264052, 264052, 264052, 264052, 264052, 264052, 264052, 264052,\n",
      "        264052, 264052, 264052, 264052, 264052, 264052, 264052, 264052, 264052,\n",
      "        264052, 264052, 264052, 264052, 264052, 264052, 264052, 293444, 293444,\n",
      "         13613,  13613,  55796, 264052, 264052, 264052, 264052, 264052, 264052,\n",
      "        264052, 264052, 264052, 264052, 264052, 264052, 264052, 264052, 264052,\n",
      "        264052, 264052, 264052, 264052, 264052, 264052, 264052, 264052, 264052,\n",
      "        264052], device='cuda:0')\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m     \u001b[39mreturn\u001b[39;00m bound(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m     58\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     \u001b[39m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[39m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[39m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[39m# exception has a traceback chain.\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: cumsum() received an invalid combination of arguments - got (dtype=NoneType, out=NoneType, axis=NoneType, ), but expected one of:\n * (int dim, *, torch.dtype dtype)\n      didn't match because some of the keywords were incorrect: out, axis\n * (name dim, *, torch.dtype dtype)\n      didn't match because some of the keywords were incorrect: out, axis\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/amos/programming/create_graphds/learnings_training_v1_learning_FactorizationMachine.ipynb Cell 6\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/amos/programming/create_graphds/learnings_training_v1_learning_FactorizationMachine.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=83'>84</a>\u001b[0m \u001b[39m# convert the field dims to integer\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/amos/programming/create_graphds/learnings_training_v1_learning_FactorizationMachine.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=84'>85</a>\u001b[0m field_dims \u001b[39m=\u001b[39m field_dims\u001b[39m.\u001b[39mto(torch\u001b[39m.\u001b[39mint64)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/amos/programming/create_graphds/learnings_training_v1_learning_FactorizationMachine.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=85'>86</a>\u001b[0m fm \u001b[39m=\u001b[39m FactorizationMachineModel(\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/amos/programming/create_graphds/learnings_training_v1_learning_FactorizationMachine.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=86'>87</a>\u001b[0m     field_dims\u001b[39m=\u001b[39;49mfield_dims,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/amos/programming/create_graphds/learnings_training_v1_learning_FactorizationMachine.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=87'>88</a>\u001b[0m         embed_dim\u001b[39m=\u001b[39;49mhidden_channels)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/amos/programming/create_graphds/learnings_training_v1_learning_FactorizationMachine.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=95'>96</a>\u001b[0m model \u001b[39m=\u001b[39m Model(fm, head\u001b[39m=\u001b[39mhead, node_types\u001b[39m=\u001b[39mmetadata[\u001b[39m0\u001b[39m], edge_types\u001b[39m=\u001b[39mmetadata[\u001b[39m1\u001b[39m], ggn_output_dim\u001b[39m=\u001b[39mout_channels, pnorm\u001b[39m=\u001b[39mpnorm, num_supervisors\u001b[39m=\u001b[39mnum_supervisors, num_organizations\u001b[39m=\u001b[39mnum_organizations)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/amos/programming/create_graphds/learnings_training_v1_learning_FactorizationMachine.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=96'>97</a>\u001b[0m \u001b[39m#torch_geometric.compile(model, dynamic=True)\u001b[39;00m\n",
      "File \u001b[0;32m~/programming/create_graphds/models/FactorizationMachineModel.py:16\u001b[0m, in \u001b[0;36mFactorizationMachineModel.__init__\u001b[0;34m(self, field_dims, embed_dim)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, field_dims, embed_dim):\n\u001b[1;32m     15\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[0;32m---> 16\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding \u001b[39m=\u001b[39m FeaturesEmbedding(field_dims, embed_dim)\n\u001b[1;32m     17\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear \u001b[39m=\u001b[39m FeaturesLinear(field_dims)\n\u001b[1;32m     18\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfm \u001b[39m=\u001b[39m FactorizationMachine(reduce_sum\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/mambaforge/envs/pyg_torch21/lib/python3.10/site-packages/torchfm/layer.py:27\u001b[0m, in \u001b[0;36mFeaturesEmbedding.__init__\u001b[0;34m(self, field_dims, embed_dim)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[1;32m     26\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mEmbedding(\u001b[39msum\u001b[39m(field_dims), embed_dim)\n\u001b[0;32m---> 27\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moffsets \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray((\u001b[39m0\u001b[39m, \u001b[39m*\u001b[39mnp\u001b[39m.\u001b[39;49mcumsum(field_dims)[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]), dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mlonglong)\n\u001b[1;32m     28\u001b[0m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39minit\u001b[39m.\u001b[39mxavier_uniform_(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding\u001b[39m.\u001b[39mweight\u001b[39m.\u001b[39mdata)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mcumsum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:2597\u001b[0m, in \u001b[0;36mcumsum\u001b[0;34m(a, axis, dtype, out)\u001b[0m\n\u001b[1;32m   2523\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_cumsum_dispatcher)\n\u001b[1;32m   2524\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcumsum\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   2525\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2526\u001b[0m \u001b[39m    Return the cumulative sum of the elements along a given axis.\u001b[39;00m\n\u001b[1;32m   2527\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2595\u001b[0m \n\u001b[1;32m   2596\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2597\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapfunc(a, \u001b[39m'\u001b[39;49m\u001b[39mcumsum\u001b[39;49m\u001b[39m'\u001b[39;49m, axis\u001b[39m=\u001b[39;49maxis, dtype\u001b[39m=\u001b[39;49mdtype, out\u001b[39m=\u001b[39;49mout)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:66\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[39mreturn\u001b[39;00m bound(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m     58\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     \u001b[39m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[39m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[39m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[39m# exception has a traceback chain.\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:43\u001b[0m, in \u001b[0;36m_wrapit\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m     wrap \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(asarray(obj), method)(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m     44\u001b[0m \u001b[39mif\u001b[39;00m wrap:\n\u001b[1;32m     45\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(result, mu\u001b[39m.\u001b[39mndarray):\n",
      "File \u001b[0;32m~/mambaforge/envs/pyg_torch21/lib/python3.10/site-packages/torch/_tensor.py:1030\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1028\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[39m.\u001b[39m__array__, (\u001b[39mself\u001b[39m,), \u001b[39mself\u001b[39m, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[1;32m   1029\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1030\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnumpy()\n\u001b[1;32m   1031\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1032\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from models.TransE import TransE\n",
    "from models.DistMult import DistMult\n",
    "from models.FactorizationMachineModel import FactorizationMachineModel\n",
    "import torch_geometric\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, fm : torch.nn.Module, head, node_types, edge_types, ggn_output_dim, pnorm=1, num_supervisors=0, num_organizations=0):\n",
    "        super().__init__()\n",
    "        # edge_type onehot lookup table with keys\n",
    "        # node_type onehot lookup table with keys\n",
    "        self.node_type_embedding = torch.nn.Embedding(len(node_types), ggn_output_dim) # hidden channels should be the output dim of gnn\n",
    "        self.num_supervisors = num_supervisors\n",
    "        self.num_organizations = num_organizations\n",
    "        self.edge_types = edge_types\n",
    "        for edge_type in edge_types:\n",
    "            if edge_type[1].startswith('rev_'):\n",
    "                self.edge_types.remove(edge_type)\n",
    "        \n",
    "        # create edge to int mapping\n",
    "        self.edgeindex_lookup = {edge_type:torch.tensor(i)  for i, edge_type in enumerate(edge_types)}\n",
    "            \n",
    "        if head=='TransE': \n",
    "            self.head = TransE(len(node_types), len(edge_types) , ggn_output_dim, p_norm= pnorm)  # KGE head with loss function\n",
    "        elif head=='DistMult':\n",
    "            self.head = DistMult(len(node_types), len(edge_types) , ggn_output_dim, p_norm= pnorm)  # KGE head with loss function\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        \n",
    "        self.fm = fm\n",
    "        \n",
    "    \n",
    "\n",
    "    def forward(self, hetero_data, edge_label_index, edge_label):\n",
    "        \n",
    "    \n",
    "        people = hetero_data['people'].x[edge_label_index[0,:]]\n",
    "        # last two columns in people are the indices of onehot, so change them to full onehot supervisor and organization\n",
    "        #supervisors = torch.nn.functional.one_hot(people[:,-2].to(torch.int64), num_classes=self.num_supervisors).to(torch.float32)\n",
    "        #organizations = torch.nn.functional.one_hot(people[:,-1].to(torch.int64), num_classes=self.num_organizations).to(torch.float32)\n",
    "        #people = torch.cat((people[:,:-2], supervisors, organizations), dim=1)\n",
    "        \n",
    "                        \n",
    "        learnings = hetero_data['courses_and_programs'].x[edge_label_index[1,:]]\n",
    "    \n",
    "        x = torch.cat((people,learnings),dim=1)\n",
    "        scores = self.fm(x)\n",
    "        pos_scores = scores[edge_label==1]\n",
    "        neg_scores = scores[edge_label==0]\n",
    "            \n",
    "\n",
    "        return F.margin_ranking_loss(\n",
    "            pos_scores,\n",
    "            neg_scores,\n",
    "            target=torch.ones_like(pos_scores), # 1 for similarity, -1 for dissimilarity\n",
    "            margin=0.2\n",
    "        )\n",
    "        \n",
    "    \n",
    "out_channels = 1\n",
    "hidden_channels = 16\n",
    "num_heads = 0\n",
    "num_layers = 0\n",
    "pnorm = 2\n",
    "head = 'TransE'\n",
    "#gnn = HGT(hidden_channels=out_channels, out_channels=out_channels, num_heads=num_heads, num_layers=num_layers, node_types=train_data.node_types, data_metadata=metadata)\n",
    "filename = 'HeteroData_Learnings_normalized_triangles_withadditionaldata_v1.pt'\n",
    "data_forlookup = HeteroData.from_dict(torch.load(ROOT_FOLDER+filename))\n",
    "num_supervisors = data_forlookup['people'].num_nodes\n",
    "num_organizations = data_forlookup['organizations'].num_nodes\n",
    "metadata = data_forlookup.metadata()\n",
    "# add selfloops\n",
    "for node_type in data_forlookup.node_types:\n",
    "    metadata[1].append((node_type, 'self_loop', node_type))  \n",
    "    \n",
    "    \n",
    "\n",
    "del data_forlookup\n",
    "print(train_data['people'].labelencoding.shape, train_data['courses_and_programs'].labelencoding.shape)  \n",
    "field_dims = torch.cat((train_data['people'].labelencoding,train_data['courses_and_programs'].labelencoding), dim=0)\n",
    "print(field_dims)\n",
    "# convert the field dims to integer\n",
    "field_dims = field_dims.to(torch.int64)\n",
    "fm = FactorizationMachineModel(\n",
    "    field_dims=field_dims,\n",
    "        embed_dim=hidden_channels)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Model(fm, head=head, node_types=metadata[0], edge_types=metadata[1], ggn_output_dim=out_channels, pnorm=pnorm, num_supervisors=num_supervisors, num_organizations=num_organizations)\n",
    "#torch_geometric.compile(model, dynamic=True)\n",
    "model.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([293444,  55638, 264052, 264052, 264052, 264052, 264052, 264052, 264052,\n",
       "        264052, 264052, 264052, 264052, 264052, 264052, 264052, 264052, 264052,\n",
       "        264052, 264052, 264052, 264052, 264052, 264052, 264052, 264052, 264052,\n",
       "        264052, 264052, 264052, 264052, 264052, 264052, 264052, 264052, 264052,\n",
       "        264052, 264052, 264052, 264052, 264052, 264052, 264052, 264052, 264052,\n",
       "        264052, 264052, 264052, 264052, 264052, 264052, 264052, 293444, 293444,\n",
       "         13613,  13613,  55796, 264052, 264052, 264052, 264052, 264052, 264052,\n",
       "        264052, 264052, 264052, 264052, 264052, 264052, 264052, 264052, 264052,\n",
       "        264052, 264052, 264052, 264052, 264052, 264052, 264052, 264052, 264052,\n",
       "        264052])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "field_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FactorizationMachineModel(\n",
       "  (embedding): FeaturesEmbedding(\n",
       "    (embedding): Embedding(20822892, 16)\n",
       "  )\n",
       "  (linear): FeaturesLinear(\n",
       "    (fc): Embedding(20822892, 1)\n",
       "  )\n",
       "  (fm): FactorizationMachine()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ebad4a8-bb51-45f9-8f93-8036fd9e89ae",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writer runs/learningpeople_factorizationmachines_20231103_195322_pnorm2_llr0.0002_bs32_neighbors__head_TransE_hiddenchannels_16_outchannels_1_numheads_0_numlayers_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4826 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 82]) tensor([[149242,      0,      0,  ...,      0,      0,      0],\n",
      "        [244672,   3844,   7448,  ...,      0,      0,      0],\n",
      "        [283744,      0,      0,  ...,      0,      0,      0],\n",
      "        ...,\n",
      "        [201083,   3692,   7554,  ...,      0,      0,      0],\n",
      "        [161913,      0,      0,  ...,      0,      0,      0],\n",
      "        [137156,  10039,    721,  ...,      0,      0,      0]],\n",
      "       device='cuda:0')\n",
      "torch.Size([64, 82]) tensor([[ 50480,   4428,      0,  ...,      0,      0,      0],\n",
      "        [247290,  14171,    721,  ...,      0,      0,      0],\n",
      "        [214730,  23181,      0,  ...,      0,      0,      0],\n",
      "        ...,\n",
      "        [ 17080,  27869,    721,  ...,      0,      0,      0],\n",
      "        [165403,  23106,    721,  ...,      0,      0,      0],\n",
      "        [161241,   3874,    200,  ...,      0,      0,      0]],\n",
      "       device='cuda:0')\n",
      "torch.Size([64, 82]) tensor([[255339,  23110,    721,  ...,      0,      0,      0],\n",
      "        [ 15120,  27869,    721,  ...,      0,      0,      0],\n",
      "        [225363,  23381,    721,  ...,      0,      0,      0],\n",
      "        ...,\n",
      "        [231177,      0,      0,  ...,      0,      0,      0],\n",
      "        [220990,    489,    721,  ...,      0,      0,      0],\n",
      "        [ 88948,      4,    721,  ...,      0,      0,      0]],\n",
      "       device='cuda:0')\n",
      "torch.Size([64, 82]) tensor([[ 77843,  23339,    721,  ...,      0,      0,      0],\n",
      "        [187133,      0,      0,  ...,      0,      0,      0],\n",
      "        [164198,    282,    721,  ...,      0,      0,      0],\n",
      "        ...,\n",
      "        [ 69358,  27869,    721,  ...,      0,      0,      0],\n",
      "        [  6660,  10039,    721,  ...,      0,      0,      0],\n",
      "        [157128,  23353,    721,  ...,      0,      0,      0]],\n",
      "       device='cuda:0')\n",
      "saving model to models/learningpeople_factorizationmachines_20231103_195322_pnorm2_llr0.0002_bs32_neighbors__head_TransE_hiddenchannels_16_outchannels_1_numheads_0_numlayers_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/4826 [00:16<22:31:53, 16.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 82]) tensor([[163972,  23362,    721,  ...,      0,      0,      0],\n",
      "        [236234,  23353,   4277,  ...,      0,      0,      0],\n",
      "        [253213,      0,      0,  ...,      0,      0,      0],\n",
      "        ...,\n",
      "        [262788,      0,      0,  ...,      0,      0,      0],\n",
      "        [241937,    361,   3339,  ...,      0,      0,      0],\n",
      "        [230249,   3666,    200,  ...,      0,      0,      0]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/4826 [00:20<12:11:42,  9.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 82]) tensor([[144381,    118,   7514,  ...,      0,      0,      0],\n",
      "        [ 21312,      0,      0,  ...,      0,      0,      0],\n",
      "        [265339,    395,    721,  ...,      0,      0,      0],\n",
      "        ...,\n",
      "        [142351,   3666,    200,  ...,      0,      0,      0],\n",
      "        [241843,      0,      0,  ...,      0,      0,      0],\n",
      "        [141513,      0,      0,  ...,      0,      0,      0]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/4826 [00:22<7:41:33,  5.74s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 82]) tensor([[143858,   9501,    721,  ...,      0,      0,      0],\n",
      "        [201094,      0,      0,  ...,      0,      0,      0],\n",
      "        [ 92214,      0,      0,  ...,      0,      0,      0],\n",
      "        ...,\n",
      "        [230019,   5428,    721,  ...,      0,      0,      0],\n",
      "        [172120,      0,      0,  ...,      0,      0,      0],\n",
      "        [173985,  23353,   4277,  ...,      0,      0,      0]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/4826 [00:23<5:34:21,  4.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 82]) tensor([[142678,   3753,    721,  ...,      0,      0,      0],\n",
      "        [169917,   5408,   4789,  ...,      0,      0,      0],\n",
      "        [228103,  24717,    721,  ...,      0,      0,      0],\n",
      "        ...,\n",
      "        [149049,   3077,    721,  ...,      0,      0,      0],\n",
      "        [ 81309,  23350,    721,  ...,      0,      0,      0],\n",
      "        [104231,   3448,   9835,  ...,      0,      0,      0]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/4826 [00:25<4:23:51,  3.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 82]) tensor([[ 58467,      0,      0,  ...,      0,      0,      0],\n",
      "        [286496,   9502,   1513,  ...,      0,      0,      0],\n",
      "        [203943,  27702,      0,  ...,      0,      0,      0],\n",
      "        ...,\n",
      "        [256237,    555,   2561,  ...,      0,      0,      0],\n",
      "        [231737,      0,      0,  ...,      0,      0,      0],\n",
      "        [249314,      0,      0,  ...,      0,      0,      0]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/4826 [00:27<3:41:46,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 82]) tensor([[261766,   3692,   7554,  ...,      0,      0,      0],\n",
      "        [173181,      0,      0,  ...,      0,      0,      0],\n",
      "        [199930,   3025,   7554,  ...,      0,      0,      0],\n",
      "        ...,\n",
      "        [203330,   8734,  12702,  ...,      0,      0,      0],\n",
      "        [163245,    282,    721,  ...,      0,      0,      0],\n",
      "        [248462,      0,      0,  ...,      0,      0,      0]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/4826 [00:29<6:31:10,  4.87s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/amos/programming/create_graphds/learnings_training_v1_learning_FactorizationMachine.ipynb Cell 11\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/amos/programming/create_graphds/learnings_training_v1_learning_FactorizationMachine.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/amos/programming/create_graphds/learnings_training_v1_learning_FactorizationMachine.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=44'>45</a>\u001b[0m total_samples_seen \u001b[39m=\u001b[39m i \u001b[39m*\u001b[39m batch_size\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/amos/programming/create_graphds/learnings_training_v1_learning_FactorizationMachine.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=45'>46</a>\u001b[0m writer\u001b[39m.\u001b[39madd_scalar(\u001b[39m'\u001b[39m\u001b[39mLoss/train\u001b[39m\u001b[39m'\u001b[39m, loss\u001b[39m.\u001b[39;49mitem(), total_samples_seen)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/amos/programming/create_graphds/learnings_training_v1_learning_FactorizationMachine.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=47'>48</a>\u001b[0m \u001b[39mif\u001b[39;00m i \u001b[39m==\u001b[39m total_minibatches\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/amos/programming/create_graphds/learnings_training_v1_learning_FactorizationMachine.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=48'>49</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m loss: \u001b[39m\u001b[39m{\u001b[39;00mloss\u001b[39m.\u001b[39mitem()\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime\n",
    "batch_size = 32\n",
    "\n",
    "learning_rate = 2e-4\n",
    "# torch get optimizer by string name\n",
    "optimizer = 'Adam'\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) #2e-15\n",
    "\n",
    "\n",
    "# create a tensorboard writer\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "neighbors = '_'.join([str(n) for n in []])\n",
    "\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "writer = SummaryWriter(ROOT_FOLDER+f'runs/learningpeople_factorizationmachines_{timestamp}_pnorm{pnorm}_lr{learning_rate}_bs{batch_size}_neighbors_{neighbors}_head_{head}_hiddenchannels_{hidden_channels}_outchannels_{out_channels}_numheads_{num_heads}_numlayers_{num_layers}')\n",
    "print('writer',ROOT_FOLDER+f'runs/learningpeople_factorizationmachines_{timestamp}_pnorm{pnorm}_llr{learning_rate}_bs{batch_size}_neighbors_{neighbors}_head_{head}_hiddenchannels_{hidden_channels}_outchannels_{out_channels}_numheads_{num_heads}_numlayers_{num_layers}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "num_learnings = train_data['courses_and_programs'].num_nodes\n",
    "neg_sample_ratio = 1\n",
    "train_loader = nf_loader(train_data['people','completed','courses_and_programs'].edge_label_index.to('cpu'), batch_size, num_learnings, neg_sample_ratio)\n",
    "val_loader = nf_loader(val_data['people','completed','courses_and_programs'].edge_label_index.to('cpu'), batch_size, num_learnings, neg_sample_ratio)\n",
    "total_minibatches = get_total_minibatch_count_fm(batch_size, train_data['people','completed','courses_and_programs'].edge_label_index)\n",
    "\n",
    "\n",
    "model.train()\n",
    "start_epoch = 1\n",
    "for epoch in range(start_epoch, start_epoch+1000):\n",
    "    for i, (batch_edge_label_index, labels) in tqdm(enumerate(train_loader), total=total_minibatches):\n",
    "        \n",
    "        optimizer.zero_grad() \n",
    "        # batching is different depending on if node types in edge are same or different\n",
    "        \n",
    "        loss = model(train_data.to(device), batch_edge_label_index.to(device), labels.to(device))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_samples_seen = i * batch_size\n",
    "        writer.add_scalar('Loss/train', loss.item(), total_samples_seen)\n",
    "        \n",
    "        if i == total_minibatches-1:\n",
    "            print(f'{i} loss: {loss.item():.4f}')\n",
    "            writer.add_scalar('Epoch Loss/train', loss.item(), total_samples_seen)\n",
    "        \n",
    "        # print loss and minibatch in the same line\n",
    "        print(f'{i} loss: {loss.item():.4f}', end='\\r')\n",
    "        \n",
    "        if i % 300 == 0 or i == total_minibatches-1:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_loss = 0\n",
    "                for _ in range(3):\n",
    "                    try:\n",
    "                        batch_edge_label_index, labels = next(val_loader)\n",
    "                    except StopIteration:\n",
    "                        val_loader = iter(val_loader)\n",
    "                        batch_edge_label_index, labels = next(val_loader)\n",
    "                    val_loss = model(val_data.to(device), batch_edge_label_index.to(device), labels.to(device))\n",
    "                    \n",
    "                    \n",
    "            val_loss /= 3\n",
    "            if i == 0:\n",
    "                writer.add_scalar('Epoch Loss/val', val_loss, total_samples_seen)\n",
    "                writer.add_scalar('Loss/val', val_loss, total_samples_seen)\n",
    "            elif i == total_minibatches-1:\n",
    "                writer.add_scalar('Epoch Loss/val', val_loss, total_samples_seen)\n",
    "            else:\n",
    "                writer.add_scalar('Loss/val', val_loss, total_samples_seen)\n",
    "            \n",
    "\n",
    "            print(f'val_loss: {val_loss:.4f}', end='\\r')\n",
    "            model.train()\n",
    "\n",
    "        writer.flush()\n",
    "        \n",
    "        if i % 1000 == 0 or i == total_minibatches-1:\n",
    "            folder = 'models'\n",
    "            if not os.path.exists(folder):\n",
    "                os.makedirs(folder)\n",
    "            \n",
    "            run_folder = ROOT_FOLDER+f'{folder}/learningpeople_factorizationmachines_{timestamp}_pnorm{pnorm}_llr{learning_rate}_bs{batch_size}_neighbors_{neighbors}_head_{head}_hiddenchannels_{hidden_channels}_outchannels_{out_channels}_numheads_{num_heads}_numlayers_{num_layers}'\n",
    "            if not os.path.exists(run_folder):\n",
    "                os.makedirs(run_folder)\n",
    "                \n",
    "            print('saving model to', run_folder)\n",
    "            # save model and optimizer\n",
    "            is_epoch = f'Ep{epoch}_' if i == total_minibatches-1 else ''\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                }, run_folder+f'/{is_epoch}model_samplesseen{total_samples_seen}.pt')\n",
    "            \n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "learnings_training_v1_learningpeople_hgt",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "pyg_torch21",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
