{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Reciprocal Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if \"DATABRICKS_RUNTIME_VERSION\" in os.environ and not 'installed_libs' in globals():\n",
    "  #CUDA = 'cu121' \n",
    "  installed_libs = True\n",
    "  \n",
    "  \n",
    "  !pip install torch==2.1.0  torchvision==0.16.0 torchtext==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu121\n",
    "  import torch\n",
    "  #os.environ['TORCH'] = torch.__version__\n",
    "  #print(torch.__version__)\n",
    "  #torch_version = '2.0.0+cu118'\n",
    "  \n",
    "  #!pip install pyg_lib torch_scatter torch_sparse torch_cluster -f https://data.pyg.org/whl/torch-2.1.0+${CUDA}.html # torch_spline_conv\n",
    "  !pip install torch_geometric\n",
    "  !pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.1.0+cu121.html\n",
    "  #!pip install torch_sparse -f https://data.pyg.org/whl/torch-2.1.0+${CUDA}.html\n",
    "  #!pip install torch_scatter -f https://data.pyg.org/whl/torch-2.1.0+${CUDA}.html\n",
    "  #!pip install pyg_lib -f https://data.pyg.org/whl/torch-2.1.0+${CUDA}.html\n",
    "  !pip install sentence-transformers\n",
    "  !pip install torcheval\n",
    "  !pip install matplotlib\n",
    "  !pip install pandas\n",
    "  !pip install tensorboard\n",
    "  \n",
    "if \"DATABRICKS_RUNTIME_VERSION\" in os.environ:\n",
    "  ROOT_FOLDER = '/dbfs/FileStore/GraphNeuralNetworks/'\n",
    "else:\n",
    "  ROOT_FOLDER = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amos/mambaforge/envs/pyg_torch21/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of dataset on disk:  2.279761238 gb\n",
      "loading saved heterodata object\n",
      "for skill job edges keep top k edges per job, k is  50\n",
      "keep tensor(1208056) of total 16289586\n"
     ]
    }
   ],
   "source": [
    "from learnings_sampler_v1 import get_datasets, uniform_hgt_sampler, get_minibatch_count, add_reverse_edge_original_attributes_and_label_inplace, get_hgt_linkloader, get_single_minibatch_count\n",
    "\n",
    "train_data, val_data, test_data = get_datasets(get_edge_attr=False, filename=ROOT_FOLDER+'HeteroData_Learnings_normalized_triangles_withadditionaldata_v1.pt', filter_top_k=True, top_k=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models.TransE import TransE\n",
    "from models.DistMult import DistMult\n",
    "from models.HGT import HGT\n",
    "import torch_geometric\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, gnn : torch.nn.Module, head :  torch.nn.Module, node_types, edge_types, ggn_output_dim, pnorm):\n",
    "        super().__init__()\n",
    "        # edge_type onehot lookup table with keys\n",
    "        # node_type onehot lookup table with keys\n",
    "        self.node_type_embedding = torch.nn.Embedding(len(node_types), ggn_output_dim) # hidden channels should be the output dim of gnn\n",
    "        \n",
    "        self.edge_types = edge_types\n",
    "        for edge_type in edge_types:\n",
    "            if edge_type[1].startswith('rev_'):\n",
    "                self.edge_types.remove(edge_type)\n",
    "        \n",
    "        # create edge to int mapping\n",
    "        self.edgeindex_lookup = {edge_type:torch.tensor(i)  for i, edge_type in enumerate(edge_types)}\n",
    "            \n",
    "        # hidden channels should be the output dim of gnn\n",
    "        if head=='TransE': \n",
    "            self.head = TransE(len(node_types), len(edge_types) , ggn_output_dim, p_norm=pnorm)  # KGE head with loss function\n",
    "        elif head=='DistMult':\n",
    "            self.head = DistMult(len(node_types), len(edge_types) , ggn_output_dim, p_norm=pnorm)  # KGE head with loss function\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        \n",
    "        self.gnn = gnn\n",
    "        \n",
    "    \n",
    "\n",
    "    def forward(self, hetero_data1, target_edge_type, edge_label_index, edge_label, hetero_data2=None, get_head_fn='loss'):\n",
    "        \n",
    "        if hetero_data2 is not None:\n",
    "            assert target_edge_type[0] != target_edge_type[2], 'when passing two data objects, the edge type has to contain two different node types'\n",
    "            head_embeddings = self.gnn(hetero_data1.x_dict, hetero_data1.edge_index_dict)[target_edge_type[0]][edge_label_index[0,:]]\n",
    "            tail_embeddings = self.gnn(hetero_data2.x_dict, hetero_data2.edge_index_dict)[target_edge_type[2]][edge_label_index[1,:]]\n",
    "        else:\n",
    "            assert target_edge_type[0] == target_edge_type[2], 'when passing one data object, the edge type has to contain the same node types'\n",
    "\n",
    "\n",
    "            embeddings = self.gnn(hetero_data1.x_dict, hetero_data1.edge_index_dict)\n",
    "            head_embeddings = embeddings[target_edge_type[0]][edge_label_index[0,:]]\n",
    "            tail_embeddings = embeddings[target_edge_type[2]][edge_label_index[1,:]]\n",
    "\n",
    "        \n",
    "        edgeindex = self.edgeindex_lookup[target_edge_type]\n",
    "        if get_head_fn=='loss':\n",
    "            loss = self.head.loss(head_embeddings, edgeindex.to(device), tail_embeddings, edge_label)\n",
    "            return loss\n",
    "        elif get_head_fn=='forward':\n",
    "            return self.head.forward(head_embeddings, edgeindex.to(device), tail_embeddings)\n",
    "    \n",
    "    def get_embeddings(self, hetero_data, rel_type, node_type, first_n_nodes=None):\n",
    "        # gives us the closeness of embeddings to the other side of the relationship, i.e. e + r or e - r\n",
    "        if node_type == rel_type[0]:\n",
    "            have_head_or_tail =='head'\n",
    "        else:\n",
    "            have_head_or_tail =='tail'\n",
    "            \n",
    "        mask = torch.zeros(hetero_data.x_dict[rel_type[0]].shape[0])\n",
    "        mask[:first_n_nodes] = 1\n",
    "        embeddings = self.gnn(hetero_data.x_dict, hetero_data.edge_index_dict)[node_type][mask]\n",
    "        return self.head.get_embeddings(embeddings, rel_type, have_head_or_tail)\n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "# out_channels = 256\n",
    "# hidden_channels = 256\n",
    "# num_heads = 8\n",
    "# num_layers = 2\n",
    "# head = 'TransE'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_folder):\n",
    "    metadata = train_data.metadata()\n",
    "    # add selfloops\n",
    "    for node_type in train_data.node_types:\n",
    "        metadata[1].append((node_type, 'self_loop', node_type))    \n",
    "    \n",
    "    # infer model parameters, dimensions batchsize etc from filename\n",
    "    out_channels = int(model_folder.split('outchannels_')[1].split('_')[0])\n",
    "    hidden_channels = int(model_folder.split('hiddenchannels_')[1].split('_')[0])\n",
    "    num_heads = int(model_folder.split('numheads_')[1].split('_')[0])\n",
    "    num_layers = int(model_folder.split('numlayers_')[1].split('/')[0])\n",
    "    head = model_folder.split('head_')[1].split('_')[0]\n",
    "    learning_rate = float(model_folder.split('lr')[1].split('_')[0])\n",
    "    batch_size = int(model_folder.split('bs')[1].split('_')[0])\n",
    "    num_neighbors = [int(x) for x in model_folder.split('neighbors_')[1].split('head')[0].strip('_').split('_')]\n",
    "    if 'pnrom' in model_folder:\n",
    "        pnorm = int(model_folder.split('pnrom')[1].split('_')[0])\n",
    "    elif 'pnorm' in model_folder:\n",
    "        pnorm = int(model_folder.split('pnorm')[1].split('_')[0])\n",
    "    else:\n",
    "        pnorm = 1\n",
    "        \n",
    "    gnn = HGT(hidden_channels=out_channels, out_channels=out_channels, num_heads=num_heads, num_layers=num_layers, node_types=train_data.node_types, data_metadata=metadata)\n",
    "\n",
    "    model = Model(gnn, head=head, node_types=metadata[0], edge_types=metadata[1], ggn_output_dim=out_channels, pnorm=pnorm)\n",
    "    #torch_geometric.compile(model, dynamic=True)\n",
    "    #model.load_state_dict(torch.load(model_folder)['model_state_dict'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_foldere5 = ROOT_FOLDER+'models/learningpeople_hgt_20231102_004035_lr2e-06_bs32_neighbors_133_1333_head_TransE_hiddenchannels_256_outchannels_256_numheads_8_numlayers_2/Ep0_model_samplesseen154400.pt'\n",
    "modele5 = get_model(model_foldere5)\n",
    "\n",
    "model_foldere4 = ROOT_FOLDER+'models/learningpeople_hgt_20231102_114410_lr0.0002_bs32_neighbors_133_1333_head_TransE_hiddenchannels_256_outchannels_256_numheads_8_numlayers_2/Ep1_model_samplesseen154400.pt'\n",
    "modele4 = get_model(model_foldere4)\n",
    "\n",
    "model_foldere4euclidean = ROOT_FOLDER+'models/learningpeople_hgt_20231102_170612_pnrom2_llr0.0002_bs32_neighbors_133_1333_head_TransE_hiddenchannels_256_outchannels_256_numheads_8_numlayers_2/Ep1_model_samplesseen154400.pt'\n",
    "modele4euclidean = get_model(model_foldere4euclidean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(model, model_folder):\n",
    "    model.to(device)\n",
    "    num_neighbors = [int(x) for x in model_folder.split('neighbors_')[1].split('head')[0].strip('_').split('_')]\n",
    "    \n",
    "    # init dimensions of model by training it\n",
    "    from tqdm.auto import tqdm\n",
    "    from datetime import datetime\n",
    "    input_edgetype = ('people', 'rev_course_and_programs_student', 'courses_and_programs')\n",
    "    add_reverse_edge_original_attributes_and_label_inplace(train_data['courses_and_programs', 'course_and_programs_student', 'people'], reverse_edge=train_data[input_edgetype] )\n",
    "    add_reverse_edge_original_attributes_and_label_inplace(val_data['courses_and_programs', 'course_and_programs_student', 'people'], reverse_edge=val_data[input_edgetype] )\n",
    "\n",
    "    val_sampler = get_hgt_linkloader(val_data, input_edgetype, 10, False, 'triplet', 1, num_neighbors, num_workers=0, prefetch_factor=None, pin_memory=True)\n",
    "\n",
    "    learning_rate = 2e-4\n",
    "    # torch get optimizer by string name\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) #2e-15\n",
    "\n",
    "    # train model\n",
    "\n",
    "    model.eval()\n",
    "    minibatchpart1, minibatchpart2, edge_label_index, edge_label, input_edge_id, src_nodes, dst_nodes = next(iter(val_sampler))\n",
    "    #optimizer.zero_grad()\n",
    "    loss = model(minibatchpart1.to(device), input_edgetype, edge_label_index.to(device), edge_label.to(device), minibatchpart2.to(device))\n",
    "    model.load_state_dict(torch.load(model_folder)['model_state_dict'])\n",
    "    model.to('cpu')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_model(modele5, model_foldere5)\n",
    "init_model(modele4, model_foldere4)\n",
    "init_model(modele4euclidean, model_foldere4euclidean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model on test set\n",
    "# init dimensions of model by training it\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime\n",
    "import numpy as np \n",
    "\n",
    "def evaluate(model, n_negatives, model_folder, on='test'):\n",
    "    num_neighbors = [int(x) for x in model_folder.split('neighbors_')[1].split('head')[0].strip('_').split('_')]\n",
    "    \n",
    "    model.to(device)\n",
    "    mrrs = []\n",
    "   \n",
    "    \n",
    "    #test_sampler = get_hgt_linkloader(test_data, input_edgetype, 1, False, 'triplet', n_negatives, num_neighbors, num_workers=0, prefetch_factor=None, pin_memory=True)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    # test data\n",
    "    train_data_text, val_data_text, test_data_text = get_datasets(get_edge_attr=False, filename=ROOT_FOLDER+'HeteroData_Learnings_normalized_triangles_withadditionaldata_v1.pt', filter_top_k=True, top_k=50, remove_text_attr=False)\n",
    "    input_edgetype = ('people', 'rev_course_and_programs_student', 'courses_and_programs')\n",
    "    if on=='test':\n",
    "        add_reverse_edge_original_attributes_and_label_inplace(test_data['courses_and_programs', 'course_and_programs_student', 'people'], reverse_edge=test_data[input_edgetype] )\n",
    "        test_sampler = get_hgt_linkloader(test_data, input_edgetype, 1, False, 'triplet', n_negatives, num_neighbors, num_workers=0, prefetch_factor=None, pin_memory=True)\n",
    "    elif on =='train':\n",
    "        add_reverse_edge_original_attributes_and_label_inplace(train_data['courses_and_programs', 'course_and_programs_student', 'people'], reverse_edge=train_data[input_edgetype] )\n",
    "        test_sampler = get_hgt_linkloader(train_data, input_edgetype, 1, False, 'triplet', n_negatives, num_neighbors, num_workers=0, prefetch_factor=None, pin_memory=True)\n",
    "    # test data\n",
    "    best_mrr, best_differences, best_src_nodes, best_dst_nodes = 0, None, None, None\n",
    "    for i, minibatch in tqdm(enumerate(test_sampler)):\n",
    "        if i==100:\n",
    "            break\n",
    "        model.eval()\n",
    "        minibatchpart1, minibatchpart2, edge_label_index, edge_label, input_edge_id, global_src_nodes, global_dst_nodes = minibatch\n",
    "        #optimizer.zero_grad()\n",
    "        differences = model.forward(minibatchpart1.to(device), input_edgetype, edge_label_index.to(device), edge_label.to(device), minibatchpart2.to(device), get_head_fn='forward')\n",
    "        #loss.backward()\n",
    "\n",
    "        # define mrr with differences and labels\n",
    "        # get rank of positive edge from tensor, positive edge is first in batch\n",
    "\n",
    "        differences = -1* differences.cpu().detach().numpy()\n",
    "        edge_label = edge_label.cpu().detach().numpy()\n",
    "        rank = (differences < differences[0]).sum()\n",
    "\n",
    "        # reciprocal\n",
    "        mrr = 1/(rank+1)\n",
    "        if mrr > best_mrr:\n",
    "            best_mrr = mrr\n",
    "            best_differences = differences\n",
    "            best_src_nodes = global_src_nodes\n",
    "            best_dst_nodes = global_dst_nodes\n",
    "            print('new best mrr', best_mrr)\n",
    "            \n",
    "    \n",
    "        mrrs.append(mrr)\n",
    "\n",
    "        \n",
    "        if False:\n",
    "            jobpeople = test_data_text['jobs', 'job_student', 'people']\n",
    "            job_edge = jobpeople.edge_index[1,:] == global_src_nodes[0]\n",
    "            \n",
    "            \n",
    "            if torch.sum(job_edge) != 0:\n",
    "                job_idx = jobpeople.edge_index[0,:][job_edge]\n",
    "                \n",
    "            else:\n",
    "                job_idx = torch.tensor([0])\n",
    "\n",
    "            job_edge = jobpeople.edge_label_index[1,:] == global_src_nodes[0]\n",
    "            if torch.sum(job_edge) != 0:\n",
    "                job_idx2 = jobpeople.edge_label_index[0,:][job_edge]\n",
    "                torch.cat((job_idx, job_idx2)).squeeze()\n",
    "                \n",
    "                \n",
    "            \n",
    "        \n",
    "            print('==============')\n",
    "            print('==============')\n",
    "            print('==============')\n",
    "            # (differences < differences[0])\n",
    "            print('mrr',mrr)\n",
    "            print('rank',rank)\n",
    "            for idx in job_idx:\n",
    "                jobtitle = test_data_text['jobs'].TITLE[idx.item()]\n",
    "                print('job title', jobtitle)\n",
    "                \n",
    "            print('original', test_data_text['courses_and_programs'].TITLE[global_dst_nodes[0]])\n",
    "            print('original', test_data_text['courses_and_programs'].DESCRIPTION[global_dst_nodes[0]])\n",
    "            \n",
    "            # first 10 higher ranked\n",
    "            mask = torch.where(torch.tensor((differences < differences[0])))\n",
    "            indices = torch.argsort(torch.tensor(differences[mask]))\n",
    "            for i in range(10):\n",
    "                index = indices[i]\n",
    "                global_index = global_dst_nodes[mask][index]\n",
    "                print('------')\n",
    "                print(differences[mask][index])\n",
    "                print(test_data_text['courses_and_programs'].TITLE[global_index])\n",
    "                print(test_data_text['courses_and_programs'].DESCRIPTION[global_index])\n",
    "\n",
    "    print('mean mrr',np.mean(mrrs))\n",
    "    print('mean rank',1/np.mean(mrrs))\n",
    "    # mean rank\n",
    "    model.to('cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of dataset on disk:  2.279761238 gb\n",
      "loading saved heterodata object\n",
      "for skill job edges keep top k edges per job, k is  50\n",
      "keep tensor(1208056) of total 16289586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:03,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new best mrr 0.00038774718883288094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:09,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new best mrr 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:13,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new best mrr 0.0625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:21,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new best mrr 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [05:22,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean mrr 0.11858597909438917\n",
      "mean rank 8.432700118823023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of dataset on disk:  2.279761238 gb\n",
      "loading saved heterodata object\n",
      "for skill job edges keep top k edges per job, k is  50\n",
      "keep tensor(1208056) of total 16289586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:07,  7.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new best mrr 8.224360555966774e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:11,  5.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new best mrr 0.000363901018922853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:52,  4.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new best mrr 0.0045871559633027525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35it [03:00,  5.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new best mrr 0.038461538461538464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "61it [05:25,  5.34s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodele5\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_foldere5\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 36\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(model, n_negatives, model_folder, on)\u001b[0m\n\u001b[1;32m     34\u001b[0m minibatchpart1, minibatchpart2, edge_label_index, edge_label, input_edge_id, global_src_nodes, global_dst_nodes \u001b[38;5;241m=\u001b[39m minibatch\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m#optimizer.zero_grad()\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m differences \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mminibatchpart1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_edgetype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_label_index\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_label\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminibatchpart2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_head_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforward\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m#loss.backward()\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# define mrr with differences and labels\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# get rank of positive edge from tensor, positive edge is first in batch\u001b[39;00m\n\u001b[1;32m     42\u001b[0m differences \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m*\u001b[39m differences\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "Cell \u001b[0;32mIn[5], line 40\u001b[0m, in \u001b[0;36mModel.forward\u001b[0;34m(self, hetero_data1, target_edge_type, edge_label_index, edge_label, hetero_data2, get_head_fn)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m target_edge_type[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m target_edge_type[\u001b[38;5;241m2\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwhen passing two data objects, the edge type has to contain two different node types\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     39\u001b[0m     head_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgnn(hetero_data1\u001b[38;5;241m.\u001b[39mx_dict, hetero_data1\u001b[38;5;241m.\u001b[39medge_index_dict)[target_edge_type[\u001b[38;5;241m0\u001b[39m]][edge_label_index[\u001b[38;5;241m0\u001b[39m,:]]\n\u001b[0;32m---> 40\u001b[0m     tail_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhetero_data2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhetero_data2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index_dict\u001b[49m\u001b[43m)\u001b[49m[target_edge_type[\u001b[38;5;241m2\u001b[39m]][edge_label_index[\u001b[38;5;241m1\u001b[39m,:]]\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m target_edge_type[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m target_edge_type[\u001b[38;5;241m2\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwhen passing one data object, the edge type has to contain the same node types\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/mambaforge/envs/pyg_torch21/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/pyg_torch21/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/programming/create_graphds/models/HGT.py:27\u001b[0m, in \u001b[0;36mHGT.forward\u001b[0;34m(self, x_dict, edge_index_dict)\u001b[0m\n\u001b[1;32m     21\u001b[0m x_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     22\u001b[0m     node_type: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin_dict[node_type](x)\u001b[38;5;241m.\u001b[39mrelu_()\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m node_type, x \u001b[38;5;129;01min\u001b[39;00m x_dict\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m     24\u001b[0m }\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m conv \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvs:\n\u001b[0;32m---> 27\u001b[0m     x_dict \u001b[38;5;241m=\u001b[39m \u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x_dict\n",
      "File \u001b[0;32m~/mambaforge/envs/pyg_torch21/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/pyg_torch21/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/pyg_torch21/lib/python3.10/site-packages/torch_geometric/nn/conv/hgt_conv.py:196\u001b[0m, in \u001b[0;36mHGTConv.forward\u001b[0;34m(self, x_dict, edge_index_dict)\u001b[0m\n\u001b[1;32m    193\u001b[0m     v_dict[key] \u001b[38;5;241m=\u001b[39m v\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, H, D)\n\u001b[1;32m    195\u001b[0m q, dst_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cat(q_dict)\n\u001b[0;32m--> 196\u001b[0m k, v, src_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_construct_src_node_feat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mk_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m edge_index, edge_attr \u001b[38;5;241m=\u001b[39m construct_bipartite_edge_index(\n\u001b[1;32m    200\u001b[0m     edge_index_dict, src_offset, dst_offset, edge_attr_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mp_rel)\n\u001b[1;32m    202\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpropagate(edge_index, k\u001b[38;5;241m=\u001b[39mk, q\u001b[38;5;241m=\u001b[39mq, v\u001b[38;5;241m=\u001b[39mv, edge_attr\u001b[38;5;241m=\u001b[39medge_attr,\n\u001b[1;32m    203\u001b[0m                      size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/mambaforge/envs/pyg_torch21/lib/python3.10/site-packages/torch_geometric/nn/conv/hgt_conv.py:156\u001b[0m, in \u001b[0;36mHGTConv._construct_src_node_feat\u001b[0;34m(self, k_dict, v_dict, edge_index_dict)\u001b[0m\n\u001b[1;32m    153\u001b[0m type_vec \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(type_list, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m    155\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_rel(ks, type_vec)\u001b[38;5;241m.\u001b[39mview(H, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, D)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 156\u001b[0m v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mv_rel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtype_vec\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mview(H, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, D)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m k, v, offset\n",
      "File \u001b[0;32m~/mambaforge/envs/pyg_torch21/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/pyg_torch21/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/pyg_torch21/lib/python3.10/site-packages/torch_geometric/nn/dense/linear.py:274\u001b[0m, in \u001b[0;36mHeteroLinear.forward\u001b[0;34m(self, x, type_vec)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_types):\n\u001b[1;32m    273\u001b[0m     mask \u001b[38;5;241m=\u001b[39m type_vec \u001b[38;5;241m==\u001b[39m i\n\u001b[0;32m--> 274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mmask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    275\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    276\u001b[0m     subset_out \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mlinear(x[mask], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight[i]\u001b[38;5;241m.\u001b[39mT)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "evaluate(modele5, 50000, model_foldere5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(modele4, 50000, model_foldere4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(modele4euclidean, 50000, model_foldere4euclidean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(modele5, 50000, model_foldere5, on='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(modele4, 50000, model_foldere4, on='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(modele4euclidean, 30000, model_foldere4euclidean, on='train')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
