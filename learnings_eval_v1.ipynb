{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Reciprocal Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if \"DATABRICKS_RUNTIME_VERSION\" in os.environ and not 'installed_libs' in globals():\n",
    "  #CUDA = 'cu121' \n",
    "  installed_libs = True\n",
    "  \n",
    "  \n",
    "  !pip install torch==2.1.0  torchvision==0.16.0 torchtext==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cu121\n",
    "  import torch\n",
    "  #os.environ['TORCH'] = torch.__version__\n",
    "  #print(torch.__version__)\n",
    "  #torch_version = '2.0.0+cu118'\n",
    "  \n",
    "  #!pip install pyg_lib torch_scatter torch_sparse torch_cluster -f https://data.pyg.org/whl/torch-2.1.0+${CUDA}.html # torch_spline_conv\n",
    "  !pip install torch_geometric\n",
    "  !pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.1.0+cu121.html\n",
    "  #!pip install torch_sparse -f https://data.pyg.org/whl/torch-2.1.0+${CUDA}.html\n",
    "  #!pip install torch_scatter -f https://data.pyg.org/whl/torch-2.1.0+${CUDA}.html\n",
    "  #!pip install pyg_lib -f https://data.pyg.org/whl/torch-2.1.0+${CUDA}.html\n",
    "  !pip install sentence-transformers\n",
    "  !pip install torcheval\n",
    "  !pip install matplotlib\n",
    "  !pip install pandas\n",
    "  !pip install tensorboard\n",
    "  \n",
    "if \"DATABRICKS_RUNTIME_VERSION\" in os.environ:\n",
    "  ROOT_FOLDER = '/dbfs/FileStore/GraphNeuralNetworks/'\n",
    "else:\n",
    "  ROOT_FOLDER = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amos/mambaforge/envs/pyg_torch21/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of dataset on disk:  2.279761238 gb\n",
      "loading saved heterodata object\n",
      "for skill job edges keep top k edges per job, k is  50\n",
      "keep tensor(1208056) of total 16289586\n"
     ]
    }
   ],
   "source": [
    "from learnings_sampler_v1 import get_datasets, uniform_hgt_sampler, get_minibatch_count, add_reverse_edge_original_attributes_and_label_inplace, get_hgt_linkloader, get_single_minibatch_count\n",
    "\n",
    "train_data, val_data, test_data = get_datasets(get_edge_attr=False, filename=ROOT_FOLDER+'HeteroData_Learnings_normalized_triangles_withadditionaldata_v1.pt', filter_top_k=True, top_k=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models.TransE import TransE\n",
    "from models.DistMult import DistMult\n",
    "from models.HGT import HGT\n",
    "import torch_geometric\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, gnn : torch.nn.Module, head :  torch.nn.Module, node_types, edge_types, ggn_output_dim):\n",
    "        super().__init__()\n",
    "        # edge_type onehot lookup table with keys\n",
    "        # node_type onehot lookup table with keys\n",
    "        self.node_type_embedding = torch.nn.Embedding(len(node_types), ggn_output_dim) # hidden channels should be the output dim of gnn\n",
    "        \n",
    "        self.edge_types = edge_types\n",
    "        for edge_type in edge_types:\n",
    "            if edge_type[1].startswith('rev_'):\n",
    "                self.edge_types.remove(edge_type)\n",
    "        \n",
    "        # create edge to int mapping\n",
    "        self.edgeindex_lookup = {edge_type:torch.tensor(i)  for i, edge_type in enumerate(edge_types)}\n",
    "            \n",
    "        # hidden channels should be the output dim of gnn\n",
    "        if head=='TransE': \n",
    "            self.head = TransE(len(node_types), len(edge_types) , ggn_output_dim)  # KGE head with loss function\n",
    "        elif head=='DistMult':\n",
    "            self.head = DistMult(len(node_types), len(edge_types) , ggn_output_dim)  # KGE head with loss function\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        \n",
    "        self.gnn = gnn\n",
    "        \n",
    "    \n",
    "\n",
    "    def forward(self, hetero_data1, target_edge_type, edge_label_index, edge_label, hetero_data2=None, get_head_fn='loss'):\n",
    "        \n",
    "        if hetero_data2 is not None:\n",
    "            assert target_edge_type[0] != target_edge_type[2], 'when passing two data objects, the edge type has to contain two different node types'\n",
    "            head_embeddings = self.gnn(hetero_data1.x_dict, hetero_data1.edge_index_dict)[target_edge_type[0]][edge_label_index[0,:]]\n",
    "            tail_embeddings = self.gnn(hetero_data2.x_dict, hetero_data2.edge_index_dict)[target_edge_type[2]][edge_label_index[1,:]]\n",
    "        else:\n",
    "            assert target_edge_type[0] == target_edge_type[2], 'when passing one data object, the edge type has to contain the same node types'\n",
    "\n",
    "\n",
    "            embeddings = self.gnn(hetero_data1.x_dict, hetero_data1.edge_index_dict)\n",
    "            head_embeddings = embeddings[target_edge_type[0]][edge_label_index[0,:]]\n",
    "            tail_embeddings = embeddings[target_edge_type[2]][edge_label_index[1,:]]\n",
    "\n",
    "        \n",
    "        edgeindex = self.edgeindex_lookup[target_edge_type]\n",
    "        if get_head_fn=='loss':\n",
    "            loss = self.head.loss(head_embeddings, edgeindex.to(device), tail_embeddings, edge_label)\n",
    "            return loss\n",
    "        elif get_head_fn=='forward':\n",
    "            return self.head.forward(head_embeddings, edgeindex.to(device), tail_embeddings)\n",
    "    \n",
    "    def get_embeddings(self, hetero_data, rel_type, node_type, first_n_nodes=None):\n",
    "        # gives us the closeness of embeddings to the other side of the relationship, i.e. e + r or e - r\n",
    "        if node_type == rel_type[0]:\n",
    "            have_head_or_tail =='head'\n",
    "        else:\n",
    "            have_head_or_tail =='tail'\n",
    "            \n",
    "        mask = torch.zeros(hetero_data.x_dict[rel_type[0]].shape[0])\n",
    "        mask[:first_n_nodes] = 1\n",
    "        embeddings = self.gnn(hetero_data.x_dict, hetero_data.edge_index_dict)[node_type][mask]\n",
    "        return self.head.get_embeddings(embeddings, rel_type, have_head_or_tail)\n",
    "        \n",
    "        \n",
    "metadata = train_data.metadata()\n",
    "# add selfloops\n",
    "for node_type in train_data.node_types:\n",
    "    metadata[1].append((node_type, 'self_loop', node_type))    \n",
    "    \n",
    "# out_channels = 256\n",
    "# hidden_channels = 256\n",
    "# num_heads = 8\n",
    "# num_layers = 2\n",
    "# head = 'TransE'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "model_folder = ROOT_FOLDER+'models/learningpeople_hgt_20231102_004035_lr2e-06_bs32_neighbors_133_1333_head_TransE_hiddenchannels_256_outchannels_256_numheads_8_numlayers_2/Ep0_model_samplesseen154400.pt'\n",
    "\n",
    "# infer model parameters, dimensions batchsize etc from filename\n",
    "out_channels = int(model_folder.split('outchannels_')[1].split('_')[0])\n",
    "hidden_channels = int(model_folder.split('hiddenchannels_')[1].split('_')[0])\n",
    "num_heads = int(model_folder.split('numheads_')[1].split('_')[0])\n",
    "num_layers = int(model_folder.split('numlayers_')[1].split('/')[0])\n",
    "head = model_folder.split('head_')[1].split('_')[0]\n",
    "learning_rate = float(model_folder.split('lr')[1].split('_')[0])\n",
    "batch_size = int(model_folder.split('bs')[1].split('_')[0])\n",
    "num_neighbors = [int(x) for x in model_folder.split('neighbors_')[1].split('head')[0].strip('_').split('_')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (node_type_embedding): Embedding(6, 256)\n",
       "  (head): TransE(6, num_relations=22, hidden_channels=256)\n",
       "  (gnn): HGT(\n",
       "    (lin_dict): ModuleDict(\n",
       "      (courses_and_programs): Linear(-1, 256, bias=True)\n",
       "      (qualifications): Linear(-1, 256, bias=True)\n",
       "      (skills): Linear(-1, 256, bias=True)\n",
       "      (people): Linear(-1, 256, bias=True)\n",
       "      (jobs): Linear(-1, 256, bias=True)\n",
       "      (organizations): Linear(-1, 256, bias=True)\n",
       "    )\n",
       "    (convs): ModuleList(\n",
       "      (0-1): 2 x HGTConv(-1, 256, heads=8)\n",
       "    )\n",
       "    (lin): Linear(256, 256, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnn = HGT(hidden_channels=out_channels, out_channels=out_channels, num_heads=num_heads, num_layers=num_layers, node_types=train_data.node_types, data_metadata=metadata)\n",
    "\n",
    "model = Model(gnn, head=head, node_types=metadata[0], edge_types=metadata[1], ggn_output_dim=out_channels)\n",
    "#torch_geometric.compile(model, dynamic=True)\n",
    "#model.load_state_dict(torch.load(model_folder)['model_state_dict'])\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init dimensions of model by training it\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime\n",
    "input_edgetype = ('people', 'rev_course_and_programs_student', 'courses_and_programs')\n",
    "add_reverse_edge_original_attributes_and_label_inplace(train_data['courses_and_programs', 'course_and_programs_student', 'people'], reverse_edge=train_data[input_edgetype] )\n",
    "add_reverse_edge_original_attributes_and_label_inplace(val_data['courses_and_programs', 'course_and_programs_student', 'people'], reverse_edge=val_data[input_edgetype] )\n",
    "\n",
    "val_sampler = get_hgt_linkloader(val_data, input_edgetype, 4, False, 'triplet', 1, num_neighbors, num_workers=0, prefetch_factor=None, pin_memory=True)\n",
    "\n",
    "learning_rate = 2e-4\n",
    "# torch get optimizer by string name\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) #2e-15\n",
    "\n",
    "# train model\n",
    "\n",
    "model.eval()\n",
    "minibatchpart1, minibatchpart2, edge_label_index, edge_label, input_edge_id, src_nodes, dst_nodes = next(iter(val_sampler))\n",
    "#optimizer.zero_grad()\n",
    "loss = model(minibatchpart1.to(device), input_edgetype, edge_label_index.to(device), edge_label.to(device), minibatchpart2.to(device))\n",
    "#loss.backward()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load state dict\n",
    "model.load_state_dict(torch.load(model_folder)['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (663561555.py, line 59)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[39], line 59\u001b[0;36m\u001b[0m\n\u001b[0;31m    if False:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# evaluate model on test set\n",
    "# init dimensions of model by training it\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime\n",
    "import numpy as np \n",
    "\n",
    "mrrs = []\n",
    "input_edgetype = ('people', 'rev_course_and_programs_student', 'courses_and_programs')\n",
    "add_reverse_edge_original_attributes_and_label_inplace(test_data['courses_and_programs', 'course_and_programs_student', 'people'], reverse_edge=test_data[input_edgetype] )\n",
    "negatives = 10000\n",
    "test_sampler = get_hgt_linkloader(test_data, input_edgetype, 1, False, 'triplet', negatives, num_neighbors, num_workers=0, prefetch_factor=None, pin_memory=True)\n",
    "best_mrr, best_differences, best_src_nodes, best_dst_nodes = 0, None, None, None\n",
    "\n",
    "\n",
    "\n",
    "# test data\n",
    "train_data_text, val_data_text, test_data_text = get_datasets(get_edge_attr=False, filename=ROOT_FOLDER+'HeteroData_Learnings_normalized_triangles_withadditionaldata_v1.pt', filter_top_k=True, top_k=50, remove_text_attr=False)\n",
    "input_edgetype = ('people', 'rev_course_and_programs_student', 'courses_and_programs')\n",
    "add_reverse_edge_original_attributes_and_label_inplace(test_data_text['courses_and_programs', 'course_and_programs_student', 'people'], reverse_edge=test_data_text[input_edgetype] )\n",
    "# test data\n",
    "\n",
    "for i, minibatch in tqdm(enumerate(test_sampler)):\n",
    "    if i==100:\n",
    "        break\n",
    "    model.eval()\n",
    "    minibatchpart1, minibatchpart2, edge_label_index, edge_label, input_edge_id, global_src_nodes, global_dst_nodes = minibatch\n",
    "    #optimizer.zero_grad()\n",
    "    differences = model.forward(minibatchpart1.to(device), input_edgetype, edge_label_index.to(device), edge_label.to(device), minibatchpart2.to(device), get_head_fn='forward')\n",
    "    #loss.backward()\n",
    "\n",
    "    # define mrr with differences and labels\n",
    "    # get rank of positive edge from tensor, positive edge is first in batch\n",
    "\n",
    "    differences = -1* differences.cpu().detach().numpy()\n",
    "    edge_label = edge_label.cpu().detach().numpy()\n",
    "    rank = (differences < differences[0]).sum()\n",
    "\n",
    "    # reciprocal\n",
    "    mrr = 1/(rank+1)\n",
    "    if mrr > best_mrr:\n",
    "        best_mrr = mrr\n",
    "        best_differences = differences\n",
    "        best_src_nodes = global_src_nodes\n",
    "        best_dst_nodes = global_dst_nodes\n",
    "        print('new best mrr', best_mrr)\n",
    "        \n",
    "    print(mrr)\n",
    "    mrrs.append(mrr)\n",
    "\n",
    "    jobpeople = test_data_text['jobs', 'job_student', 'people']\n",
    "    job_edge = jobpeople.edge_index[1,:] == global_src_nodes[0]\n",
    "    if torch.sum(job_edge) == 0:\n",
    "        job_edge = jobpeople.edge_label_index[1,:] == global_src_nodes[0]\n",
    "        job_idx = jobpeople.edge_label_index[0,:][job_edge]\n",
    "    else:\n",
    "        job_idx = jobpeople.edge_index[0,:][job_edge]\n",
    "        \n",
    "    jobtitle = test_data_text['jobs'].TITLE[job_idx.item()]\n",
    "    if False:\n",
    "        print('==============')\n",
    "        print('==============')\n",
    "        print('==============')\n",
    "        # (differences < differences[0])\n",
    "        print('mrr',mrr)\n",
    "        print('rank',rank)\n",
    "        print('job title', jobtitle)\n",
    "        print('original', test_data_text['courses_and_programs'].TITLE[global_dst_nodes[0]])\n",
    "        print('original', test_data_text['courses_and_programs'].DESCRIPTION[global_dst_nodes[0]])\n",
    "        \n",
    "        # first 10 higher ranked\n",
    "        mask = torch.where(torch.tensor((differences < differences[0])))\n",
    "        indices = torch.argsort(torch.tensor(differences[mask]))\n",
    "        for i in range(10):\n",
    "            index = indices[i]\n",
    "            global_index = global_dst_nodes[mask][index]\n",
    "            print('------')\n",
    "            print(differences[mask][index])\n",
    "            print(test_data_text['courses_and_programs'].TITLE[global_index])\n",
    "            print(test_data_text['courses_and_programs'].DESCRIPTION[global_index])\n",
    "\n",
    "print('mean mrr',np.mean(mrrs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  courses_and_programs={ x=[55796, 815] },\n",
       "  qualifications={ x=[1242, 786] },\n",
       "  skills={ x=[264052, 775] },\n",
       "  people={ x=[293444, 25] },\n",
       "  jobs={ x=[55638, 775] },\n",
       "  organizations={ x=[13613, 3] },\n",
       "  (skills, qualification_skill, qualifications)={\n",
       "    edge_index=[2, 1517],\n",
       "    edge_label=[158],\n",
       "    edge_label_index=[2, 158],\n",
       "  },\n",
       "  (skills, course_and_program_skill, courses_and_programs)={\n",
       "    edge_index=[2, 245195],\n",
       "    edge_label=[25808],\n",
       "    edge_label_index=[2, 25808],\n",
       "  },\n",
       "  (courses_and_programs, course_qualification, qualifications)={\n",
       "    edge_index=[2, 1995],\n",
       "    edge_label=[208],\n",
       "    edge_label_index=[2, 208],\n",
       "  },\n",
       "  (courses_and_programs, course_and_programs_student, people)={\n",
       "    edge_index=[2, 525782],\n",
       "    edge_label=[55344],\n",
       "    edge_label_index=[2, 55344],\n",
       "  },\n",
       "  (jobs, job_student, people)={\n",
       "    edge_index=[2, 278772],\n",
       "    edge_label=[29344],\n",
       "    edge_label_index=[2, 29344],\n",
       "  },\n",
       "  (people, supervisor_supervisee, people)={\n",
       "    edge_index=[2, 207026],\n",
       "    edge_label=[21792],\n",
       "    edge_label_index=[2, 21792],\n",
       "  },\n",
       "  (people, organization_student, organizations)={\n",
       "    edge_index=[2, 277457],\n",
       "    edge_label=[29206],\n",
       "    edge_label_index=[2, 29206],\n",
       "  },\n",
       "  (jobs, job_job, jobs)={\n",
       "    edge_index=[2, 17465],\n",
       "    edge_label=[1838],\n",
       "    edge_label_index=[2, 1838],\n",
       "  },\n",
       "  (skills, job_skill, jobs)={\n",
       "    edge_index=[2, 1147654],\n",
       "    edge_label=[120804],\n",
       "    edge_label_index=[2, 120804],\n",
       "  },\n",
       "  (jobs, broader_job_job, jobs)={\n",
       "    edge_index=[2, 51857],\n",
       "    edge_label=[5458],\n",
       "    edge_label_index=[2, 5458],\n",
       "  },\n",
       "  (skills, skill_skill, skills)={\n",
       "    edge_index=[2, 2146454],\n",
       "    edge_label=[225942],\n",
       "    edge_label_index=[2, 225942],\n",
       "  },\n",
       "  (qualifications, rev_qualification_skill, skills)={ edge_index=[2, 1517] },\n",
       "  (courses_and_programs, rev_course_and_program_skill, skills)={ edge_index=[2, 245195] },\n",
       "  (qualifications, rev_course_qualification, courses_and_programs)={ edge_index=[2, 1995] },\n",
       "  (people, rev_course_and_programs_student, courses_and_programs)={\n",
       "    edge_index=[2, 525782],\n",
       "    edge_label_index=[2, 55344],\n",
       "  },\n",
       "  (people, rev_job_student, jobs)={ edge_index=[2, 278772] },\n",
       "  (people, rev_supervisor_supervisee, people)={ edge_index=[2, 207026] },\n",
       "  (organizations, rev_organization_student, people)={ edge_index=[2, 277457] },\n",
       "  (jobs, rev_job_job, jobs)={ edge_index=[2, 17465] },\n",
       "  (jobs, rev_job_skill, skills)={ edge_index=[2, 1147654] },\n",
       "  (jobs, rev_broader_job_job, jobs)={ edge_index=[2, 51857] },\n",
       "  (skills, rev_skill_skill, skills)={ edge_index=[2, 2146454] }\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1/0.003534380551853457 +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.99999999999999"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#rank + 1 = 1/mmr\n",
    "1/best_mrr -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of dataset on disk:  2.279761238 gb\n",
      "loading saved heterodata object\n",
      "for skill job edges keep top k edges per job, k is  50\n",
      "keep tensor(1208056) of total 16289586\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'edge_index': tensor([[237571, 232648, 223362,  ..., 144382, 146638, 167762],\n",
       "        [ 33929,  15584,  28839,  ...,  27864,  27235,  50546]]), 'edge_attr': tensor([[0.8948, 0.8944, 0.0037],\n",
       "        [0.9398, 0.9394, 0.0038],\n",
       "        [0.6720, 0.6716, 0.0036],\n",
       "        ...,\n",
       "        [0.5501, 0.5497, 0.0036],\n",
       "        [0.6741, 0.6737, 0.0036],\n",
       "        [0.9708, 0.9704, 0.0037]], dtype=torch.float64), 'edge_label': tensor([1., 1., 1.,  ..., 0., 0., 0.]), 'edge_label_index': tensor([[229076, 231606, 159751,  ..., 145961,  84933,  77255],\n",
       "        [ 29467,  47061,  25464,  ...,  15266,  48246,  13604]])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([253238])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_src_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(job_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'IS_ACTIVE_INFERRED': array(['Y', 'Y', 'N', ..., 'N', 'Y', 'N'], dtype=object), 'x': tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00, 1.8083e-03,\n",
       "         0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00, 1.8083e-03,\n",
       "         0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00, 1.8083e-03,\n",
       "         0.0000e+00],\n",
       "        ...,\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 9.0416e-04,\n",
       "         0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 9.0416e-04,\n",
       "         0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 9.0416e-04,\n",
       "         0.0000e+00]])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_text['people']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original 4. Pre-Fund Maintenance on TLS\n",
      "original \n",
      "This course provides information to perform pre-fund maintenance functions on the Term Lending System (TLS), including screen index organization, key features of selected screens and interactive customer scenarios. Estimated completion time is 30 minutes.\n"
     ]
    }
   ],
   "source": [
    "# (differences < differences[0])\n",
    "print('original', test_data_text['courses_and_programs'].TITLE[best_dst_nodes[0]])\n",
    "print('original', test_data_text['courses_and_programs'].DESCRIPTION[best_dst_nodes[0]])\n",
    "\n",
    "# first 10 higher ranked\n",
    "mask = torch.where(torch.tensor((best_differences < best_differences[0])))\n",
    "indices = torch.argsort(torch.tensor(best_differences[mask]))\n",
    "for i in range(10):\n",
    "    index = indices[i]\n",
    "    global_index = best_dst_nodes[mask][index]\n",
    "    print('------')\n",
    "    print(best_differences[mask][index])\n",
    "    print(test_data_text['courses_and_programs'].TITLE[global_index])\n",
    "    print(test_data_text['courses_and_programs'].DESCRIPTION[global_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "0.6546815\n",
      "Check-Off Request: Small Business Administration for AMSB Trainee\n",
      "\n",
      "The CareerStart certfications on My Learning Centre have been set up in a unique way to make it easier and less time consuming to manage training completions. Under most CareerStart certifications there are two modules, 'Certification Check-off' and 'Courses'. The Courses are optional and can be taken by the Trainee if it has been deemed necessary to close a learning gap. The Certification Check-off is required, and whether training is completed or not, once it has been determined that the relevant skilland knowledge has been mastered, the Certification Check-off is used to show completion on MLC.\n",
      "------\n",
      "0.6613003\n",
      "U.S. GCM Education Series Prime Services\n",
      "Please join the next edition of the U.S. GCM Education Series to help the development and education of Scotiabankers. The next session topic is about Prime Services\n",
      "------\n",
      "0.67238903\n",
      "Behavior: Putting Your Best Foot Forward\n",
      "\n",
      "------\n",
      "0.673694\n",
      "Report of Assets & Liabilities of US Branches & Agencies of Foreign Banks (Houston Agency\n",
      "Training on the FFIEC 002/Call Report - Part I Assets and Part II Liabilities and Off-Balance Sheet Items for Houston Branch.\n",
      "------\n",
      "0.68224865\n",
      "TIC Report\n",
      "TIC Report\n",
      "------\n",
      "0.6858703\n",
      "Scotiatrust TA Silver - Checkpoint 1\n",
      "Checkpoint 1 confirms your acknowledgement for completing all related activities and meeting with your Manager.\n",
      "------\n",
      "0.6870931\n",
      "Taxation Issues for Estates and Trusts\n",
      "You can request a refund* online or by completing the \"Course Cancellation Form\" and faxing the form to CSI. CSI will retain $175 if a refund request is received online or by fax within 14 days of course purchase. Note: Scotiabank students must cancel through your corporate Learning Management System (LMS). *Refunds are not available for textbooks, learning aids (such as Check practice exams), online courses and products, Continuing Education courses and certificate frames.\n",
      "Upon completion of Taxation Issues of Estates and Trusts, learners will be able to:-Identify the types of incomes subject to tax-State the available tax deduction and credits available to individuals-Explain how tax is calculated for individuals, estates, trusts and corporation-Identify the rules regarding filing of returns for the year of death and ongoing trusts-State the differences between taxation of testamentary trusts and inter vivos trusts-Describe the special taxation issues facing the trustee of a trust that owns an interest in an active incorporated business or an interest in a holding corporation-State withholding tax obligations when making payments to non-resident beneficiaries-Explain the issues arising in meeting foreign taxation claims from the perspective of the trustee-Outline the tax rules for:-Computing the income of trust and allocating income to beneficiaries-Distribution of income or capital to beneficiaries-Obtaining clearance certificates-Deemed\n",
      "This activity is designed to introduce you to the tax management of trusts and how they relate to trust creation, administration upon the testator's death and other on-going trust administration issues. You'll learn about individual, year-of-death and testamentary taxations, as well as inter vivos trusts, corporate taxation and taxation principles that affect individuals, trusts, estates and corporations from the trustee's perspective.\n",
      "------\n",
      "0.68781316\n",
      "Scotiatrust TA Silver - Checkpoint 2\n",
      "Checkpoint 2 confirms your acknowledgement for completing all related activities and meeting with your Manager.\n",
      "------\n",
      "0.69173574\n",
      "Gira Seguros 2022\n",
      "This tour covers Scotiabank product topics\n",
      "------\n",
      "0.6958084\n",
      "06. CLB: Opportunity Assessment\n",
      "\n",
      "Audience: Commercial Content Summary: the first of the Commercial Loans to Business (CLB) modules covers The Lending Environment, The Decision Strategy, Assessing Opportunities, and Preliminary Assessment ProcessCompletion time is approximately 2 hours. All of the modules are coached assisted/self study; your coach will be in touch with you in the next few days and throughout the program. If any other assistance is required, send an email to commercial.training@scotiabank.com. For this module to run properly, a font size adjustment is required. Before clicking on the course, follow these steps to adjust the font on your PC: Click on View in the menu going across the top of your screen Select Text Size Select Medium Your font size will reset to the default upon exiting My Learning Centre.\n"
     ]
    }
   ],
   "source": [
    "# first 10 higher ranked\n",
    "mask = torch.where(torch.tensor((best_differences < best_differences[0])))\n",
    "indices = torch.argsort(torch.tensor(best_differences[mask]))\n",
    "for i in range(10):\n",
    "    index = indices[i]\n",
    "    global_index = best_dst_nodes[mask][index]\n",
    "    print('------')\n",
    "    print(best_differences[mask][index])\n",
    "    print(test_data_text['courses_and_programs'].TITLE[global_index])\n",
    "    print(test_data_text['courses_and_programs'].DESCRIPTION[global_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
